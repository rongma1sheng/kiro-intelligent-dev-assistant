#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ™ºèƒ½å¼€å‘æ”¯æŒåŠŸèƒ½
éªŒè¯é”™è¯¯è¯Šæ–­ã€ä»»åŠ¡åˆ†é…ã€ç”Ÿå‘½å‘¨æœŸç®¡ç†çš„å…·ä½“åŠŸèƒ½
"""

import sys
import os
from datetime import datetime
from pathlib import Path

# è®¾ç½®UTF-8ç¼–ç ï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform.startswith('win'):
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# å¯¼å…¥æ™ºèƒ½å¼€å‘æ”¯æŒç³»ç»Ÿ
sys.path.append('scripts/utilities')
from intelligent_development_support_integrated import IntelligentDevelopmentSupport

class IntelligentSupportFeatureTester:
    def __init__(self):
        self.support_system = IntelligentDevelopmentSupport()
        self.test_results = {
            "timestamp": datetime.now().isoformat(),
            "error_diagnosis_tests": [],
            "task_assignment_tests": [],
            "lifecycle_management_tests": [],
            "integration_tests": [],
            "overall_success": False
        }
    
    def test_error_diagnosis(self):
        """æµ‹è¯•é”™è¯¯è¯Šæ–­åŠŸèƒ½"""
        
        print("ğŸ” æµ‹è¯•é”™è¯¯è¯Šæ–­åŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "Unicodeç¼–ç é”™è¯¯",
                "error_message": "UnicodeEncodeError: 'gbk' codec can't encode character 'ğŸ¤–'",
                "expected_category": "ç¼–ç é—®é¢˜",
                "expected_role": "ğŸš€ Full-Stack Engineer"
            },
            {
                "name": "è¯­æ³•é”™è¯¯",
                "error_message": "IndentationError: expected an indented block after 'if' statement",
                "expected_category": "è¯­æ³•é”™è¯¯",
                "expected_role": "ğŸ” Code Review Specialist"
            },
            {
                "name": "å¯¼å…¥é”™è¯¯",
                "error_message": "ModuleNotFoundError: No module named 'numpy'",
                "expected_category": "å¯¼å…¥é”™è¯¯",
                "expected_role": "ğŸš€ Full-Stack Engineer"
            },
            {
                "name": "æƒé™é”™è¯¯",
                "error_message": "PermissionError: Access denied to file",
                "expected_category": "æƒé™é—®é¢˜",
                "expected_role": "ğŸ”’ Security Engineer"
            }
        ]
        
        for test_case in test_cases:
            try:
                diagnosis = self.support_system.diagnose_error(
                    test_case["error_message"],
                    {"test_case": test_case["name"]}
                )
                
                test_result = {
                    "test_name": test_case["name"],
                    "success": True,
                    "diagnosis": {
                        "category": diagnosis["category"],
                        "severity": diagnosis["severity"],
                        "assigned_role": diagnosis["assigned_role"],
                        "solutions_count": len(diagnosis["solutions"]),
                        "prevention_measures_count": len(diagnosis["prevention_measures"])
                    },
                    "expectations_met": {
                        "category_match": diagnosis["category"] == test_case["expected_category"],
                        "role_match": diagnosis["assigned_role"] == test_case["expected_role"],
                        "has_solutions": len(diagnosis["solutions"]) > 0,
                        "has_prevention": len(diagnosis["prevention_measures"]) > 0
                    }
                }
                
                # éªŒè¯æœŸæœ›ç»“æœ
                all_expectations_met = all(test_result["expectations_met"].values())
                test_result["success"] = all_expectations_met
                
                print(f"  {'âœ…' if test_result['success'] else 'âŒ'} {test_case['name']}: "
                      f"{diagnosis['category']} -> {diagnosis['assigned_role']}")
                
            except Exception as e:
                test_result = {
                    "test_name": test_case["name"],
                    "success": False,
                    "error": str(e)
                }
                print(f"  âŒ {test_case['name']}: æµ‹è¯•å¤±è´¥ - {e}")
            
            self.test_results["error_diagnosis_tests"].append(test_result)
    
    def test_task_assignment(self):
        """æµ‹è¯•ä»»åŠ¡åˆ†é…åŠŸèƒ½"""
        
        print("\nğŸ“‹ æµ‹è¯•ä»»åŠ¡åˆ†é…åŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "æ¶æ„ä¼˜åŒ–ä»»åŠ¡",
                "task_description": "é‡æ„Hookç³»ç»Ÿæ¶æ„ï¼Œæå‡æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§",
                "expected_primary": "ğŸ—ï¸ Software Architect",
                "expected_effort": "é«˜"  # åŒ…å«"é‡æ„"å’Œ"æ¶æ„"å…³é”®è¯
            },
            {
                "name": "æ€§èƒ½ä¼˜åŒ–ä»»åŠ¡", 
                "task_description": "ä¼˜åŒ–ç®—æ³•æ€§èƒ½ï¼Œå‡å°‘è®¡ç®—å¤æ‚åº¦",
                "expected_primary": "ğŸ§® Algorithm Engineer",
                "expected_effort": "é«˜"  # æ€§èƒ½ä¼˜åŒ–æ˜¯é«˜å·¥ä½œé‡
            },
            {
                "name": "UIç•Œé¢æ”¹è¿›",
                "task_description": "æ”¹è¿›ç”¨æˆ·ç•Œé¢è®¾è®¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒ",
                "expected_primary": "ğŸ¨ UI/UX Engineer",
                "expected_effort": "ä¸­ç­‰"  # åŒ…å«"æ”¹è¿›"å…³é”®è¯
            },
            {
                "name": "å®‰å…¨æ¼æ´ä¿®å¤",
                "task_description": "ä¿®å¤å®‰å…¨æ¼æ´ï¼ŒåŠ å¼ºæƒé™æ§åˆ¶",
                "expected_primary": "ğŸ”’ Security Engineer",
                "expected_effort": "é«˜"  # å®‰å…¨ç›¸å…³ä»»åŠ¡æ˜¯é«˜å·¥ä½œé‡
            }
        ]
        
        for test_case in test_cases:
            try:
                assignment = self.support_system.assign_task_intelligently(
                    test_case["task_description"],
                    {"test_case": test_case["name"]}
                )
                
                test_result = {
                    "test_name": test_case["name"],
                    "success": True,
                    "assignment": {
                        "primary_assignee": assignment["primary_assignee"],
                        "supporting_roles": assignment["supporting_roles"],
                        "estimated_effort": assignment["estimated_effort"],
                        "priority": assignment["priority"],
                        "skills_required": assignment["skills_required"]
                    },
                    "expectations_met": {
                        "primary_match": assignment["primary_assignee"] == test_case["expected_primary"],
                        "effort_match": assignment["estimated_effort"] == test_case["expected_effort"],
                        "has_supporting_roles": len(assignment["supporting_roles"]) > 0,
                        "has_skills": len(assignment["skills_required"]) > 0,
                        "has_priority": assignment["priority"] in ["é«˜", "ä¸­", "ä½"]
                    }
                }
                
                # éªŒè¯æœŸæœ›ç»“æœ
                all_expectations_met = all(test_result["expectations_met"].values())
                test_result["success"] = all_expectations_met
                
                print(f"  {'âœ…' if test_result['success'] else 'âŒ'} {test_case['name']}: "
                      f"{assignment['primary_assignee']} ({assignment['estimated_effort']}) "
                      f"[æœŸæœ›: {test_case['expected_primary']} ({test_case['expected_effort']})]")
                
            except Exception as e:
                test_result = {
                    "test_name": test_case["name"],
                    "success": False,
                    "error": str(e)
                }
                print(f"  âŒ {test_case['name']}: æµ‹è¯•å¤±è´¥ - {e}")
            
            self.test_results["task_assignment_tests"].append(test_result)
    
    def test_lifecycle_management(self):
        """æµ‹è¯•ç”Ÿå‘½å‘¨æœŸç®¡ç†åŠŸèƒ½"""
        
        print("\nğŸ”„ æµ‹è¯•ç”Ÿå‘½å‘¨æœŸç®¡ç†åŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "ä»»åŠ¡å¼€å§‹æ‰§è¡Œ",
                "task_id": "test_task_001",
                "current_state": "planned",
                "action": "å¼€å§‹æ‰§è¡Œ",
                "expected_new_state": "in_progress"
            },
            {
                "name": "è¯·æ±‚ä»£ç å®¡æŸ¥",
                "task_id": "test_task_002", 
                "current_state": "in_progress",
                "action": "è¯·æ±‚å®¡æŸ¥",
                "expected_new_state": "review"
            },
            {
                "name": "å®¡æŸ¥é€šè¿‡å®Œæˆ",
                "task_id": "test_task_003",
                "current_state": "review",
                "action": "é€šè¿‡å®¡æŸ¥",
                "expected_new_state": "completed"
            },
            {
                "name": "è´¨é‡éªŒè¯",
                "task_id": "test_task_004",
                "current_state": "completed",
                "action": "è´¨é‡éªŒè¯",
                "expected_new_state": "verified"
            }
        ]
        
        for test_case in test_cases:
            try:
                lifecycle_result = self.support_system.manage_task_lifecycle(
                    test_case["task_id"],
                    test_case["current_state"],
                    test_case["action"]
                )
                
                test_result = {
                    "test_name": test_case["name"],
                    "success": True,
                    "lifecycle": {
                        "current_state": lifecycle_result["current_state"],
                        "new_state": lifecycle_result["new_state"],
                        "action_taken": lifecycle_result["action_taken"],
                        "available_actions": lifecycle_result["available_actions"],
                        "recommendations_count": len(lifecycle_result["recommendations"])
                    },
                    "expectations_met": {
                        "state_transition": lifecycle_result["new_state"] == test_case["expected_new_state"],
                        "has_actions": len(lifecycle_result["available_actions"]) > 0,
                        "has_recommendations": len(lifecycle_result["recommendations"]) > 0
                    }
                }
                
                # éªŒè¯æœŸæœ›ç»“æœ
                all_expectations_met = all(test_result["expectations_met"].values())
                test_result["success"] = all_expectations_met
                
                print(f"  {'âœ…' if test_result['success'] else 'âŒ'} {test_case['name']}: "
                      f"{test_case['current_state']} -> {lifecycle_result['new_state']}")
                
            except Exception as e:
                test_result = {
                    "test_name": test_case["name"],
                    "success": False,
                    "error": str(e)
                }
                print(f"  âŒ {test_case['name']}: æµ‹è¯•å¤±è´¥ - {e}")
            
            self.test_results["lifecycle_management_tests"].append(test_result)
    
    def test_integrated_support(self):
        """æµ‹è¯•é›†æˆæ”¯æŒåŠŸèƒ½"""
        
        print("\nğŸ¯ æµ‹è¯•é›†æˆæ”¯æŒåŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "ç»¼åˆæ”¯æŒè¯·æ±‚",
                "request": {
                    "id": "integration_test_001",
                    "type": "comprehensive",
                    "error_message": "SyntaxError: invalid syntax in line 42",
                    "task_description": "ä¿®å¤è¯­æ³•é”™è¯¯å¹¶ä¼˜åŒ–ä»£ç è´¨é‡",
                    "task_id": "fix_syntax_001",
                    "current_state": "blocked",
                    "action": "è§£é™¤é˜»å¡",
                    "context": {"urgency": "é«˜", "file": "test_module.py"}
                }
            },
            {
                "name": "é”™è¯¯è¯Šæ–­ä¸“é¡¹",
                "request": {
                    "id": "integration_test_002",
                    "type": "error_diagnosis",
                    "error_message": "ImportError: cannot import name 'missing_function'",
                    "context": {"module": "utils", "function": "missing_function"}
                }
            },
            {
                "name": "ä»»åŠ¡åˆ†é…ä¸“é¡¹",
                "request": {
                    "id": "integration_test_003",
                    "type": "task_assignment",
                    "task_description": "å®ç°æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–ï¼Œæå‡æŸ¥è¯¢æ€§èƒ½",
                    "context": {"database": "postgresql", "performance_target": "50%"}
                }
            }
        ]
        
        for test_case in test_cases:
            try:
                integrated_result = self.support_system.provide_integrated_support(
                    test_case["request"]
                )
                
                test_result = {
                    "test_name": test_case["name"],
                    "success": True,
                    "integration": {
                        "request_id": integrated_result["request_id"],
                        "has_error_diagnosis": integrated_result["error_diagnosis"] is not None,
                        "has_task_assignment": integrated_result["task_assignment"] is not None,
                        "has_lifecycle_management": integrated_result["lifecycle_management"] is not None,
                        "recommendations_count": len(integrated_result["integrated_recommendations"]),
                        "next_actions_count": len(integrated_result["next_actions"])
                    },
                    "expectations_met": {
                        "has_recommendations": len(integrated_result["integrated_recommendations"]) > 0,
                        "has_next_actions": len(integrated_result["next_actions"]) > 0,
                        "request_processed": integrated_result["request_id"] == test_case["request"]["id"]
                    }
                }
                
                # éªŒè¯æœŸæœ›ç»“æœ
                all_expectations_met = all(test_result["expectations_met"].values())
                test_result["success"] = all_expectations_met
                
                print(f"  {'âœ…' if test_result['success'] else 'âŒ'} {test_case['name']}: "
                      f"{integrated_result['request_id']} - "
                      f"{len(integrated_result['integrated_recommendations'])}å»ºè®®, "
                      f"{len(integrated_result['next_actions'])}è¡ŒåŠ¨")
                
            except Exception as e:
                test_result = {
                    "test_name": test_case["name"],
                    "success": False,
                    "error": str(e)
                }
                print(f"  âŒ {test_case['name']}: æµ‹è¯•å¤±è´¥ - {e}")
            
            self.test_results["integration_tests"].append(test_result)
    
    def calculate_overall_success(self):
        """è®¡ç®—æ€»ä½“æˆåŠŸç‡"""
        
        all_tests = (
            self.test_results["error_diagnosis_tests"] +
            self.test_results["task_assignment_tests"] +
            self.test_results["lifecycle_management_tests"] +
            self.test_results["integration_tests"]
        )
        
        if not all_tests:
            return False
        
        successful_tests = sum(1 for test in all_tests if test.get("success", False))
        success_rate = successful_tests / len(all_tests)
        
        self.test_results["overall_success"] = success_rate >= 0.9  # 90%æˆåŠŸç‡
        self.test_results["success_rate"] = success_rate
        self.test_results["total_tests"] = len(all_tests)
        self.test_results["successful_tests"] = successful_tests
        
        return self.test_results["overall_success"]
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        
        print("ğŸ§ª å¼€å§‹æ™ºèƒ½å¼€å‘æ”¯æŒåŠŸèƒ½æµ‹è¯•...")
        print("=" * 60)
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.test_error_diagnosis()
        self.test_task_assignment()
        self.test_lifecycle_management()
        self.test_integrated_support()
        
        # è®¡ç®—æ€»ä½“æˆåŠŸç‡
        overall_success = self.calculate_overall_success()
        
        # æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š æ™ºèƒ½å¼€å‘æ”¯æŒåŠŸèƒ½æµ‹è¯•æ‘˜è¦")
        print("=" * 60)
        
        print(f"ğŸ¯ æ€»ä½“æµ‹è¯•ç»“æœ: {'âœ… é€šè¿‡' if overall_success else 'âŒ å¤±è´¥'}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {self.test_results['success_rate']:.1%}")
        print(f"ğŸ“‹ æµ‹è¯•ç»Ÿè®¡: {self.test_results['successful_tests']}/{self.test_results['total_tests']} é€šè¿‡")
        print()
        
        # å„åŠŸèƒ½æ¨¡å—æµ‹è¯•ç»“æœ
        modules = [
            ("é”™è¯¯è¯Šæ–­", "error_diagnosis_tests"),
            ("ä»»åŠ¡åˆ†é…", "task_assignment_tests"),
            ("ç”Ÿå‘½å‘¨æœŸç®¡ç†", "lifecycle_management_tests"),
            ("é›†æˆæ”¯æŒ", "integration_tests")
        ]
        
        print("ğŸ“‹ åŠŸèƒ½æ¨¡å—æµ‹è¯•ç»“æœ:")
        for module_name, module_key in modules:
            module_tests = self.test_results[module_key]
            if module_tests:
                successful = sum(1 for test in module_tests if test.get("success", False))
                total = len(module_tests)
                status = "âœ…" if successful == total else "âš ï¸" if successful > 0 else "âŒ"
                print(f"  {status} {module_name}: {successful}/{total} é€šè¿‡")
        
        print("\n" + "=" * 60)
        
        if overall_success:
            print("ğŸ‰ æ‰€æœ‰æ™ºèƒ½å¼€å‘æ”¯æŒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
            print("ğŸ’ª ç³»ç»Ÿå·²å‡†å¤‡å¥½æä¾›å…¨é¢çš„æ™ºèƒ½å¼€å‘æ”¯æŒ")
        else:
            print("âš ï¸ éƒ¨åˆ†åŠŸèƒ½æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥å’Œä¼˜åŒ–")
        
        return self.test_results

def main():
    """ä¸»å‡½æ•°"""
    
    # åˆ›å»ºåŠŸèƒ½æµ‹è¯•å™¨
    tester = IntelligentSupportFeatureTester()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = tester.run_all_tests()
    
    return results

if __name__ == "__main__":
    main()