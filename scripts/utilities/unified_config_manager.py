#!/usr/bin/env python3
"""
ç»Ÿä¸€é…ç½®ç®¡ç†ç³»ç»Ÿ - ç¡…è°·é¡¹ç›®å¼€å‘ç»ç†è®¾è®¡
ç¡®ä¿æ‰€æœ‰Kiroé…ç½®çš„ä¸€è‡´æ€§ã€åŒæ­¥æ€§å’Œå¯ç»´æŠ¤æ€§
"""

import json
import yaml
import os
import hashlib
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
from dataclasses import dataclass, asdict

@dataclass
class ConfigSource:
    """é…ç½®æºå®šä¹‰"""
    name: str
    path: str
    type: str  # 'json', 'yaml', 'md'
    priority: int
    last_modified: datetime
    checksum: str

@dataclass
class ConfigInconsistency:
    """é…ç½®ä¸ä¸€è‡´æŠ¥å‘Š"""
    source1: str
    source2: str
    field: str
    value1: Any
    value2: Any
    severity: str
    recommendation: str

class UnifiedConfigManager:
    """ç»Ÿä¸€é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, kiro_root: str = ".kiro"):
        self.kiro_root = Path(kiro_root)
        self.logger = self._setup_logger()
        self.config_sources = []
        self.config_cache = {}
        self.sync_status = {}
        
        # åˆå§‹åŒ–é…ç½®æº
        self._discover_config_sources()
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('unified_config_manager')
        logger.setLevel(logging.INFO)
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        
        handler = logging.FileHandler('logs/config_manager.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def _discover_config_sources(self):
        """å‘ç°æ‰€æœ‰é…ç½®æº"""
        config_patterns = [
            # Hooksé…ç½®
            (self.kiro_root / "hooks", "*.kiro.hook", "json", 1),
            # Settingsé…ç½®
            (self.kiro_root / "settings", "*.json", "json", 2),
            # Steeringé…ç½®
            (self.kiro_root / "steering", "*.md", "md", 3),
            # Specsé…ç½®
            (self.kiro_root / "specs", "*.md", "md", 4),
        ]
        
        for base_path, pattern, config_type, priority in config_patterns:
            if base_path.exists():
                for config_file in base_path.rglob(pattern):
                    self._add_config_source(config_file, config_type, priority)
    
    def _add_config_source(self, file_path: Path, config_type: str, priority: int):
        """æ·»åŠ é…ç½®æº"""
        try:
            stat = file_path.stat()
            checksum = self._calculate_file_checksum(file_path)
            
            source = ConfigSource(
                name=file_path.name,
                path=str(file_path),
                type=config_type,
                priority=priority,
                last_modified=datetime.fromtimestamp(stat.st_mtime),
                checksum=checksum
            )
            
            self.config_sources.append(source)
            self.logger.info(f"å‘ç°é…ç½®æº: {source.name}")
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ é…ç½®æºå¤±è´¥ {file_path}: {e}")
    
    def _calculate_file_checksum(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ"""
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()
        except Exception as e:
            self.logger.error(f"è®¡ç®—æ ¡éªŒå’Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    def sync_all_configs(self) -> Dict[str, Any]:
        """åŒæ­¥æ‰€æœ‰é…ç½®"""
        sync_results = {}
        
        for source in self.config_sources:
            try:
                result = self._sync_config_source(source)
                sync_results[source.name] = result
                self.sync_status[source.name] = {
                    'status': 'success',
                    'last_sync': datetime.now(),
                    'checksum': source.checksum
                }
            except Exception as e:
                error_msg = str(e)
                sync_results[source.name] = {
                    'status': 'failed', 
                    'error': error_msg
                }
                self.sync_status[source.name] = {
                    'status': 'failed',
                    'last_sync': datetime.now(),
                    'error': error_msg
                }
                self.logger.error(f"åŒæ­¥é…ç½®å¤±è´¥ {source.name}: {e}")
        
        return sync_results
    
    def _sync_config_source(self, source: ConfigSource) -> Dict[str, Any]:
        """åŒæ­¥å•ä¸ªé…ç½®æº"""
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«ä¿®æ”¹
        current_checksum = self._calculate_file_checksum(Path(source.path))
        if current_checksum != source.checksum:
            self.logger.info(f"æ£€æµ‹åˆ°é…ç½®å˜æ›´: {source.name}")
            source.checksum = current_checksum
            source.last_modified = datetime.now()
        
        # åŠ è½½é…ç½®å†…å®¹
        config_content = self._load_config_content(source)
        self.config_cache[source.name] = config_content
        
        return {
            'status': 'success',
            'checksum': current_checksum,
            'last_modified': source.last_modified.isoformat()
        }
    
    def _load_config_content(self, source: ConfigSource) -> Any:
        """åŠ è½½é…ç½®å†…å®¹"""
        try:
            with open(source.path, 'r', encoding='utf-8') as f:
                if source.type == 'json':
                    return json.load(f)
                elif source.type == 'yaml':
                    return yaml.safe_load(f)
                elif source.type == 'md':
                    return f.read()
                else:
                    return f.read()
        except Exception as e:
            self.logger.error(f"åŠ è½½é…ç½®å†…å®¹å¤±è´¥ {source.path}: {e}")
            return None
    
    def validate_config_consistency(self) -> List[ConfigInconsistency]:
        """éªŒè¯é…ç½®ä¸€è‡´æ€§"""
        inconsistencies = []
        
        # æ£€æŸ¥è§’è‰²å®šä¹‰ä¸€è‡´æ€§
        role_inconsistencies = self._check_role_consistency()
        inconsistencies.extend(role_inconsistencies)
        
        # æ£€æŸ¥æƒé™é…ç½®ä¸€è‡´æ€§
        permission_inconsistencies = self._check_permission_consistency()
        inconsistencies.extend(permission_inconsistencies)
        
        # æ£€æŸ¥Hooké…ç½®ä¸€è‡´æ€§
        hook_inconsistencies = self._check_hook_consistency()
        inconsistencies.extend(hook_inconsistencies)
        
        # æ£€æŸ¥è´¨é‡æ ‡å‡†ä¸€è‡´æ€§
        quality_inconsistencies = self._check_quality_standards_consistency()
        inconsistencies.extend(quality_inconsistencies)
        
        return inconsistencies
    
    def _check_role_consistency(self) -> List[ConfigInconsistency]:
        """æ£€æŸ¥è§’è‰²å®šä¹‰ä¸€è‡´æ€§"""
        inconsistencies = []
        
        # ä»ä¸åŒé…ç½®æºæå–è§’è‰²å®šä¹‰
        role_sources = {}
        
        # ä»steeringé…ç½®æå–è§’è‰²
        for source_name, content in self.config_cache.items():
            if 'steering' in source_name and isinstance(content, str):
                roles = self._extract_roles_from_markdown(content)
                if roles:
                    role_sources[source_name] = roles
        
        # ä»æƒé™çŸ©é˜µæå–è§’è‰²
        for source_name, content in self.config_cache.items():
            if 'role-permission-matrix' in source_name and isinstance(content, str):
                roles = self._extract_roles_from_permission_matrix(content)
                if roles:
                    role_sources[source_name] = roles
        
        # æ¯”è¾ƒè§’è‰²å®šä¹‰
        if len(role_sources) >= 2:
            source_names = list(role_sources.keys())
            for i in range(len(source_names)):
                for j in range(i + 1, len(source_names)):
                    source1, source2 = source_names[i], source_names[j]
                    roles1, roles2 = role_sources[source1], role_sources[source2]
                    
                    # æ£€æŸ¥è§’è‰²æ•°é‡
                    if len(roles1) != len(roles2):
                        inconsistencies.append(ConfigInconsistency(
                            source1=source1,
                            source2=source2,
                            field="role_count",
                            value1=len(roles1),
                            value2=len(roles2),
                            severity="medium",
                            recommendation="ç»Ÿä¸€è§’è‰²æ•°é‡å®šä¹‰"
                        ))
                    
                    # æ£€æŸ¥è§’è‰²åç§°
                    roles1_set = set(roles1)
                    roles2_set = set(roles2)
                    missing_in_source2 = roles1_set - roles2_set
                    missing_in_source1 = roles2_set - roles1_set
                    
                    if missing_in_source2:
                        inconsistencies.append(ConfigInconsistency(
                            source1=source1,
                            source2=source2,
                            field="missing_roles",
                            value1=list(missing_in_source2),
                            value2="not_present",
                            severity="high",
                            recommendation=f"åœ¨{source2}ä¸­æ·»åŠ ç¼ºå¤±è§’è‰²"
                        ))
        
        return inconsistencies
    
    def _extract_roles_from_markdown(self, content: str) -> List[str]:
        """ä»Markdownå†…å®¹æå–è§’è‰²"""
        roles = []
        lines = content.split('\n')
        
        for line in lines:
            # æŸ¥æ‰¾è§’è‰²å®šä¹‰æ¨¡å¼ï¼Œå¦‚ "### 1. ğŸ“Š Product Manager"
            if line.strip().startswith('###') and any(emoji in line for emoji in ['ğŸ“Š', 'ğŸ—ï¸', 'ğŸ§®', 'ğŸ—„ï¸', 'ğŸ¨', 'ğŸš€', 'ğŸ”’', 'â˜ï¸', 'ğŸ“ˆ', 'ğŸ§ª', 'ğŸ¯', 'ğŸ”']):
                # æå–è§’è‰²åç§°
                role_part = line.split('###')[1].strip()
                if '. ' in role_part:
                    role_name = role_part.split('. ', 1)[1].strip()
                    roles.append(role_name)
        
        return roles
    
    def _extract_roles_from_permission_matrix(self, content: str) -> List[str]:
        """ä»æƒé™çŸ©é˜µæå–è§’è‰²"""
        roles = []
        lines = content.split('\n')
        
        for line in lines:
            # æŸ¥æ‰¾æƒé™çŸ©é˜µä¸­çš„è§’è‰²å®šä¹‰
            if line.strip().startswith('### ') and any(emoji in line for emoji in ['ğŸ“Š', 'ğŸ—ï¸', 'ğŸ§®', 'ğŸ—„ï¸', 'ğŸ¨', 'ğŸš€', 'ğŸ”’', 'â˜ï¸', 'ğŸ“ˆ', 'ğŸ§ª', 'ğŸ¯', 'ğŸ”']):
                role_name = line.replace('### ', '').strip()
                roles.append(role_name)
        
        return roles
    
    def _check_permission_consistency(self) -> List[ConfigInconsistency]:
        """æ£€æŸ¥æƒé™é…ç½®ä¸€è‡´æ€§"""
        inconsistencies = []
        
        # ä»MCPé…ç½®å’Œæƒé™çŸ©é˜µæ£€æŸ¥æƒé™ä¸€è‡´æ€§
        mcp_permissions = self._extract_mcp_permissions()
        matrix_permissions = self._extract_matrix_permissions()
        
        if mcp_permissions and matrix_permissions:
            # æ£€æŸ¥æƒé™å·¥å…·åç§°ä¸€è‡´æ€§
            mcp_tools = set(mcp_permissions.get('autoApprove', []))
            matrix_operations = set()
            
            for role_perms in matrix_permissions.values():
                matrix_operations.update(role_perms.get('allowed_operations', []))
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„æƒé™ä¸€è‡´æ€§æ£€æŸ¥
            
        return inconsistencies
    
    def _extract_mcp_permissions(self) -> Optional[Dict]:
        """æå–MCPæƒé™é…ç½®"""
        for source_name, content in self.config_cache.items():
            if 'mcp.json' in source_name and isinstance(content, dict):
                return content
        return None
    
    def _extract_matrix_permissions(self) -> Optional[Dict]:
        """æå–æƒé™çŸ©é˜µé…ç½®"""
        # è¿™é‡Œéœ€è¦è§£ææƒé™çŸ©é˜µMarkdownæ–‡ä»¶
        # å®ç°å…·ä½“çš„è§£æé€»è¾‘
        return None
    
    def _check_hook_consistency(self) -> List[ConfigInconsistency]:
        """æ£€æŸ¥Hooké…ç½®ä¸€è‡´æ€§"""
        inconsistencies = []
        
        hook_configs = {}
        for source_name, content in self.config_cache.items():
            if source_name.endswith('.kiro.hook') and isinstance(content, dict):
                hook_configs[source_name] = content
        
        # æ£€æŸ¥Hookç‰ˆæœ¬ä¸€è‡´æ€§
        versions = {}
        for hook_name, config in hook_configs.items():
            version = config.get('version', 'unknown')
            if version not in versions:
                versions[version] = []
            versions[version].append(hook_name)
        
        # å¦‚æœæœ‰å¤šä¸ªç‰ˆæœ¬ï¼ŒæŠ¥å‘Šä¸ä¸€è‡´
        if len(versions) > 1:
            inconsistencies.append(ConfigInconsistency(
                source1="multiple_hooks",
                source2="version_mismatch",
                field="version",
                value1=list(versions.keys()),
                value2="should_be_consistent",
                severity="medium",
                recommendation="ç»Ÿä¸€Hookç‰ˆæœ¬å·"
            ))
        
        return inconsistencies
    
    def _check_quality_standards_consistency(self) -> List[ConfigInconsistency]:
        """æ£€æŸ¥è´¨é‡æ ‡å‡†ä¸€è‡´æ€§"""
        inconsistencies = []
        
        # ä»ä¸åŒé…ç½®æºæå–è´¨é‡æ ‡å‡†
        quality_sources = {}
        
        # ä»LLMè¡Œä¸ºçº¦æŸé…ç½®æå–
        for source_name, content in self.config_cache.items():
            if 'llm-behavior-constraints.json' in source_name and isinstance(content, dict):
                quality_thresholds = content.get('quality_thresholds', {})
                if quality_thresholds:
                    quality_sources[source_name] = quality_thresholds
        
        # ä»å…¶ä»–é…ç½®æºæå–è´¨é‡æ ‡å‡†
        # å¯ä»¥æ·»åŠ æ›´å¤šæºçš„æ£€æŸ¥
        
        return inconsistencies
    
    def generate_consistency_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š"""
        inconsistencies = self.validate_config_consistency()
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        by_severity = {'critical': [], 'high': [], 'medium': [], 'low': []}
        for inconsistency in inconsistencies:
            severity = inconsistency.severity
            if severity in by_severity:
                by_severity[severity].append(asdict(inconsistency))
        
        # ç”Ÿæˆæ‘˜è¦
        summary = {
            'total_inconsistencies': len(inconsistencies),
            'by_severity': {k: len(v) for k, v in by_severity.items()},
            'config_sources_count': len(self.config_sources),
            'last_sync_status': self.sync_status
        }
        
        return {
            'timestamp': datetime.now().isoformat(),
            'summary': summary,
            'inconsistencies': by_severity,
            'recommendations': self._generate_recommendations(inconsistencies)
        }
    
    def _generate_recommendations(self, inconsistencies: List[ConfigInconsistency]) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        recommendations = []
        
        # æŒ‰é—®é¢˜ç±»å‹åˆ†ç»„å¹¶ç”Ÿæˆå»ºè®®
        role_issues = [i for i in inconsistencies if 'role' in i.field]
        if role_issues:
            recommendations.append("ç»Ÿä¸€æ‰€æœ‰é…ç½®æ–‡ä»¶ä¸­çš„è§’è‰²å®šä¹‰")
        
        permission_issues = [i for i in inconsistencies if 'permission' in i.field]
        if permission_issues:
            recommendations.append("åŒæ­¥MCPé…ç½®å’Œæƒé™çŸ©é˜µä¸­çš„æƒé™å®šä¹‰")
        
        version_issues = [i for i in inconsistencies if 'version' in i.field]
        if version_issues:
            recommendations.append("ç»Ÿä¸€æ‰€æœ‰Hooké…ç½®çš„ç‰ˆæœ¬å·")
        
        return recommendations
    
    def auto_fix_inconsistencies(self, inconsistencies: List[ConfigInconsistency]) -> Dict[str, Any]:
        """è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´é—®é¢˜"""
        fix_results = {}
        
        for inconsistency in inconsistencies:
            try:
                if inconsistency.severity in ['low', 'medium']:
                    # åªè‡ªåŠ¨ä¿®å¤ä½é£é™©é—®é¢˜
                    result = self._apply_auto_fix(inconsistency)
                    fix_results[f"{inconsistency.source1}_{inconsistency.field}"] = result
                else:
                    fix_results[f"{inconsistency.source1}_{inconsistency.field}"] = {
                        'status': 'skipped',
                        'reason': 'high_risk_requires_manual_review'
                    }
            except Exception as e:
                fix_results[f"{inconsistency.source1}_{inconsistency.field}"] = {
                    'status': 'failed',
                    'error': str(e)
                }
        
        return fix_results
    
    def _apply_auto_fix(self, inconsistency: ConfigInconsistency) -> Dict[str, Any]:
        """åº”ç”¨è‡ªåŠ¨ä¿®å¤"""
        # å®ç°å…·ä½“çš„è‡ªåŠ¨ä¿®å¤é€»è¾‘
        # è¿™é‡Œåªæ˜¯ç¤ºä¾‹æ¡†æ¶
        return {
            'status': 'success',
            'action': 'auto_fixed',
            'details': inconsistency.recommendation
        }
    
    def backup_configs(self) -> str:
        """å¤‡ä»½æ‰€æœ‰é…ç½®"""
        backup_dir = Path('backups') / f"config_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        for source in self.config_sources:
            try:
                source_path = Path(source.path)
                backup_path = backup_dir / source_path.name
                
                # å¤åˆ¶æ–‡ä»¶
                import shutil
                shutil.copy2(source_path, backup_path)
                
                self.logger.info(f"å¤‡ä»½é…ç½®æ–‡ä»¶: {source.name} -> {backup_path}")
                
            except Exception as e:
                self.logger.error(f"å¤‡ä»½å¤±è´¥ {source.name}: {e}")
        
        return str(backup_dir)

def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œå‘½ä»¤è¡Œä½¿ç”¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€é…ç½®ç®¡ç†ç³»ç»Ÿ')
    parser.add_argument('--sync', action='store_true', help='åŒæ­¥æ‰€æœ‰é…ç½®')
    parser.add_argument('--validate', action='store_true', help='éªŒè¯é…ç½®ä¸€è‡´æ€§')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š')
    parser.add_argument('--backup', action='store_true', help='å¤‡ä»½æ‰€æœ‰é…ç½®')
    parser.add_argument('--auto-fix', action='store_true', help='è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´é—®é¢˜')
    
    args = parser.parse_args()
    
    manager = UnifiedConfigManager()
    
    if args.sync:
        print("åŒæ­¥æ‰€æœ‰é…ç½®...")
        results = manager.sync_all_configs()
        print(json.dumps(results, indent=2, ensure_ascii=False))
    
    if args.validate:
        print("éªŒè¯é…ç½®ä¸€è‡´æ€§...")
        inconsistencies = manager.validate_config_consistency()
        print(f"å‘ç° {len(inconsistencies)} ä¸ªä¸ä¸€è‡´é—®é¢˜")
        for inc in inconsistencies:
            print(f"- {inc.severity}: {inc.field} ({inc.source1} vs {inc.source2})")
    
    if args.report:
        print("ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š...")
        report = manager.generate_consistency_report()
        print(json.dumps(report, indent=2, ensure_ascii=False))
    
    if args.backup:
        print("å¤‡ä»½æ‰€æœ‰é…ç½®...")
        backup_path = manager.backup_configs()
        print(f"é…ç½®å·²å¤‡ä»½åˆ°: {backup_path}")
    
    if args.auto_fix:
        print("è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´é—®é¢˜...")
        inconsistencies = manager.validate_config_consistency()
        fix_results = manager.auto_fix_inconsistencies(inconsistencies)
        print(json.dumps(fix_results, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()