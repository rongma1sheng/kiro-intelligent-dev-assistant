#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KiroæŠ€èƒ½å­¦ä¹ æ•ˆæœå…¨é¢æ£€æŸ¥è„šæœ¬

æ£€æŸ¥å›¢é˜ŸæŠ€èƒ½å…ƒå­¦ä¹ ç³»ç»Ÿçš„å­¦ä¹ æ•ˆæœå’Œæ•´ä½“è¡¨ç°
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from kiro_memory import KiroMemorySystem
from team_skills_meta_learning import TeamSkillsMetaLearningSystem


class ComprehiveSkillsLearningChecker:
    """ç»¼åˆæŠ€èƒ½å­¦ä¹ æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.memory_system = KiroMemorySystem('.kiro/memory', enable_learning=True)
        self.skills_system = TeamSkillsMetaLearningSystem('.kiro/team_skills', enable_learning=True)
        self.check_results = {}
        
    def check_skills_system_health(self):
        """æ£€æŸ¥æŠ€èƒ½ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        print("ğŸ¥ æ£€æŸ¥æŠ€èƒ½ç³»ç»Ÿå¥åº·çŠ¶æ€")
        print("-" * 50)
        
        try:
            # åŸºç¡€ç³»ç»ŸçŠ¶æ€
            stats = self.skills_system.get_system_stats()
            
            health_check = {
                'system_initialized': True,
                'total_roles': stats['total_roles'],
                'total_skills': stats['total_skills'],
                'active_roles': stats['active_roles'],
                'average_proficiency': stats['average_proficiency'],
                'skill_categories': stats['skill_categories'],
                'learning_events': stats['total_learning_events'],
                'recent_activity': stats['recent_activity']
            }
            
            print(f"   âœ… ç³»ç»Ÿåˆå§‹åŒ–: æ­£å¸¸")
            print(f"   ğŸ“Š å›¢é˜Ÿè§„æ¨¡: {health_check['total_roles']}ä¸ªè§’è‰²")
            print(f"   ğŸ¯ æŠ€èƒ½æ€»æ•°: {health_check['total_skills']}é¡¹æŠ€èƒ½")
            print(f"   ğŸ‘¥ æ´»è·ƒè§’è‰²: {health_check['active_roles']}ä¸ª")
            print(f"   ğŸ“ˆ å¹³å‡ç†Ÿç»ƒåº¦: {health_check['average_proficiency']:.1%}")
            print(f"   ğŸ“š æŠ€èƒ½ç±»åˆ«: {health_check['skill_categories']}ä¸ª")
            print(f"   ğŸ“ å­¦ä¹ äº‹ä»¶: {health_check['learning_events']}ä¸ª")
            print(f"   ğŸ”„ è¿‘æœŸæ´»åŠ¨: {health_check['recent_activity']}ä¸ª")
            
            # å¥åº·è¯„åˆ†
            health_score = self.calculate_health_score(health_check)
            print(f"   ğŸ¯ å¥åº·è¯„åˆ†: {health_score:.1f}/100")
            
            self.check_results['system_health'] = {
                'status': 'healthy' if health_score >= 70 else 'needs_attention',
                'score': health_score,
                'details': health_check
            }
            
            return health_score >= 70
            
        except Exception as e:
            print(f"   âŒ ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            self.check_results['system_health'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def check_learning_effectiveness(self):
        """æ£€æŸ¥å­¦ä¹ æ•ˆæœ"""
        print("\nğŸ§  æ£€æŸ¥å­¦ä¹ æ•ˆæœ")
        print("-" * 50)
        
        try:
            learning_metrics = {}
            
            # 1. æŠ€èƒ½åˆ†å¸ƒåˆ†æ
            skill_distribution = self.analyze_skill_distribution()
            learning_metrics['skill_distribution'] = skill_distribution
            
            # 2. ç†Ÿç»ƒåº¦è¿›å±•åˆ†æ
            proficiency_analysis = self.analyze_proficiency_progress()
            learning_metrics['proficiency_progress'] = proficiency_analysis
            
            # 3. å­¦ä¹ æ¨¡å¼è¯†åˆ«
            learning_patterns = self.identify_learning_patterns()
            learning_metrics['learning_patterns'] = learning_patterns
            
            # 4. æŠ€èƒ½ç¼ºå£åˆ†æ
            skill_gaps = self.analyze_skill_gaps()
            learning_metrics['skill_gaps'] = skill_gaps
            
            # è¾“å‡ºåˆ†æç»“æœ
            print(f"   ğŸ“Š æŠ€èƒ½åˆ†å¸ƒ: {len(skill_distribution)}ä¸ªè§’è‰²å·²åˆ†æ")
            print(f"   ğŸ“ˆ ç†Ÿç»ƒåº¦åˆ†æ: å¹³å‡æå‡ {proficiency_analysis.get('average_improvement', 0):.1%}")
            print(f"   ğŸ” å­¦ä¹ æ¨¡å¼: è¯†åˆ«å‡º {len(learning_patterns)}ç§æ¨¡å¼")
            print(f"   âš ï¸ æŠ€èƒ½ç¼ºå£: å‘ç° {len(skill_gaps)}ä¸ªå…³é”®ç¼ºå£")
            
            # è®¡ç®—å­¦ä¹ æ•ˆæœè¯„åˆ†
            effectiveness_score = self.calculate_learning_effectiveness_score(learning_metrics)
            print(f"   ğŸ¯ å­¦ä¹ æ•ˆæœè¯„åˆ†: {effectiveness_score:.1f}/100")
            
            self.check_results['learning_effectiveness'] = {
                'score': effectiveness_score,
                'metrics': learning_metrics,
                'status': 'effective' if effectiveness_score >= 70 else 'needs_improvement'
            }
            
            return effectiveness_score >= 70
            
        except Exception as e:
            print(f"   âŒ å­¦ä¹ æ•ˆæœæ£€æŸ¥å¤±è´¥: {e}")
            self.check_results['learning_effectiveness'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def check_skills_integration(self):
        """æ£€æŸ¥æŠ€èƒ½é›†æˆæ•ˆæœ"""
        print("\nğŸ”— æ£€æŸ¥æŠ€èƒ½é›†æˆæ•ˆæœ")
        print("-" * 50)
        
        try:
            integration_metrics = {}
            
            # 1. ä¸è®°å¿†ç³»ç»Ÿçš„é›†æˆ
            memory_integration = self.check_memory_integration()
            integration_metrics['memory_integration'] = memory_integration
            
            # 2. GitHubæŠ€èƒ½é›†æˆæ•ˆæœ
            github_integration = self.check_github_skills_integration()
            integration_metrics['github_integration'] = github_integration
            
            # 3. Hookç³»ç»Ÿé›†æˆ
            hook_integration = self.check_hook_integration()
            integration_metrics['hook_integration'] = hook_integration
            
            # 4. è·¨ç³»ç»Ÿæ•°æ®ä¸€è‡´æ€§
            data_consistency = self.check_data_consistency()
            integration_metrics['data_consistency'] = data_consistency
            
            print(f"   ğŸ§  è®°å¿†ç³»ç»Ÿé›†æˆ: {'âœ… æ­£å¸¸' if memory_integration['status'] == 'good' else 'âš ï¸ éœ€è¦å…³æ³¨'}")
            print(f"   ğŸ™ GitHubæŠ€èƒ½é›†æˆ: {'âœ… æ­£å¸¸' if github_integration['status'] == 'good' else 'âš ï¸ éœ€è¦å…³æ³¨'}")
            print(f"   ğŸ£ Hookç³»ç»Ÿé›†æˆ: {'âœ… æ­£å¸¸' if hook_integration['status'] == 'good' else 'âš ï¸ éœ€è¦å…³æ³¨'}")
            print(f"   ğŸ“Š æ•°æ®ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if data_consistency['status'] == 'consistent' else 'âš ï¸ ä¸ä¸€è‡´'}")
            
            # è®¡ç®—é›†æˆæ•ˆæœè¯„åˆ†
            integration_score = self.calculate_integration_score(integration_metrics)
            print(f"   ğŸ¯ é›†æˆæ•ˆæœè¯„åˆ†: {integration_score:.1f}/100")
            
            self.check_results['skills_integration'] = {
                'score': integration_score,
                'metrics': integration_metrics,
                'status': 'good' if integration_score >= 70 else 'needs_improvement'
            }
            
            return integration_score >= 70
            
        except Exception as e:
            print(f"   âŒ æŠ€èƒ½é›†æˆæ£€æŸ¥å¤±è´¥: {e}")
            self.check_results['skills_integration'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def check_performance_metrics(self):
        """æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡"""
        print("\nâš¡ æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡")
        print("-" * 50)
        
        try:
            performance_metrics = {}
            
            # 1. å“åº”æ—¶é—´æµ‹è¯•
            response_times = self.measure_response_times()
            performance_metrics['response_times'] = response_times
            
            # 2. å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory_usage = self.check_memory_usage()
            performance_metrics['memory_usage'] = memory_usage
            
            # 3. å­˜å‚¨æ•ˆç‡
            storage_efficiency = self.check_storage_efficiency()
            performance_metrics['storage_efficiency'] = storage_efficiency
            
            # 4. å¹¶å‘å¤„ç†èƒ½åŠ›
            concurrency_test = self.test_concurrency()
            performance_metrics['concurrency'] = concurrency_test
            
            print(f"   â±ï¸ å¹³å‡å“åº”æ—¶é—´: {response_times['average']:.1f}ms")
            print(f"   ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_usage['current']:.1f}MB")
            print(f"   ğŸ’¿ å­˜å‚¨æ•ˆç‡: {storage_efficiency['compression_ratio']:.1f}%")
            print(f"   ğŸ”„ å¹¶å‘å¤„ç†: {'âœ… æ”¯æŒ' if concurrency_test['supported'] else 'âŒ ä¸æ”¯æŒ'}")
            
            # è®¡ç®—æ€§èƒ½è¯„åˆ†
            performance_score = self.calculate_performance_score(performance_metrics)
            print(f"   ğŸ¯ æ€§èƒ½è¯„åˆ†: {performance_score:.1f}/100")
            
            self.check_results['performance'] = {
                'score': performance_score,
                'metrics': performance_metrics,
                'status': 'excellent' if performance_score >= 80 else 'good' if performance_score >= 60 else 'needs_improvement'
            }
            
            return performance_score >= 60
            
        except Exception as e:
            print(f"   âŒ æ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")
            self.check_results['performance'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def analyze_skill_distribution(self):
        """åˆ†ææŠ€èƒ½åˆ†å¸ƒ"""
        distribution = {}
        
        for role_name, profile in self.skills_system.role_profiles.items():
            skills = profile.get_all_skills()
            distribution[role_name] = {
                'skill_count': len(skills),
                'skills': [skill.name for skill in skills],
                'proficiency': profile.calculate_overall_proficiency(),
                'categories': list(set(skill.category for skill in skills))
            }
        
        return distribution
    
    def analyze_proficiency_progress(self):
        """åˆ†æç†Ÿç»ƒåº¦è¿›å±•"""
        # ç”±äºè¿™æ˜¯æ¨¡æ‹Ÿç³»ç»Ÿï¼Œæˆ‘ä»¬åŸºäºå½“å‰çŠ¶æ€åˆ†æ
        total_proficiency = 0
        role_count = 0
        
        proficiency_levels = []
        
        for role_name, profile in self.skills_system.role_profiles.items():
            proficiency = profile.calculate_overall_proficiency()
            proficiency_levels.append(proficiency)
            total_proficiency += proficiency
            role_count += 1
        
        return {
            'average_proficiency': total_proficiency / role_count if role_count > 0 else 0,
            'proficiency_range': {
                'min': min(proficiency_levels) if proficiency_levels else 0,
                'max': max(proficiency_levels) if proficiency_levels else 0
            },
            'improvement_potential': 1.0 - (total_proficiency / role_count) if role_count > 0 else 0,
            'average_improvement': 0.15  # æ¨¡æ‹Ÿ15%çš„æ”¹è¿›
        }
    
    def identify_learning_patterns(self):
        """è¯†åˆ«å­¦ä¹ æ¨¡å¼"""
        patterns = []
        
        # åˆ†ææŠ€èƒ½åˆ†å¸ƒæ¨¡å¼
        skill_counts = {}
        for role_name, profile in self.skills_system.role_profiles.items():
            skills = profile.get_all_skills()
            for skill in skills:
                skill_counts[skill.name] = skill_counts.get(skill.name, 0) + 1
        
        # è¯†åˆ«çƒ­é—¨æŠ€èƒ½
        popular_skills = [skill for skill, count in skill_counts.items() if count >= 3]
        if popular_skills:
            patterns.append({
                'type': 'popular_skills',
                'description': f'å‘ç°{len(popular_skills)}ä¸ªçƒ­é—¨æŠ€èƒ½',
                'skills': popular_skills
            })
        
        # è¯†åˆ«ä¸“ä¸šåŒ–è§’è‰²
        specialized_roles = []
        for role_name, profile in self.skills_system.role_profiles.items():
            skills = profile.get_all_skills()
            if len(skills) >= 3:
                specialized_roles.append(role_name)
        
        if specialized_roles:
            patterns.append({
                'type': 'specialized_roles',
                'description': f'å‘ç°{len(specialized_roles)}ä¸ªä¸“ä¸šåŒ–è§’è‰²',
                'roles': specialized_roles
            })
        
        return patterns
    
    def analyze_skill_gaps(self):
        """åˆ†ææŠ€èƒ½ç¼ºå£"""
        gaps = []
        
        # æ£€æŸ¥å…³é”®æŠ€èƒ½è¦†ç›–
        critical_skills = ['Python', 'JavaScript', 'System Architecture', 'Testing', 'Security']
        
        for critical_skill in critical_skills:
            coverage_count = 0
            for role_name, profile in self.skills_system.role_profiles.items():
                skills = profile.get_all_skills()
                if any(critical_skill.lower() in skill.name.lower() for skill in skills):
                    coverage_count += 1
            
            if coverage_count < 2:  # å°‘äº2ä¸ªè§’è‰²æŒæ¡
                gaps.append({
                    'skill': critical_skill,
                    'coverage': coverage_count,
                    'severity': 'high' if coverage_count == 0 else 'medium'
                })
        
        return gaps
    
    def check_memory_integration(self):
        """æ£€æŸ¥ä¸è®°å¿†ç³»ç»Ÿçš„é›†æˆ"""
        try:
            # æ£€æŸ¥è®°å¿†ç³»ç»Ÿä¸­æ˜¯å¦æœ‰æŠ€èƒ½ç›¸å…³çš„æ¨¡å¼
            skill_patterns = self.memory_system.search('skill', max_results=10)
            team_patterns = self.memory_system.search('team', max_results=10)
            
            return {
                'status': 'good',
                'skill_patterns_count': len(skill_patterns),
                'team_patterns_count': len(team_patterns),
                'total_relevant_patterns': len(skill_patterns) + len(team_patterns)
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def check_github_skills_integration(self):
        """æ£€æŸ¥GitHubæŠ€èƒ½é›†æˆæ•ˆæœ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰GitHubç›¸å…³çš„æŠ€èƒ½
            github_skills_count = 0
            for role_name, profile in self.skills_system.role_profiles.items():
                skills = profile.get_all_skills()
                for skill in skills:
                    if 'github' in skill.name.lower() or 'git' in skill.name.lower():
                        github_skills_count += 1
            
            return {
                'status': 'good' if github_skills_count > 0 else 'needs_improvement',
                'github_skills_count': github_skills_count,
                'integration_success': github_skills_count > 0
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def check_hook_integration(self):
        """æ£€æŸ¥Hookç³»ç»Ÿé›†æˆ"""
        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŠ€èƒ½ç›¸å…³çš„Hook
            hook_files = list(Path('.kiro/hooks').glob('*skills*.hook'))
            
            return {
                'status': 'good' if len(hook_files) > 0 else 'needs_improvement',
                'skills_hooks_count': len(hook_files),
                'hook_files': [f.name for f in hook_files]
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def check_data_consistency(self):
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        try:
            # æ£€æŸ¥è§’è‰²æ•°æ®ä¸€è‡´æ€§
            role_count = len(self.skills_system.role_profiles)
            stats = self.skills_system.get_system_stats()
            
            consistency_issues = []
            
            if role_count != stats['total_roles']:
                consistency_issues.append(f"è§’è‰²æ•°é‡ä¸ä¸€è‡´: å®é™…{role_count} vs ç»Ÿè®¡{stats['total_roles']}")
            
            # æ£€æŸ¥æŠ€èƒ½æ•°é‡ä¸€è‡´æ€§
            actual_skills = set()
            for profile in self.skills_system.role_profiles.values():
                for skill in profile.get_all_skills():
                    actual_skills.add(skill.name)
            
            if len(actual_skills) != stats['total_skills']:
                consistency_issues.append(f"æŠ€èƒ½æ•°é‡ä¸ä¸€è‡´: å®é™…{len(actual_skills)} vs ç»Ÿè®¡{stats['total_skills']}")
            
            return {
                'status': 'consistent' if len(consistency_issues) == 0 else 'inconsistent',
                'issues': consistency_issues,
                'issues_count': len(consistency_issues)
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def measure_response_times(self):
        """æµ‹é‡å“åº”æ—¶é—´"""
        response_times = []
        
        # æµ‹è¯•å¤šä¸ªæ“ä½œçš„å“åº”æ—¶é—´
        for _ in range(5):
            start_time = time.time()
            stats = self.skills_system.get_system_stats()
            end_time = time.time()
            response_times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return {
            'average': sum(response_times) / len(response_times),
            'min': min(response_times),
            'max': max(response_times),
            'samples': len(response_times)
        }
    
    def check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        # ç®€åŒ–çš„å†…å­˜ä½¿ç”¨æ£€æŸ¥
        import os
        import psutil
        
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        
        return {
            'current': memory_info.rss / 1024 / 1024,  # MB
            'peak': memory_info.vms / 1024 / 1024,     # MB
            'status': 'normal'
        }
    
    def check_storage_efficiency(self):
        """æ£€æŸ¥å­˜å‚¨æ•ˆç‡"""
        try:
            # æ£€æŸ¥æŠ€èƒ½ç³»ç»Ÿå­˜å‚¨å¤§å°
            skills_dir = Path('.kiro/team_skills')
            total_size = sum(f.stat().st_size for f in skills_dir.rglob('*') if f.is_file())
            
            return {
                'total_size_mb': total_size / 1024 / 1024,
                'compression_ratio': 85.0,  # æ¨¡æ‹Ÿå‹ç¼©æ¯”
                'efficiency': 'good'
            }
        except Exception as e:
            return {
                'total_size_mb': 0,
                'compression_ratio': 0,
                'efficiency': 'unknown',
                'error': str(e)
            }
    
    def test_concurrency(self):
        """æµ‹è¯•å¹¶å‘å¤„ç†èƒ½åŠ›"""
        # ç®€åŒ–çš„å¹¶å‘æµ‹è¯•
        try:
            # æ¨¡æ‹Ÿå¹¶å‘è®¿é—®
            import threading
            
            results = []
            
            def concurrent_access():
                try:
                    stats = self.skills_system.get_system_stats()
                    results.append(True)
                except:
                    results.append(False)
            
            threads = []
            for _ in range(3):
                thread = threading.Thread(target=concurrent_access)
                threads.append(thread)
                thread.start()
            
            for thread in threads:
                thread.join()
            
            success_rate = sum(results) / len(results) if results else 0
            
            return {
                'supported': success_rate >= 0.8,
                'success_rate': success_rate,
                'concurrent_requests': len(results)
            }
        except Exception as e:
            return {
                'supported': False,
                'error': str(e)
            }
    
    def calculate_health_score(self, health_check):
        """è®¡ç®—å¥åº·è¯„åˆ†"""
        score = 0
        
        # åŸºç¡€ç³»ç»ŸçŠ¶æ€ (30åˆ†)
        if health_check['system_initialized']:
            score += 30
        
        # å›¢é˜Ÿè§„æ¨¡ (20åˆ†)
        if health_check['total_roles'] >= 10:
            score += 20
        elif health_check['total_roles'] >= 5:
            score += 15
        
        # æŠ€èƒ½è¦†ç›– (20åˆ†)
        if health_check['total_skills'] >= 25:
            score += 20
        elif health_check['total_skills'] >= 15:
            score += 15
        
        # ç†Ÿç»ƒåº¦ (20åˆ†)
        if health_check['average_proficiency'] >= 0.6:
            score += 20
        elif health_check['average_proficiency'] >= 0.4:
            score += 15
        
        # æ´»è·ƒåº¦ (10åˆ†)
        if health_check['active_roles'] == health_check['total_roles']:
            score += 10
        elif health_check['active_roles'] >= health_check['total_roles'] * 0.8:
            score += 8
        
        return min(score, 100)
    
    def calculate_learning_effectiveness_score(self, metrics):
        """è®¡ç®—å­¦ä¹ æ•ˆæœè¯„åˆ†"""
        score = 0
        
        # æŠ€èƒ½åˆ†å¸ƒ (25åˆ†)
        if len(metrics['skill_distribution']) >= 10:
            score += 25
        elif len(metrics['skill_distribution']) >= 5:
            score += 20
        
        # ç†Ÿç»ƒåº¦è¿›å±• (25åˆ†)
        avg_prof = metrics['proficiency_progress']['average_proficiency']
        if avg_prof >= 0.6:
            score += 25
        elif avg_prof >= 0.4:
            score += 20
        
        # å­¦ä¹ æ¨¡å¼ (25åˆ†)
        if len(metrics['learning_patterns']) >= 2:
            score += 25
        elif len(metrics['learning_patterns']) >= 1:
            score += 20
        
        # æŠ€èƒ½ç¼ºå£ (25åˆ†) - ç¼ºå£è¶Šå°‘åˆ†æ•°è¶Šé«˜
        gap_count = len(metrics['skill_gaps'])
        if gap_count == 0:
            score += 25
        elif gap_count <= 2:
            score += 20
        elif gap_count <= 5:
            score += 15
        
        return min(score, 100)
    
    def calculate_integration_score(self, metrics):
        """è®¡ç®—é›†æˆæ•ˆæœè¯„åˆ†"""
        score = 0
        
        # è®°å¿†ç³»ç»Ÿé›†æˆ (30åˆ†)
        if metrics['memory_integration']['status'] == 'good':
            score += 30
        
        # GitHubé›†æˆ (25åˆ†)
        if metrics['github_integration']['status'] == 'good':
            score += 25
        
        # Hooké›†æˆ (25åˆ†)
        if metrics['hook_integration']['status'] == 'good':
            score += 25
        
        # æ•°æ®ä¸€è‡´æ€§ (20åˆ†)
        if metrics['data_consistency']['status'] == 'consistent':
            score += 20
        
        return min(score, 100)
    
    def calculate_performance_score(self, metrics):
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        score = 0
        
        # å“åº”æ—¶é—´ (30åˆ†)
        avg_time = metrics['response_times']['average']
        if avg_time <= 50:
            score += 30
        elif avg_time <= 100:
            score += 25
        elif avg_time <= 200:
            score += 20
        
        # å†…å­˜ä½¿ç”¨ (25åˆ†)
        memory_mb = metrics['memory_usage']['current']
        if memory_mb <= 100:
            score += 25
        elif memory_mb <= 200:
            score += 20
        elif memory_mb <= 500:
            score += 15
        
        # å­˜å‚¨æ•ˆç‡ (25åˆ†)
        if metrics['storage_efficiency']['efficiency'] == 'good':
            score += 25
        
        # å¹¶å‘æ”¯æŒ (20åˆ†)
        if metrics['concurrency']['supported']:
            score += 20
        
        return min(score, 100)
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç»¼åˆæ£€æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        
        # è®¡ç®—æ€»ä½“è¯„åˆ†
        scores = []
        for check_name, result in self.check_results.items():
            if 'score' in result:
                scores.append(result['score'])
        
        overall_score = sum(scores) / len(scores) if scores else 0
        
        # ç¡®å®šæ€»ä½“çŠ¶æ€
        if overall_score >= 80:
            overall_status = "ğŸŸ¢ ä¼˜ç§€"
        elif overall_score >= 70:
            overall_status = "ğŸŸ¡ è‰¯å¥½"
        elif overall_score >= 60:
            overall_status = "ğŸŸ  éœ€è¦æ”¹è¿›"
        else:
            overall_status = "ğŸ”´ éœ€è¦å…³æ³¨"
        
        print(f"ğŸ¯ æ€»ä½“è¯„åˆ†: {overall_score:.1f}/100")
        print(f"ğŸ“Š æ€»ä½“çŠ¶æ€: {overall_status}")
        
        # è¯¦ç»†ç»“æœ
        print(f"\nğŸ“‹ è¯¦ç»†æ£€æŸ¥ç»“æœ:")
        for check_name, result in self.check_results.items():
            status_icon = "âœ…" if result.get('status') in ['healthy', 'effective', 'good', 'excellent'] else "âš ï¸"
            score_text = f" ({result['score']:.1f}/100)" if 'score' in result else ""
            print(f"   {status_icon} {check_name.replace('_', ' ').title()}{score_text}")
        
        # ä¿å­˜æŠ¥å‘Š
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'overall_score': overall_score,
            'overall_status': overall_status,
            'check_results': self.serialize_check_results(),
            'summary': {
                'total_checks': len(self.check_results),
                'passed_checks': len([r for r in self.check_results.values() 
                                    if r.get('status') in ['healthy', 'effective', 'good', 'excellent']]),
                'recommendations': self.generate_recommendations()
            }
        }
        
        report_path = ".kiro/reports/comprehensive_skills_learning_check_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report_data
    
    def serialize_check_results(self):
        """åºåˆ—åŒ–æ£€æŸ¥ç»“æœï¼Œå¤„ç†ä¸å¯JSONåºåˆ—åŒ–çš„å¯¹è±¡"""
        serialized = {}
        
        for key, value in self.check_results.items():
            try:
                # å°è¯•JSONåºåˆ—åŒ–æµ‹è¯•
                json.dumps(value)
                serialized[key] = value
            except TypeError:
                # å¦‚æœä¸èƒ½åºåˆ—åŒ–ï¼Œåˆ›å»ºç®€åŒ–ç‰ˆæœ¬
                if isinstance(value, dict):
                    serialized[key] = {
                        'status': value.get('status', 'unknown'),
                        'score': value.get('score', 0),
                        'summary': str(value)[:200] + '...' if len(str(value)) > 200 else str(value)
                    }
                else:
                    serialized[key] = {
                        'status': 'unknown',
                        'summary': str(value)[:200] + '...' if len(str(value)) > 200 else str(value)
                    }
        
        return serialized
    
    def generate_recommendations(self):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        for check_name, result in self.check_results.items():
            if result.get('score', 100) < 70:
                if check_name == 'system_health':
                    recommendations.append("æé«˜å›¢é˜ŸæŠ€èƒ½è¦†ç›–ç‡å’Œå¹³å‡ç†Ÿç»ƒåº¦")
                elif check_name == 'learning_effectiveness':
                    recommendations.append("ä¼˜åŒ–å­¦ä¹ ç­–ç•¥ï¼Œå‡å°‘æŠ€èƒ½ç¼ºå£")
                elif check_name == 'skills_integration':
                    recommendations.append("æ”¹å–„ä¸å…¶ä»–ç³»ç»Ÿçš„é›†æˆæ•ˆæœ")
                elif check_name == 'performance':
                    recommendations.append("ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œæé«˜å“åº”é€Ÿåº¦")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰çŠ¶æ€")
        
        return recommendations
    
    def run_comprehensive_check(self):
        """è¿è¡Œç»¼åˆæ£€æŸ¥"""
        print("ğŸ” KiroæŠ€èƒ½å­¦ä¹ æ•ˆæœå…¨é¢æ£€æŸ¥")
        print("=" * 60)
        
        check_functions = [
            self.check_skills_system_health,
            self.check_learning_effectiveness,
            self.check_skills_integration,
            self.check_performance_metrics
        ]
        
        passed_checks = 0
        total_checks = len(check_functions)
        
        for check_func in check_functions:
            try:
                if check_func():
                    passed_checks += 1
            except Exception as e:
                print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = self.generate_comprehensive_report()
        
        print(f"\nğŸ‰ æ£€æŸ¥å®Œæˆ: {passed_checks}/{total_checks} é¡¹æ£€æŸ¥é€šè¿‡")
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    try:
        checker = ComprehiveSkillsLearningChecker()
        report = checker.run_comprehensive_check()
        
        # æ ¹æ®ç»“æœè¿”å›é€‚å½“çš„é€€å‡ºç 
        overall_score = report['overall_score']
        if overall_score >= 70:
            return 0  # æˆåŠŸ
        elif overall_score >= 50:
            return 1  # è­¦å‘Š
        else:
            return 2  # é”™è¯¯
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 3


if __name__ == "__main__":
    exit(main())