"""SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç† - SPSC Manager

ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†

é—®é¢˜: è¿›ç¨‹å¼‚å¸¸é€€å‡ºå¯¼è‡´SharedMemoryæ³„æ¼
é£é™©ç­‰çº§: ğŸŸ¡ ä¸­

åŠŸèƒ½:
1. ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ
2. åŸå­å†™å…¥ï¼ˆå¸¦åºåˆ—IDï¼‰
3. åŸå­è¯»å–ï¼ˆæ’•è£‚è¯»æ£€æµ‹ï¼‰
4. è‡ªåŠ¨æ¸…ç†æœºåˆ¶

æ€§èƒ½è¦æ±‚:
- å»¶è¿Ÿ: < 100Î¼s
- ååé‡: > 60Hz
"""

import atexit
import struct
import threading
import time
from dataclasses import dataclass
from typing import Any, Dict, Optional

from loguru import logger

try:
    from multiprocessing import shared_memory

    import msgpack

    SHARED_MEMORY_AVAILABLE = True
except ImportError:
    SHARED_MEMORY_AVAILABLE = False
    logger.warning("shared_memoryæˆ–msgpackä¸å¯ç”¨ï¼ŒSPSCManagerå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")


@dataclass
class SPSCStats:
    """SPSCç»Ÿè®¡ä¿¡æ¯

    ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†

    Attributes:
        total_writes: æ€»å†™å…¥æ¬¡æ•°
        total_reads: æ€»è¯»å–æ¬¡æ•°
        torn_reads: æ’•è£‚è¯»æ¬¡æ•°
        avg_write_latency_us: å¹³å‡å†™å…¥å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰
        avg_read_latency_us: å¹³å‡è¯»å–å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰
    """

    total_writes: int = 0
    total_reads: int = 0
    torn_reads: int = 0
    avg_write_latency_us: float = 0.0
    avg_read_latency_us: float = 0.0
    _write_latencies: list = None
    _read_latencies: list = None

    def __post_init__(self):
        self._write_latencies = []
        self._read_latencies = []

    def record_write(self, latency_us: float) -> None:
        """è®°å½•å†™å…¥"""
        self.total_writes += 1
        self._write_latencies.append(latency_us)
        if len(self._write_latencies) > 100:
            self._write_latencies.pop(0)
        self.avg_write_latency_us = sum(self._write_latencies) / len(self._write_latencies)

    def record_read(self, latency_us: float, is_torn: bool = False) -> None:
        """è®°å½•è¯»å–"""
        self.total_reads += 1
        if is_torn:
            self.torn_reads += 1
        else:
            self._read_latencies.append(latency_us)
            if len(self._read_latencies) > 100:
                self._read_latencies.pop(0)
            self.avg_read_latency_us = sum(self._read_latencies) / len(self._read_latencies)


class SPSCManager:
    """SPSCå…±äº«å†…å­˜ç®¡ç†å™¨

    ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†

    æä¾›å•ç”Ÿäº§è€…å•æ¶ˆè´¹è€…ï¼ˆSPSCï¼‰æ¨¡å¼çš„å…±äº«å†…å­˜ç®¡ç†ï¼Œ
    æ”¯æŒåŸå­è¯»å†™å’Œæ’•è£‚è¯»æ£€æµ‹ã€‚

    å†…å­˜å¸ƒå±€:
    [seq_id_start(8B)][data_len(4B)][data(N B)][seq_id_end(8B)]

    Attributes:
        name: å…±äº«å†…å­˜åç§°
        size: å…±äº«å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        is_producer: æ˜¯å¦ä¸ºç”Ÿäº§è€…
        shm: å…±äº«å†…å­˜å¯¹è±¡
        stats: ç»Ÿè®¡ä¿¡æ¯
        _lock: çº¿ç¨‹é”
        _cleaned: æ˜¯å¦å·²æ¸…ç†
    """

    # å¤´éƒ¨å¤§å°: seq_id(8B) + data_len(4B) = 12B
    HEADER_SIZE = 12
    # å°¾éƒ¨å¤§å°: seq_id(8B) = 8B
    FOOTER_SIZE = 8

    def __init__(self, name: str, size: int, create: bool = False):
        """åˆå§‹åŒ–SPSCç®¡ç†å™¨

        Args:
            name: å…±äº«å†…å­˜åç§°
            size: å…±äº«å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            create: æ˜¯å¦åˆ›å»ºæ–°çš„å…±äº«å†…å­˜ï¼ˆç”Ÿäº§è€…ä¸ºTrueï¼‰

        Raises:
            ValueError: å½“å‚æ•°æ— æ•ˆæ—¶
            RuntimeError: å½“å…±äº«å†…å­˜æ“ä½œå¤±è´¥æ—¶
        """
        if not name:
            raise ValueError("å…±äº«å†…å­˜åç§°ä¸èƒ½ä¸ºç©º")

        if size <= self.HEADER_SIZE + self.FOOTER_SIZE:
            raise ValueError(f"å…±äº«å†…å­˜å¤§å°å¿…é¡» > {self.HEADER_SIZE + self.FOOTER_SIZE}ï¼Œ" f"å½“å‰: {size}")

        self.name: str = name
        self.size: int = size
        self.is_producer: bool = create
        self.shm: Optional[Any] = None
        self.stats: SPSCStats = SPSCStats()

        self._lock: threading.RLock = threading.RLock()
        self._cleaned: bool = False

        if SHARED_MEMORY_AVAILABLE:
            try:
                if create:
                    # å…ˆå°è¯•æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§å…±äº«å†…å­˜
                    try:
                        old_shm = shared_memory.SharedMemory(name=name)
                        old_shm.close()
                        old_shm.unlink()
                        logger.info(f"[SPSC] Cleaned up existing SharedMemory: {name}")
                    except FileNotFoundError:
                        pass

                    self.shm = shared_memory.SharedMemory(name=name, create=True, size=size)
                    logger.info(f"[SPSC] Created SharedMemory: {name} ({size} bytes)")
                else:
                    self.shm = shared_memory.SharedMemory(name=name)
                    logger.info(f"[SPSC] Connected to SharedMemory: {name}")

                # æ³¨å†Œæ¸…ç†å‡½æ•°
                atexit.register(self.cleanup)

            except Exception as e:
                logger.error(f"[SPSC] Failed to initialize SharedMemory: {e}")
                raise RuntimeError(f"SharedMemoryåˆå§‹åŒ–å¤±è´¥: {e}") from e
        else:
            logger.warning(f"[SPSC] SharedMemory not available, using mock mode")  # pylint: disable=w1309
            self._mock_buffer: bytes = bytearray(size)

    def __enter__(self) -> "SPSCManager":
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£

        Returns:
            self
        """
        return self

    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£

        Args:
            exc_type: å¼‚å¸¸ç±»å‹
            exc_val: å¼‚å¸¸å€¼
            exc_tb: å¼‚å¸¸è¿½è¸ª
        """
        self.cleanup()

    def cleanup(self) -> None:
        """æ¸…ç†å…±äº«å†…å­˜

        ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†
        """
        with self._lock:
            if self._cleaned:
                return

            self._cleaned = True

            if self.shm is not None:
                try:
                    self.shm.close()
                    if self.is_producer:
                        self.shm.unlink()
                        logger.info(f"[SPSC] Cleaned up SharedMemory: {self.name}")
                except Exception as e:  # pylint: disable=broad-exception-caught
                    logger.error(f"[SPSC] Cleanup error: {e}")

    def atomic_write(self, data: Any) -> bool:
        """åŸå­å†™å…¥

        ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†

        å†™å…¥æ ¼å¼: [seq_id(8B)][data_len(4B)][data][seq_id(8B)]

        Args:
            data: è¦å†™å…¥çš„æ•°æ®ï¼ˆå¯åºåˆ—åŒ–ï¼‰

        Returns:
            å†™å…¥æ˜¯å¦æˆåŠŸ
        """
        start_time = time.perf_counter()

        try:
            # ç”Ÿæˆåºåˆ—IDï¼ˆå¾®ç§’æ—¶é—´æˆ³ï¼‰
            seq_id = int(time.time() * 1000000)

            # åºåˆ—åŒ–æ•°æ®
            if SHARED_MEMORY_AVAILABLE:
                data_bytes = msgpack.packb(data)
            else:
                data_bytes = str(data).encode("utf-8")

            # æ£€æŸ¥æ•°æ®å¤§å°
            total_size = self.HEADER_SIZE + len(data_bytes) + self.FOOTER_SIZE
            if total_size > self.size:
                logger.error(f"[SPSC] Data too large: {total_size} > {self.size}")
                return False

            # è·å–ç¼“å†²åŒº
            buf = self._get_buffer()
            if buf is None:
                return False

            with self._lock:
                # å†™å…¥å¤´éƒ¨åºåˆ—ID
                struct.pack_into("Q", buf, 0, seq_id)
                # å†™å…¥æ•°æ®é•¿åº¦
                struct.pack_into("I", buf, 8, len(data_bytes))
                # å†™å…¥æ•°æ®
                buf[12 : 12 + len(data_bytes)] = data_bytes
                # å†™å…¥å°¾éƒ¨åºåˆ—ID
                struct.pack_into("Q", buf, 12 + len(data_bytes), seq_id)

            # è®°å½•ç»Ÿè®¡
            latency_us = (time.perf_counter() - start_time) * 1000000
            self.stats.record_write(latency_us)

            return True

        except Exception as e:  # pylint: disable=broad-exception-caught
            logger.error(f"[SPSC] Write error: {e}")
            return False

    def atomic_read(self) -> Optional[Any]:
        """åŸå­è¯»å–

        ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†

        è¯»å–æ ¼å¼: [seq_id(8B)][data_len(4B)][data][seq_id(8B)]
        æ£€æµ‹æ’•è£‚è¯»ï¼šæ¯”è¾ƒå¤´å°¾åºåˆ—ID

        Returns:
            è¯»å–çš„æ•°æ®ï¼Œå¦‚æœæ’•è£‚è¯»æˆ–å¤±è´¥åˆ™è¿”å›None
        """
        start_time = time.perf_counter()

        try:
            # è·å–ç¼“å†²åŒº
            buf = self._get_buffer()
            if buf is None:
                return None

            with self._lock:
                # è¯»å–å¤´éƒ¨åºåˆ—ID
                seq_id_start = struct.unpack_from("Q", buf, 0)[0]

                # è¯»å–æ•°æ®é•¿åº¦
                data_len = struct.unpack_from("I", buf, 8)[0]

                # æ£€æŸ¥æ•°æ®é•¿åº¦æœ‰æ•ˆæ€§
                if data_len <= 0 or data_len > self.size - self.HEADER_SIZE - self.FOOTER_SIZE:
                    return None

                # è¯»å–æ•°æ®
                data_bytes = bytes(buf[12 : 12 + data_len])

                # è¯»å–å°¾éƒ¨åºåˆ—ID
                seq_id_end = struct.unpack_from("Q", buf, 12 + data_len)[0]

            # æ£€æµ‹æ’•è£‚è¯»
            if seq_id_start != seq_id_end:
                logger.warning("[SPSC] Data torn, discarding")
                latency_us = (time.perf_counter() - start_time) * 1000000
                self.stats.record_read(latency_us, is_torn=True)
                return None

            # ååºåˆ—åŒ–æ•°æ®
            if SHARED_MEMORY_AVAILABLE:
                data = msgpack.unpackb(data_bytes)
            else:
                data = data_bytes.decode("utf-8")

            # è®°å½•ç»Ÿè®¡
            latency_us = (time.perf_counter() - start_time) * 1000000
            self.stats.record_read(latency_us)

            return data

        except Exception as e:  # pylint: disable=broad-exception-caught
            logger.error(f"[SPSC] Read error: {e}")
            return None

    def _get_buffer(self) -> Optional[Any]:
        """è·å–ç¼“å†²åŒºï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Returns:
            ç¼“å†²åŒºï¼Œå¦‚æœä¸å¯ç”¨åˆ™è¿”å›None
        """
        if SHARED_MEMORY_AVAILABLE and self.shm is not None:  # pylint: disable=no-else-return
            return self.shm.buf
        elif hasattr(self, "_mock_buffer"):
            return self._mock_buffer
        return None

    def get_stats(self) -> SPSCStats:
        """è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        return self.stats

    def is_available(self) -> bool:
        """æ£€æŸ¥å…±äº«å†…å­˜æ˜¯å¦å¯ç”¨

        Returns:
            æ˜¯å¦å¯ç”¨
        """
        return self.shm is not None or hasattr(self, "_mock_buffer")

    def get_name(self) -> str:
        """è·å–å…±äº«å†…å­˜åç§°

        Returns:
            å…±äº«å†…å­˜åç§°
        """
        return self.name

    def get_size(self) -> int:
        """è·å–å…±äº«å†…å­˜å¤§å°

        Returns:
            å…±äº«å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        return self.size


# å…¨å±€ç®¡ç†å™¨æ³¨å†Œè¡¨
_managers: Dict[str, SPSCManager] = {}
_managers_lock: threading.Lock = threading.Lock()


def get_spsc_manager(name: str, size: int = 1024 * 1024, create: bool = False) -> SPSCManager:
    """è·å–æˆ–åˆ›å»ºSPSCç®¡ç†å™¨

    ç™½çš®ä¹¦ä¾æ®: ç¬¬åäºŒç«  12.1.4 SharedMemoryç”Ÿå‘½å‘¨æœŸç®¡ç†

    Args:
        name: å…±äº«å†…å­˜åç§°
        size: å…±äº«å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œé»˜è®¤1MB
        create: æ˜¯å¦åˆ›å»ºæ–°çš„å…±äº«å†…å­˜

    Returns:
        SPSCç®¡ç†å™¨å®ä¾‹
    """
    with _managers_lock:
        if name not in _managers:
            _managers[name] = SPSCManager(name, size, create)
        return _managers[name]


def cleanup_all_managers() -> None:
    """æ¸…ç†æ‰€æœ‰SPSCç®¡ç†å™¨

    ä¸»è¦ç”¨äºæµ‹è¯•ç›®çš„ã€‚
    """
    with _managers_lock:
        for manager in _managers.values():
            manager.cleanup()
        _managers.clear()
