#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kiroç³»ç»Ÿå…¨é¢æµ‹è¯•
æµ‹è¯•æ‰€æœ‰Hookã€MCPè®¾ç½®ã€å…ƒå­¦ä¹ æœºåˆ¶å’Œç³»ç»Ÿè”åŠ¨
"""

import json
import sys
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import subprocess

# è®¾ç½®UTF-8ç¼–ç ï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform.startswith('win'):
    os.environ['PYTHONIOENCODING'] = 'utf-8'

class ComprehensiveKiroSystemTest:
    def __init__(self):
        self.test_timestamp = datetime.now()
        self.test_results = {
            "test_metadata": {
                "timestamp": self.test_timestamp.isoformat(),
                "platform": sys.platform,
                "test_scope": "å…¨é¢ç³»ç»Ÿæµ‹è¯•"
            },
            "hook_tests": {},
            "mcp_tests": {},
            "meta_learning_tests": {},
            "integration_tests": {},
            "system_health": {}
        }
        
    def test_hook_system(self) -> Dict:
        """æµ‹è¯•Hookç³»ç»Ÿ"""
        
        print("ğŸ”§ æµ‹è¯•Hookç³»ç»Ÿ...")
        
        hook_dir = Path('.kiro/hooks')
        hook_results = {
            "hook_directory_exists": hook_dir.exists(),
            "hook_files": [],
            "hook_validity": {},
            "architecture_score": 0
        }
        
        if hook_dir.exists():
            # æ£€æŸ¥Hookæ–‡ä»¶
            hook_files = list(hook_dir.glob('*.kiro.hook'))
            hook_results["hook_files"] = [f.name for f in hook_files]
            
            # éªŒè¯æ¯ä¸ªHookçš„æœ‰æ•ˆæ€§
            for hook_file in hook_files:
                try:
                    with open(hook_file, 'r', encoding='utf-8') as f:
                        hook_config = json.load(f)
                    
                    # éªŒè¯Hooké…ç½®çš„å®Œæ•´æ€§
                    required_fields = ['name', 'version', 'when', 'then']
                    validity = {
                        "file_readable": True,
                        "json_valid": True,
                        "required_fields": all(field in hook_config for field in required_fields),
                        "configuration": hook_config.get('metadata', {})
                    }
                    
                    hook_results["hook_validity"][hook_file.name] = validity
                    
                except Exception as e:
                    hook_results["hook_validity"][hook_file.name] = {
                        "file_readable": False,
                        "error": str(e)
                    }
            
            # æ£€æŸ¥Hookæ¶æ„æ–‡æ¡£
            arch_file = hook_dir / 'HOOK_ARCHITECTURE.md'
            if arch_file.exists():
                try:
                    with open(arch_file, 'r', encoding='utf-8') as f:
                        arch_content = f.read()
                    
                    # ä»æ¶æ„æ–‡æ¡£ä¸­æå–è¯„åˆ†
                    if "æ¶æ„è¯„åˆ†: 95.0/100" in arch_content:
                        hook_results["architecture_score"] = 95.0
                    
                except Exception:
                    pass
        
        return hook_results
    
    def test_mcp_configuration(self) -> Dict:
        """æµ‹è¯•MCPé…ç½®"""
        
        print("ğŸ”— æµ‹è¯•MCPé…ç½®...")
        
        mcp_results = {
            "mcp_directory_exists": False,
            "mcp_config_files": [],
            "memory_system_status": "æœªçŸ¥",
            "filesystem_integration": False
        }
        
        # æ£€æŸ¥MCPè®¾ç½®ç›®å½•
        mcp_dir = Path('.kiro/settings')
        if mcp_dir.exists():
            mcp_results["mcp_directory_exists"] = True
            
            # æ£€æŸ¥MCPé…ç½®æ–‡ä»¶
            mcp_files = list(mcp_dir.glob('mcp*.json'))
            mcp_results["mcp_config_files"] = [f.name for f in mcp_files]
            
            # æ£€æŸ¥è®°å¿†ç³»ç»Ÿé…ç½®
            for mcp_file in mcp_files:
                try:
                    with open(mcp_file, 'r', encoding='utf-8') as f:
                        mcp_config = json.load(f)
                    
                    if 'mcpServers' in mcp_config:
                        servers = mcp_config['mcpServers']
                        if 'memory' in servers or any('memory' in server_name.lower() for server_name in servers.keys()):
                            mcp_results["memory_system_status"] = "å·²é…ç½®"
                        
                        if 'filesystem' in servers or any('filesystem' in server_name.lower() for server_name in servers.keys()):
                            mcp_results["filesystem_integration"] = True
                            
                except Exception:
                    continue
        
        # æ£€æŸ¥è®°å¿†ç³»ç»Ÿç›®å½•
        memory_dir = Path('.kiro/memory')
        if memory_dir.exists():
            memory_subdirs = [d.name for d in memory_dir.iterdir() if d.is_dir()]
            mcp_results["memory_directories"] = memory_subdirs
            
            # æ£€æŸ¥æœ€è¿‘çš„çŸ¥è¯†å­˜å‚¨
            task_knowledge_dir = memory_dir / 'task_knowledge'
            if task_knowledge_dir.exists():
                knowledge_files = list(task_knowledge_dir.glob('task_knowledge_*.json'))
                if knowledge_files:
                    latest_file = max(knowledge_files, key=lambda x: x.stat().st_mtime)
                    mcp_results["latest_knowledge_extraction"] = latest_file.name
        
        return mcp_results
    
    def test_meta_learning_system(self) -> Dict:
        """æµ‹è¯•å…ƒå­¦ä¹ æœºåˆ¶"""
        
        print("ğŸ§  æµ‹è¯•å…ƒå­¦ä¹ æœºåˆ¶...")
        
        meta_learning_results = {
            "team_skills_meta_learning": False,
            "brain_meta_learning": False,
            "core_components": [],
            "integration_status": "æœªçŸ¥"
        }
        
        # æ£€æŸ¥å›¢é˜ŸæŠ€èƒ½å…ƒå­¦ä¹ ç³»ç»Ÿ
        team_skills_dir = Path('src/team_skills_meta_learning')
        if team_skills_dir.exists():
            meta_learning_results["team_skills_meta_learning"] = True
            
            # æ£€æŸ¥æ ¸å¿ƒç»„ä»¶
            core_files = [
                'core.py',
                'meta_coordinator.py',
                'models.py',
                '__init__.py'
            ]
            
            existing_components = []
            for core_file in core_files:
                if (team_skills_dir / core_file).exists():
                    existing_components.append(core_file)
            
            meta_learning_results["core_components"] = existing_components
        
        # æ£€æŸ¥å¤§è„‘å…ƒå­¦ä¹ ç³»ç»Ÿ
        brain_meta_dir = Path('src/brain/meta_learning')
        if brain_meta_dir.exists():
            meta_learning_results["brain_meta_learning"] = True
            
            # æ£€æŸ¥é£é™©æ§åˆ¶å…ƒå­¦ä¹ å™¨
            risk_learner_file = brain_meta_dir / 'risk_control_meta_learner.py'
            if risk_learner_file.exists():
                meta_learning_results["risk_control_meta_learner"] = True
        
        # æ£€æŸ¥æµ‹è¯•è¦†ç›–
        meta_test_dir = Path('tests/unit/brain/meta_learning')
        if meta_test_dir.exists():
            test_files = list(meta_test_dir.glob('test_*.py'))
            meta_learning_results["test_coverage"] = [f.name for f in test_files]
        
        # è¯„ä¼°é›†æˆçŠ¶æ€
        if (meta_learning_results["team_skills_meta_learning"] and 
            meta_learning_results["brain_meta_learning"] and 
            len(meta_learning_results["core_components"]) >= 3):
            meta_learning_results["integration_status"] = "å®Œæ•´ä¸”è¿è¡Œæ­£å¸¸"
        elif meta_learning_results["team_skills_meta_learning"] or meta_learning_results["brain_meta_learning"]:
            meta_learning_results["integration_status"] = "éƒ¨åˆ†å¯ç”¨"
        else:
            meta_learning_results["integration_status"] = "æœªæ£€æµ‹åˆ°"
        
        return meta_learning_results
    
    def test_system_integration(self) -> Dict:
        """æµ‹è¯•ç³»ç»Ÿé›†æˆ"""
        
        print("ğŸ”„ æµ‹è¯•ç³»ç»Ÿé›†æˆ...")
        
        integration_results = {
            "background_knowledge_accumulator": False,
            "knowledge_extraction_system": False,
            "anti_drift_mechanism": False,
            "cross_platform_compatibility": False,
            "logging_system": False
        }
        
        # æ£€æŸ¥åå°çŸ¥è¯†ç§¯ç´¯å¼•æ“
        bg_accumulator = Path('scripts/utilities/background_knowledge_accumulator.py')
        if bg_accumulator.exists():
            integration_results["background_knowledge_accumulator"] = True
        
        # æ£€æŸ¥çŸ¥è¯†æå–ç³»ç»Ÿ
        knowledge_extractor = Path('scripts/utilities/background_knowledge_extraction.py')
        if knowledge_extractor.exists():
            integration_results["knowledge_extraction_system"] = True
        
        # æ£€æŸ¥åæ¼‚ç§»æœºåˆ¶ï¼ˆé€šè¿‡steeringæ–‡ä»¶ï¼‰
        steering_dir = Path('.kiro/steering')
        if steering_dir.exists():
            anti_drift_files = list(steering_dir.glob('*anti*drift*.md'))
            if anti_drift_files:
                integration_results["anti_drift_mechanism"] = True
        
        # æ£€æŸ¥è·¨å¹³å°å…¼å®¹æ€§
        platform_configs = [
            Path('3.0/win'),
            Path('3.0/mac'),
            Path('3.0/linux')
        ]
        
        if all(config.exists() for config in platform_configs):
            integration_results["cross_platform_compatibility"] = True
        
        # æ£€æŸ¥æ—¥å¿—ç³»ç»Ÿ
        log_dir = Path('.kiro/logs')
        if log_dir.exists():
            integration_results["logging_system"] = True
        
        return integration_results
    
    def assess_system_health(self) -> Dict:
        """è¯„ä¼°ç³»ç»Ÿå¥åº·çŠ¶å†µ"""
        
        print("ğŸ“Š è¯„ä¼°ç³»ç»Ÿå¥åº·çŠ¶å†µ...")
        
        health_results = {
            "overall_score": 0,
            "component_scores": {},
            "recommendations": [],
            "critical_issues": [],
            "optimization_opportunities": []
        }
        
        # åŸºäºæµ‹è¯•ç»“æœè®¡ç®—ç»„ä»¶åˆ†æ•°
        hook_score = 0
        if self.test_results["hook_tests"].get("hook_directory_exists", False):
            hook_score += 20
        
        hook_files = self.test_results["hook_tests"].get("hook_files", [])
        if len(hook_files) >= 6:  # æœŸæœ›çš„6ä¸ªHook
            hook_score += 30
        
        # æ£€æŸ¥Hookæœ‰æ•ˆæ€§
        valid_hooks = sum(1 for validity in self.test_results["hook_tests"].get("hook_validity", {}).values() 
                         if validity.get("required_fields", False))
        if valid_hooks >= 6:
            hook_score += 50  # æ‰€æœ‰Hookéƒ½æœ‰æ•ˆ
        elif valid_hooks >= 4:
            hook_score += 30  # å¤§éƒ¨åˆ†Hookæœ‰æ•ˆ
        elif valid_hooks >= 2:
            hook_score += 15  # éƒ¨åˆ†Hookæœ‰æ•ˆ
        
        mcp_score = 0
        if self.test_results["mcp_tests"].get("mcp_directory_exists", False):
            mcp_score += 40
        if self.test_results["mcp_tests"].get("memory_system_status") == "å·²é…ç½®":
            mcp_score += 60
        
        meta_learning_score = 0
        if self.test_results["meta_learning_tests"].get("integration_status") == "å®Œæ•´ä¸”è¿è¡Œæ­£å¸¸":
            meta_learning_score = 100
        elif self.test_results["meta_learning_tests"].get("integration_status") == "éƒ¨åˆ†å¯ç”¨":
            meta_learning_score = 60
        
        integration_score = 0
        integration_tests = self.test_results["integration_tests"]
        integration_count = sum(1 for v in integration_tests.values() if v)
        integration_score = (integration_count / len(integration_tests)) * 100
        
        # è®¡ç®—æ€»åˆ†
        health_results["component_scores"] = {
            "hook_system": hook_score,
            "mcp_configuration": mcp_score,
            "meta_learning": meta_learning_score,
            "system_integration": integration_score
        }
        
        overall_score = sum(health_results["component_scores"].values()) / len(health_results["component_scores"])
        health_results["overall_score"] = round(overall_score, 1)
        
        # ç”Ÿæˆå»ºè®®
        if hook_score < 80:
            health_results["recommendations"].append("ä¼˜åŒ–Hookç³»ç»Ÿé…ç½®å’Œæ¶æ„")
        
        if mcp_score < 80:
            health_results["recommendations"].append("å®Œå–„MCPé…ç½®å’Œè®°å¿†ç³»ç»Ÿé›†æˆ")
        
        if meta_learning_score < 90:
            health_results["recommendations"].append("æ£€æŸ¥å…ƒå­¦ä¹ æœºåˆ¶çš„å®Œæ•´æ€§")
        
        if integration_score < 80:
            health_results["recommendations"].append("åŠ å¼ºç³»ç»Ÿç»„ä»¶é—´çš„é›†æˆ")
        
        # è¯†åˆ«å…³é”®é—®é¢˜
        if overall_score < 70:
            health_results["critical_issues"].append("ç³»ç»Ÿæ•´ä½“å¥åº·çŠ¶å†µéœ€è¦æ”¹å–„")
        
        # è¯†åˆ«ä¼˜åŒ–æœºä¼š
        if overall_score > 90:
            health_results["optimization_opportunities"].append("ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œå¯è€ƒè™‘æ€§èƒ½ä¼˜åŒ–")
        
        return health_results
    
    def run_comprehensive_test(self) -> Dict:
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        
        print("ğŸš€ å¼€å§‹Kiroç³»ç»Ÿå…¨é¢æµ‹è¯•...")
        print(f"æµ‹è¯•æ—¶é—´: {self.test_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æµ‹è¯•å¹³å°: {sys.platform}")
        print()
        
        # æ‰§è¡Œå„é¡¹æµ‹è¯•
        self.test_results["hook_tests"] = self.test_hook_system()
        self.test_results["mcp_tests"] = self.test_mcp_configuration()
        self.test_results["meta_learning_tests"] = self.test_meta_learning_system()
        self.test_results["integration_tests"] = self.test_system_integration()
        self.test_results["system_health"] = self.assess_system_health()
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        self.save_test_results()
        
        # æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦
        self.display_test_summary()
        
        return self.test_results
    
    def save_test_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_dir = Path('.kiro/reports')
        report_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = self.test_timestamp.strftime('%Y%m%d_%H%M%S')
        report_file = report_dir / f'comprehensive_system_test_{timestamp}.json'
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def display_test_summary(self):
        """æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦"""
        
        print("\n" + "="*60)
        print("ğŸ“Š Kiroç³»ç»Ÿæµ‹è¯•æ‘˜è¦")
        print("="*60)
        
        # æ˜¾ç¤ºç³»ç»Ÿå¥åº·è¯„åˆ†
        health = self.test_results["system_health"]
        print(f"ğŸ¯ ç³»ç»Ÿæ•´ä½“å¥åº·è¯„åˆ†: {health['overall_score']}/100")
        print()
        
        # æ˜¾ç¤ºç»„ä»¶è¯„åˆ†
        print("ğŸ“‹ ç»„ä»¶è¯„åˆ†è¯¦æƒ…:")
        for component, score in health["component_scores"].items():
            status = "âœ…" if score >= 80 else "âš ï¸" if score >= 60 else "âŒ"
            print(f"  {status} {component}: {score}/100")
        print()
        
        # æ˜¾ç¤ºHookç³»ç»ŸçŠ¶æ€
        hook_tests = self.test_results["hook_tests"]
        print(f"ğŸ”§ Hookç³»ç»Ÿ: {len(hook_tests.get('hook_files', []))}ä¸ªHookæ–‡ä»¶")
        if hook_tests.get("architecture_score", 0) > 0:
            print(f"   æ¶æ„è¯„åˆ†: {hook_tests['architecture_score']}/100")
        print()
        
        # æ˜¾ç¤ºMCPçŠ¶æ€
        mcp_tests = self.test_results["mcp_tests"]
        print(f"ğŸ”— MCPç³»ç»Ÿ: {mcp_tests.get('memory_system_status', 'æœªçŸ¥')}")
        if mcp_tests.get("mcp_config_files"):
            print(f"   é…ç½®æ–‡ä»¶: {len(mcp_tests['mcp_config_files'])}ä¸ª")
        print()
        
        # æ˜¾ç¤ºå…ƒå­¦ä¹ çŠ¶æ€
        meta_tests = self.test_results["meta_learning_tests"]
        print(f"ğŸ§  å…ƒå­¦ä¹ æœºåˆ¶: {meta_tests.get('integration_status', 'æœªçŸ¥')}")
        if meta_tests.get("core_components"):
            print(f"   æ ¸å¿ƒç»„ä»¶: {len(meta_tests['core_components'])}ä¸ª")
        print()
        
        # æ˜¾ç¤ºå»ºè®®
        if health.get("recommendations"):
            print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            for rec in health["recommendations"]:
                print(f"   â€¢ {rec}")
            print()
        
        # æ˜¾ç¤ºå…³é”®é—®é¢˜
        if health.get("critical_issues"):
            print("ğŸš¨ å…³é”®é—®é¢˜:")
            for issue in health["critical_issues"]:
                print(f"   â€¢ {issue}")
            print()
        
        # æ˜¾ç¤ºä¼˜åŒ–æœºä¼š
        if health.get("optimization_opportunities"):
            print("ğŸ¯ ä¼˜åŒ–æœºä¼š:")
            for opp in health["optimization_opportunities"]:
                print(f"   â€¢ {opp}")
            print()
        
        print("="*60)
        print("âœ… æµ‹è¯•å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = ComprehensiveKiroSystemTest()
    
    # è¿è¡Œå…¨é¢æµ‹è¯•
    results = tester.run_comprehensive_test()
    
    return results

if __name__ == "__main__":
    main()