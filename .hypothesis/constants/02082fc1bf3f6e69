# file: C:\mia\src\brain\llm_gateway.py
# hypothesis_version: 6.150.2

[0.0, 0.0005, 0.0008, 0.0009, 0.001, 0.0013, 0.002, 0.02, 0.1, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.3, 10.0, 30.0, 50.0, 1500.0, 100, 150, 160, 180, 200, 300, 1000, 2000, 6379, 8000, 86400, '...', 'Assistant:', 'BUDGET_EXCEEDED', 'LLM客户端池初始化完成', 'LLM网关异步初始化完成', 'MAX_RETRIES_EXCEEDED', 'TIMEOUT_ERROR', 'VALIDATION_ERROR', 'assistant', 'avg_retries_per_call', 'batch_calls', 'batch_usage_rate', 'budget_exceeded', 'business_context', 'call_id', 'call_type', 'caller_function', 'caller_module', 'claude', 'code_generation', 'confidence', 'content', 'cost', 'data_analysis', 'decide', 'deepseek', 'deepseek-chat', 'deepseek_client', 'episodic', 'error_message', 'error_type', 'factor_generation', 'failed_calls', 'fallback_used', 'glm', 'glm-4', 'glm_client', 'hallucination_rate', 'hallucination_score', 'historical_accuracy', 'is_hallucination', 'latency_ms', 'localhost', 'market_sentiment', 'max_tokens', 'messages', 'model', 'model_used', 'prompt', 'provider', 'quality_score', 'qwen3-30b-moe', 'qwen3-30b-moe-local', 'qwen3-30b-moe-vllm', 'qwen3-next-80b', 'qwen_cloud', 'qwen_cloud_client', 'qwen_local', 'qwen_local_client', 'request_id', 'request_summary', 'research_analysis', 'response_summary', 'retries', 'retry_rate', 'risk_assessment', 'role', 'soldier', 'strategy_analysis', 'success', 'success_rate', 'successful_calls', 'system', 'temperature', 'text', 'timeout_rate', 'timeouts', 'timestamp', 'tokens_used', 'total_calls', 'trading_decision', 'unknown', 'user', 'vllm_calls', 'vllm_engine_stats', 'vllm_usage_rate', '消息列表不能为空', '空响应', '空请求']