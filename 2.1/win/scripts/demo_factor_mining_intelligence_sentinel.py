#!/usr/bin/env python
"""
MIAç³»ç»Ÿå› å­æŒ–æ˜æ™ºèƒ½å“¨å…µæ¼”ç¤ºè„šæœ¬

ç™½çš®ä¹¦ä¾æ®: ç¬¬äºŒç«  2.6 FactorMining Intelligence Sentinel
ç‰ˆæœ¬: v1.6.0
ä½œè€…: MIA Team
æ—¥æœŸ: 2026-01-18

æ¼”ç¤ºåŠŸèƒ½:
1. æ™ºèƒ½å“¨å…µåˆå§‹åŒ–å’Œé…ç½®
2. æ¨¡æ‹Ÿå­¦æœ¯è®ºæ–‡å‘ç°å’Œåˆ†æ
3. è‡ªåŠ¨å› å­å®ç°å’ŒéªŒè¯
4. æ‰‹åŠ¨å‘ç°è¾“å…¥å’Œå¤„ç†
5. å‘ç°ç»Ÿè®¡å’ŒæŸ¥è¯¢
6. å› å­åº“é›†æˆå±•ç¤º
"""

import asyncio
import json
import tempfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path
import numpy as np
import pandas as pd
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
import sys
sys.path.append(str(Path(__file__).parent.parent))

from src.evolution.factor_mining_intelligence_sentinel import (
    FactorMiningIntelligenceSentinel,
    FactorDiscovery,
    DiscoveryType,
    FactorCategory,
    ValidationStatus
)
from src.brain.llm_gateway import LLMGateway


class FactorMiningIntelligenceSentinelDemo:
    """å› å­æŒ–æ˜æ™ºèƒ½å“¨å…µæ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤º"""
        self.temp_dir = tempfile.mkdtemp()
        self.sentinel = None
        print("ğŸš€ MIAå› å­æŒ–æ˜æ™ºèƒ½å“¨å…µæ¼”ç¤ºç³»ç»Ÿ")
        print("=" * 60)
        print("æ ¸å¿ƒç†å¿µ: è®©MIAåœ¨å› å­æŒ–æ˜é¢†åŸŸæ°¸è¿œä¿æŒå‰æ²¿")
        print("=" * 60)
    
    def __del__(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if hasattr(self, 'temp_dir') and Path(self.temp_dir).exists():
            shutil.rmtree(self.temp_dir)
    
    async def initialize_sentinel(self):
        """åˆå§‹åŒ–æ™ºèƒ½å“¨å…µ"""
        print("\nğŸ“¡ åˆå§‹åŒ–å› å­æŒ–æ˜æ™ºèƒ½å“¨å…µ...")
        
        # åˆ›å»ºLLMç½‘å…³å®ä¾‹
        llm_gateway = LLMGateway()
        
        # åˆ›å»ºå“¨å…µå®ä¾‹
        self.sentinel = FactorMiningIntelligenceSentinel(
            llm_gateway=llm_gateway,
            discovery_storage_path=self.temp_dir
        )
        
        # è®¾ç½®äº‹ä»¶å¤„ç†å™¨
        await self.sentinel.setup_event_handlers()
        
        print(f"âœ… å“¨å…µåˆå§‹åŒ–å®Œæˆ")
        print(f"   ğŸ“ å­˜å‚¨è·¯å¾„: {self.temp_dir}")
        print(f"   ğŸ” ç›‘æ§æºæ•°é‡: {len(self.sentinel.monitoring_sources)}")
        print(f"   ğŸ§  æ¨¡å‹é…ç½®: {len(self.sentinel.model_configs)} ä¸ª")
        
        # æ˜¾ç¤ºç›‘æ§æºé…ç½®
        print("\nğŸ¯ ç›‘æ§æºé…ç½®:")
        for source_name, config in self.sentinel.monitoring_sources.items():
            priority = config.get('priority', 'unknown')
            interval = config.get('check_interval', 0) // 3600
            print(f"   â€¢ {source_name}: ä¼˜å…ˆçº§={priority}, æ£€æŸ¥é—´éš”={interval}å°æ—¶")
        
        # æ˜¾ç¤ºæ¨¡å‹é…ç½®
        print("\nğŸ¤– AIæ¨¡å‹é…ç½®:")
        for model_name, config in self.sentinel.model_configs.items():
            model = config['model']
            role = config['role']
            print(f"   â€¢ {model_name}: {model} - {role}")
    
    async def demonstrate_academic_discovery(self):
        """æ¼”ç¤ºå­¦æœ¯è®ºæ–‡å‘ç°"""
        print("\nğŸ“š å­¦æœ¯è®ºæ–‡å‘ç°æ¼”ç¤º...")
        
        # æ¨¡æ‹Ÿå‘ç°å­¦æœ¯è®ºæ–‡
        mock_papers = [
            {
                'title': 'ESG Momentum: Sustainable Alpha in Factor Investing',
                'abstract': 'We investigate the relationship between ESG momentum and stock returns, finding significant alpha generation potential through sustainable factor construction...',
                'authors': ['Chen, L.', 'Wang, M.', 'Liu, J.'],
                'published': '2026-01-18',
                'url': 'https://arxiv.org/abs/2601.12345',
                'category': FactorCategory.SENTIMENT
            },
            {
                'title': 'Cross-Asset Momentum Spillovers in Alternative Data',
                'abstract': 'Using satellite imagery and social media sentiment, we construct cross-asset momentum factors that capture spillover effects between equity and commodity markets...',
                'authors': ['Smith, A.', 'Johnson, B.'],
                'published': '2026-01-17',
                'url': 'https://arxiv.org/abs/2601.12346',
                'category': FactorCategory.ALTERNATIVE
            },
            {
                'title': 'High-Frequency Technical Patterns with Deep Learning',
                'abstract': 'We apply transformer networks to identify high-frequency technical patterns that predict short-term price movements with superior accuracy...',
                'authors': ['Zhang, K.', 'Brown, R.'],
                'published': '2026-01-16',
                'url': 'https://arxiv.org/abs/2601.12347',
                'category': FactorCategory.TECHNICAL
            }
        ]
        
        print(f"ğŸ” æ‰«æåˆ° {len(mock_papers)} ç¯‡ç›¸å…³è®ºæ–‡:")
        
        for i, paper in enumerate(mock_papers, 1):
            print(f"\n   ğŸ“„ è®ºæ–‡ {i}: {paper['title']}")
            print(f"      ä½œè€…: {', '.join(paper['authors'])}")
            print(f"      å‘å¸ƒ: {paper['published']}")
            print(f"      æ‘˜è¦: {paper['abstract'][:100]}...")
            
            # åˆ›å»ºå‘ç°è®°å½•
            discovery = FactorDiscovery(
                discovery_id="",
                discovery_type=DiscoveryType.ACADEMIC_PAPER,
                factor_category=paper['category'],
                title=paper['title'],
                description=f"åŸºäºè®ºæ–‡ã€Š{paper['title']}ã€‹çš„å› å­å‘ç°",
                source=paper['url'],
                discovered_at=datetime.now(),
                discoverer='system',
                theoretical_basis=paper['abstract'],
                expected_alpha=np.random.uniform(0.02, 0.08),
                tags=['academic', 'arxiv', '2026'],
                confidence_score=np.random.uniform(0.7, 0.95)
            )
            
            # å¤„ç†å‘ç°
            await self.sentinel._process_new_discovery(discovery)
            
            print(f"      âœ… å‘ç°å·²è®°å½• (ID: {discovery.discovery_id})")
            print(f"      ğŸ“Š ç½®ä¿¡åº¦: {discovery.confidence_score:.2f}")
            print(f"      ğŸ¯ é¢„æœŸAlpha: {discovery.expected_alpha:.3f}")
    
    async def demonstrate_alternative_data_discovery(self):
        """æ¼”ç¤ºæ›¿ä»£æ•°æ®å‘ç°"""
        print("\nğŸ›°ï¸ æ›¿ä»£æ•°æ®æºå‘ç°æ¼”ç¤º...")
        
        # æ¨¡æ‹Ÿæ›¿ä»£æ•°æ®æºå‘ç°
        mock_data_sources = [
            {
                'name': 'Corporate Earnings Call Sentiment Analysis',
                'description': 'åŸºäºè‡ªç„¶è¯­è¨€å¤„ç†çš„ä¼ä¸šè´¢æŠ¥ç”µè¯ä¼šè®®æƒ…ç»ªåˆ†æï¼Œå®æ—¶æ•æ‰ç®¡ç†å±‚ä¿¡å¿ƒå˜åŒ–',
                'data_type': 'text_sentiment',
                'update_frequency': 'quarterly',
                'coverage': 'S&P 500 + Aè‚¡ä¸»è¦å…¬å¸',
                'potential_alpha': 0.045,
                'complexity': 'medium'
            },
            {
                'name': 'Supply Chain Disruption Satellite Monitor',
                'description': 'åˆ©ç”¨å«æ˜Ÿå›¾åƒç›‘æ§å…¨çƒä¾›åº”é“¾å…³é”®èŠ‚ç‚¹ï¼Œé¢„æµ‹ä¾›åº”é“¾ä¸­æ–­å¯¹è‚¡ä»·çš„å½±å“',
                'data_type': 'satellite_imagery',
                'update_frequency': 'daily',
                'coverage': 'Global Manufacturing Hubs',
                'potential_alpha': 0.035,
                'complexity': 'high'
            },
            {
                'name': 'Social Media Brand Sentiment Tracker',
                'description': 'è·Ÿè¸ªç¤¾äº¤åª’ä½“ä¸Šå“ç‰ŒæåŠå’Œæƒ…ç»ªå˜åŒ–ï¼Œé¢„æµ‹æ¶ˆè´¹è€…è¡Œä¸ºå¯¹è‚¡ä»·çš„å½±å“',
                'data_type': 'social_media',
                'update_frequency': 'real-time',
                'coverage': 'Consumer Brands',
                'potential_alpha': 0.028,
                'complexity': 'low'
            }
        ]
        
        print(f"ğŸ” å‘ç° {len(mock_data_sources)} ä¸ªæ–°çš„æ›¿ä»£æ•°æ®æº:")
        
        for i, data_source in enumerate(mock_data_sources, 1):
            print(f"\n   ğŸ“¡ æ•°æ®æº {i}: {data_source['name']}")
            print(f"      æè¿°: {data_source['description']}")
            print(f"      ç±»å‹: {data_source['data_type']}")
            print(f"      æ›´æ–°é¢‘ç‡: {data_source['update_frequency']}")
            print(f"      è¦†ç›–èŒƒå›´: {data_source['coverage']}")
            print(f"      é¢„æœŸAlpha: {data_source['potential_alpha']:.3f}")
            print(f"      å®ç°å¤æ‚åº¦: {data_source['complexity']}")
            
            # åˆ›å»ºå‘ç°è®°å½•
            discovery = FactorDiscovery(
                discovery_id="",
                discovery_type=DiscoveryType.ALTERNATIVE_DATA,
                factor_category=FactorCategory.ALTERNATIVE,
                title=f"æ–°æ•°æ®æº: {data_source['name']}",
                description=data_source['description'],
                source="å†…éƒ¨æ•°æ®å‘ç°ç³»ç»Ÿ",
                discovered_at=datetime.now(),
                discoverer='system',
                theoretical_basis="æ›¿ä»£æ•°æ®ä¸è‚¡ç¥¨æ”¶ç›Šçš„ç›¸å…³æ€§åˆ†æ",
                expected_alpha=data_source['potential_alpha'],
                data_requirements=[data_source['data_type']],
                implementation_complexity=data_source['complexity'],
                tags=['alternative_data', 'new_source', data_source['data_type']],
                confidence_score=0.75
            )
            
            # å¤„ç†å‘ç°
            await self.sentinel._process_new_discovery(discovery)
            
            print(f"      âœ… æ•°æ®æºå·²è®°å½• (ID: {discovery.discovery_id})")
    
    async def demonstrate_market_anomaly_detection(self):
        """æ¼”ç¤ºå¸‚åœºå¼‚è±¡å‘ç°"""
        print("\nğŸ” å¸‚åœºå¼‚è±¡å‘ç°æ¼”ç¤º...")
        
        # æ¨¡æ‹Ÿå¸‚åœºå¼‚è±¡å‘ç°
        mock_anomalies = [
            {
                'pattern': 'Post-Earnings Announcement Drift Enhancement',
                'description': 'åœ¨é«˜VIXç¯å¢ƒä¸‹ï¼Œå°ç›˜è‚¡çš„ç›ˆåˆ©å…¬å‘Šåæ¼‚ç§»æ•ˆåº”æ˜¾è‘—å¢å¼ºï¼ŒæŒç»­æœŸå»¶é•¿è‡³5-7ä¸ªäº¤æ˜“æ—¥',
                'strength': 0.042,
                'persistence': '5-7 trading days',
                'conditions': ['small_cap', 'high_vix', 'earnings_surprise > 5%'],
                'market_regime': 'high_volatility'
            },
            {
                'pattern': 'Cross-Sectional Reversal in Tech Stocks',
                'description': 'ç§‘æŠ€è‚¡åœ¨æœˆæœ«æœ€å3ä¸ªäº¤æ˜“æ—¥å‡ºç°æ˜¾è‘—çš„æˆªé¢åè½¬æ•ˆåº”ï¼Œä¸æœºæ„å†å¹³è¡¡ç›¸å…³',
                'strength': 0.038,
                'persistence': '3 days',
                'conditions': ['tech_sector', 'month_end', 'institutional_rebalancing'],
                'market_regime': 'normal'
            },
            {
                'pattern': 'Commodity-Equity Momentum Spillover',
                'description': 'å¤§å®—å•†å“åŠ¨é‡ä¿¡å·å¯¹ç›¸å…³è¡Œä¸šè‚¡ç¥¨å…·æœ‰2æ—¥æ»åçš„é¢„æµ‹èƒ½åŠ›ï¼Œåœ¨é€šèƒ€é¢„æœŸä¸Šå‡æœŸé—´æ›´å¼º',
                'strength': 0.031,
                'persistence': '2-day lag',
                'conditions': ['commodity_momentum', 'related_sectors', 'inflation_expectations'],
                'market_regime': 'inflationary'
            }
        ]
        
        print(f"ğŸ¯ æ£€æµ‹åˆ° {len(mock_anomalies)} ä¸ªå¸‚åœºå¼‚è±¡:")
        
        for i, anomaly in enumerate(mock_anomalies, 1):
            print(f"\n   ğŸ” å¼‚è±¡ {i}: {anomaly['pattern']}")
            print(f"      æè¿°: {anomaly['description']}")
            print(f"      ä¿¡å·å¼ºåº¦: {anomaly['strength']:.3f}")
            print(f"      æŒç»­æœŸ: {anomaly['persistence']}")
            print(f"      è§¦å‘æ¡ä»¶: {', '.join(anomaly['conditions'])}")
            print(f"      å¸‚åœºç¯å¢ƒ: {anomaly['market_regime']}")
            
            # åˆ›å»ºå‘ç°è®°å½•
            discovery = FactorDiscovery(
                discovery_id="",
                discovery_type=DiscoveryType.MARKET_ANOMALY,
                factor_category=FactorCategory.TECHNICAL,
                title=f"å¸‚åœºå¼‚è±¡: {anomaly['pattern']}",
                description=anomaly['description'],
                source="å†…éƒ¨å¸‚åœºåˆ†æç³»ç»Ÿ",
                discovered_at=datetime.now(),
                discoverer='system',
                theoretical_basis="è¡Œä¸ºé‡‘èå­¦å’Œå¸‚åœºå¾®è§‚ç»“æ„ç†è®º",
                expected_alpha=anomaly['strength'],
                risk_factors=['market_regime_change', 'liquidity_risk'],
                tags=['market_anomaly', 'behavioral', anomaly['market_regime']],
                confidence_score=0.8
            )
            
            # å¤„ç†å‘ç°
            await self.sentinel._process_new_discovery(discovery)
            
            print(f"      âœ… å¼‚è±¡å·²è®°å½• (ID: {discovery.discovery_id})")
    
    async def demonstrate_manual_discovery_input(self):
        """æ¼”ç¤ºæ‰‹åŠ¨å‘ç°è¾“å…¥"""
        print("\nâœ‹ æ‰‹åŠ¨å‘ç°è¾“å…¥æ¼”ç¤º...")
        
        # æ¨¡æ‹Ÿç ”ç©¶å‘˜æ‰‹åŠ¨è¾“å…¥çš„å‘ç°
        manual_discoveries = [
            {
                'title': 'åŸºäºESGè¯„çº§å˜åŒ–çš„åŠ¨é‡å› å­',
                'description': 'å½“å…¬å¸ESGè¯„çº§å‘ç”Ÿæ˜¾è‘—æå‡æ—¶ï¼Œå…¶è‚¡ä»·åœ¨éšå1-3ä¸ªæœˆå†…è¡¨ç°å‡ºæŒç»­çš„æ­£å‘åŠ¨é‡æ•ˆåº”',
                'theoretical_basis': 'åŸºäºESGæŠ•èµ„ç†å¿µçš„èµ„é‡‘æµå…¥å’Œä¼°å€¼é‡ä¼°ç†è®ºï¼Œç»“åˆè¡Œä¸ºé‡‘èå­¦ä¸­çš„é”šå®šæ•ˆåº”',
                'category': FactorCategory.SENTIMENT,
                'expected_alpha': 0.055,
                'data_requirements': ['esg_ratings', 'rating_changes', 'price_data', 'volume_data']
            },
            {
                'title': 'ä¾›åº”é“¾ç½‘ç»œä¸­å¿ƒæ€§å› å­',
                'description': 'åœ¨ä¾›åº”é“¾ç½‘ç»œä¸­å¤„äºä¸­å¿ƒä½ç½®çš„å…¬å¸ï¼Œåœ¨ä¾›åº”é“¾å†²å‡»äº‹ä»¶ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„éŸ§æ€§å’Œè¶…é¢æ”¶ç›Š',
                'theoretical_basis': 'ç½‘ç»œç†è®ºå’Œä¾›åº”é“¾ç®¡ç†ç†è®ºï¼Œä¸­å¿ƒæ€§èŠ‚ç‚¹å…·æœ‰æ›´å¼ºçš„è®®ä»·èƒ½åŠ›å’Œé£é™©åˆ†æ•£èƒ½åŠ›',
                'category': FactorCategory.FUNDAMENTAL,
                'expected_alpha': 0.041,
                'data_requirements': ['supply_chain_data', 'network_topology', 'financial_data']
            }
        ]
        
        print(f"ğŸ“ ç ”ç©¶å‘˜æ‰‹åŠ¨è¾“å…¥ {len(manual_discoveries)} ä¸ªå‘ç°:")
        
        for i, manual_discovery in enumerate(manual_discoveries, 1):
            print(f"\n   âœï¸ æ‰‹åŠ¨å‘ç° {i}: {manual_discovery['title']}")
            print(f"      æè¿°: {manual_discovery['description']}")
            print(f"      ç†è®ºåŸºç¡€: {manual_discovery['theoretical_basis'][:80]}...")
            print(f"      å› å­ç±»åˆ«: {manual_discovery['category'].value}")
            print(f"      é¢„æœŸAlpha: {manual_discovery['expected_alpha']:.3f}")
            print(f"      æ•°æ®éœ€æ±‚: {', '.join(manual_discovery['data_requirements'])}")
            
            # æ‰‹åŠ¨è¾“å…¥å‘ç°
            discovery_id = await self.sentinel.manual_discovery_input(
                title=manual_discovery['title'],
                description=manual_discovery['description'],
                theoretical_basis=manual_discovery['theoretical_basis'],
                factor_category=manual_discovery['category'],
                expected_alpha=manual_discovery['expected_alpha'],
                data_requirements=manual_discovery['data_requirements']
            )
            
            print(f"      âœ… æ‰‹åŠ¨å‘ç°å·²è®°å½• (ID: {discovery_id})")
    
    async def demonstrate_factor_implementation(self):
        """æ¼”ç¤ºå› å­è‡ªåŠ¨å®ç°"""
        print("\nğŸ”§ å› å­è‡ªåŠ¨å®ç°æ¼”ç¤º...")
        
        # é€‰æ‹©ä¸€ä¸ªé«˜ç½®ä¿¡åº¦çš„å‘ç°è¿›è¡Œå®ç°
        high_confidence_discoveries = [
            d for d in self.sentinel.discoveries.values() 
            if d.confidence_score >= 0.8 and d.status == ValidationStatus.DISCOVERED
        ]
        
        if not high_confidence_discoveries:
            print("   âš ï¸ æ²¡æœ‰æ‰¾åˆ°é«˜ç½®ä¿¡åº¦çš„å¾…å®ç°å‘ç°")
            return
        
        discovery = high_confidence_discoveries[0]
        print(f"ğŸ¯ é€‰æ‹©å®ç°å‘ç°: {discovery.title}")
        print(f"   ç½®ä¿¡åº¦: {discovery.confidence_score:.2f}")
        print(f"   å› å­ç±»åˆ«: {discovery.factor_category.value}")
        
        # è‡ªåŠ¨å®ç°å› å­
        print("\nğŸ¤– ä½¿ç”¨DeepSeek-R1è‡ªåŠ¨ç”Ÿæˆå› å­ä»£ç ...")
        implementation = await self.sentinel._generate_factor_code_with_deepseek(discovery)
        
        if implementation:
            print(f"âœ… å› å­ä»£ç ç”ŸæˆæˆåŠŸ:")
            print(f"   å› å­åç§°: {implementation.factor_name}")
            print(f"   å› å­å…¬å¼: {implementation.factor_formula}")
            print(f"   ä»£ç è´¨é‡è¯„åˆ†: {implementation.code_quality_score:.2f}")
            print(f"   ä¾èµ–åº“: {', '.join(implementation.dependencies)}")
            
            print(f"\nğŸ“ ç”Ÿæˆçš„Pythonä»£ç :")
            print("   " + "="*50)
            for line in implementation.python_code.split('\n'):
                if line.strip():
                    print(f"   {line}")
            print("   " + "="*50)
            
            # è¿è¡Œå›æµ‹éªŒè¯
            print(f"\nğŸ“Š è¿è¡Œå› å­å›æµ‹éªŒè¯...")
            validation_results = await self.sentinel._run_factor_backtest(implementation)
            
            # æ›´æ–°å®ç°æ€§èƒ½æŒ‡æ ‡
            implementation.ic_mean = validation_results['ic_mean']
            implementation.ic_std = validation_results['ic_std']
            implementation.ir_ratio = validation_results['ir_ratio']
            implementation.turnover = validation_results['turnover']
            
            print(f"âœ… å›æµ‹éªŒè¯å®Œæˆ:")
            print(f"   ICå‡å€¼: {implementation.ic_mean:.4f}")
            print(f"   ICæ ‡å‡†å·®: {implementation.ic_std:.4f}")
            print(f"   IRæ¯”ç‡: {implementation.ir_ratio:.4f}")
            print(f"   æ¢æ‰‹ç‡: {implementation.turnover:.2f}")
            print(f"   å¤æ™®æ¯”ç‡: {validation_results['sharpe_ratio']:.2f}")
            print(f"   æœ€å¤§å›æ’¤: {validation_results['max_drawdown']:.2%}")
            print(f"   èƒœç‡: {validation_results['win_rate']:.2%}")
            
            # åˆ¤æ–­æ˜¯å¦é€šè¿‡éªŒè¯
            if implementation.ic_mean > 0.02 and implementation.ir_ratio > 0.5:
                print(f"\nğŸ‰ å› å­éªŒè¯é€šè¿‡! æäº¤åˆ°Arenaæµ‹è¯•é˜Ÿåˆ—...")
                discovery.status = ValidationStatus.VALIDATED
                
                # æäº¤åˆ°Arenaæµ‹è¯•é˜Ÿåˆ—
                await self.sentinel._integrate_validated_factor(discovery, implementation)
                
                print(f"âœ… å› å­å·²æäº¤åˆ°Arenaæµ‹è¯•é˜Ÿåˆ—")
                print(f"   çŠ¶æ€: {discovery.status.value}")
                print(f"   ä¸‹ä¸€æ­¥: Arenaä¸‰è½¨æµ‹è¯• â†’ ç­–ç•¥ç”Ÿæˆ â†’ æ–¯å·´è¾¾è€ƒæ ¸ â†’ æ¨¡æ‹Ÿç›˜éªŒè¯ â†’ Z2Hè®¤è¯ â†’ ç­–ç•¥åº“")
            else:
                print(f"\nâŒ å› å­éªŒè¯æœªé€šè¿‡")
                print(f"   ICå‡å€¼ {implementation.ic_mean:.4f} {'âœ…' if implementation.ic_mean > 0.02 else 'âŒ'} (è¦æ±‚ > 0.02)")
                print(f"   IRæ¯”ç‡ {implementation.ir_ratio:.4f} {'âœ…' if implementation.ir_ratio > 0.5 else 'âŒ'} (è¦æ±‚ > 0.5)")
        else:
            print("âŒ å› å­ä»£ç ç”Ÿæˆå¤±è´¥")
    
    def demonstrate_discovery_statistics(self):
        """æ¼”ç¤ºå‘ç°ç»Ÿè®¡"""
        print("\nğŸ“Š å‘ç°ç»Ÿè®¡åˆ†æ...")
        
        stats = self.sentinel.get_discovery_statistics()
        
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»å‘ç°æ•°: {stats['total_discoveries']}")
        
        print(f"\nğŸ·ï¸ æŒ‰å‘ç°ç±»å‹åˆ†å¸ƒ:")
        for discovery_type, count in stats['by_type'].items():
            print(f"   â€¢ {discovery_type}: {count}")
        
        print(f"\nğŸ“‚ æŒ‰å› å­ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in stats['by_category'].items():
            print(f"   â€¢ {category}: {count}")
        
        print(f"\nğŸ‘¥ æŒ‰å‘ç°è€…åˆ†å¸ƒ:")
        for discoverer, count in stats['by_discoverer'].items():
            print(f"   â€¢ {discoverer}: {count}")
        
        print(f"\nğŸ”„ æŒ‰çŠ¶æ€åˆ†å¸ƒ:")
        for status, count in stats['by_status'].items():
            print(f"   â€¢ {status}: {count}")
        
        if stats['recent_discoveries']:
            print(f"\nğŸ•’ æœ€è¿‘å‘ç° (æœ€è¿‘7å¤©):")
            for discovery in stats['recent_discoveries'][:5]:
                print(f"   â€¢ {discovery['title']}")
                print(f"     æ—¶é—´: {discovery['discovered_at'][:19]}")
                print(f"     ç½®ä¿¡åº¦: {discovery['confidence_score']:.2f}")
                print(f"     çŠ¶æ€: {discovery['status']}")
        
        if stats['top_performers']:
            print(f"\nğŸ† é¡¶çº§è¡¨ç°è€… (å·²éªŒè¯å› å­):")
            for performer in stats['top_performers']:
                print(f"   â€¢ {performer['title']}")
                print(f"     é¢„æœŸAlpha: {performer['expected_alpha']:.3f}")
                print(f"     ç½®ä¿¡åº¦: {performer['confidence_score']:.2f}")
                print(f"     ç±»åˆ«: {performer['category']}")
    
    async def demonstrate_discovery_query(self):
        """æ¼”ç¤ºå‘ç°æŸ¥è¯¢"""
        print("\nğŸ” å‘ç°è¯¦æƒ…æŸ¥è¯¢æ¼”ç¤º...")
        
        if not self.sentinel.discoveries:
            print("   âš ï¸ æ²¡æœ‰å‘ç°è®°å½•å¯ä¾›æŸ¥è¯¢")
            return
        
        # é€‰æ‹©ä¸€ä¸ªå‘ç°è¿›è¡Œè¯¦æƒ…æŸ¥è¯¢
        discovery_id = list(self.sentinel.discoveries.keys())[0]
        discovery = self.sentinel.discoveries[discovery_id]
        
        print(f"ğŸ¯ æŸ¥è¯¢å‘ç°è¯¦æƒ…: {discovery.title}")
        
        details = await self.sentinel.get_discovery_details(discovery_id)
        
        if details:
            print(f"âœ… å‘ç°è¯¦æƒ…:")
            print(f"   ID: {details['discovery_id']}")
            print(f"   æ ‡é¢˜: {details['title']}")
            print(f"   ç±»å‹: {details['discovery_type']}")
            print(f"   ç±»åˆ«: {details['factor_category']}")
            print(f"   æ¥æº: {details['source']}")
            print(f"   å‘ç°æ—¶é—´: {details['discovered_at'][:19]}")
            print(f"   å‘ç°è€…: {details['discoverer']}")
            print(f"   é¢„æœŸAlpha: {details.get('expected_alpha', 'N/A')}")
            print(f"   ç½®ä¿¡åº¦: {details['confidence_score']:.2f}")
            print(f"   çŠ¶æ€: {details['status']}")
            print(f"   æ ‡ç­¾: {', '.join(details['tags'])}")
            
            if 'implementation' in details:
                impl = details['implementation']
                print(f"\nğŸ”§ å®ç°ä¿¡æ¯:")
                print(f"   å› å­ID: {impl['factor_id']}")
                print(f"   å› å­åç§°: {impl['factor_name']}")
                print(f"   å› å­å…¬å¼: {impl['factor_formula']}")
                if impl.get('ic_mean'):
                    print(f"   ICå‡å€¼: {impl['ic_mean']:.4f}")
                    print(f"   IRæ¯”ç‡: {impl['ir_ratio']:.4f}")
        else:
            print("âŒ æœªæ‰¾åˆ°å‘ç°è¯¦æƒ…")
    
    def demonstrate_factor_library_status(self):
        """æ¼”ç¤ºArenaæµ‹è¯•é˜Ÿåˆ—çŠ¶æ€"""
        print("\nğŸ“š Arenaæµ‹è¯•é˜Ÿåˆ—çŠ¶æ€å±•ç¤º...")
        
        # æ£€æŸ¥å¾…Arenaæµ‹è¯•å› å­ç´¢å¼•æ–‡ä»¶
        index_file = Path(self.temp_dir) / "pending_arena_factors_index.json"
        
        if index_file.exists():
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            print(f"ğŸ“– Arenaæµ‹è¯•é˜Ÿåˆ—:")
            print(f"   å¾…æµ‹è¯•å› å­æ•°é‡: {len(index_data)}")
            
            if index_data:
                print(f"\nğŸ“‹ å¾…Arenaæµ‹è¯•å› å­åˆ—è¡¨:")
                for i, factor in enumerate(index_data, 1):
                    print(f"   {i}. {factor['factor_name']}")
                    print(f"      ç±»åˆ«: {factor['category']}")
                    print(f"      ICå‡å€¼: {factor.get('ic_mean', 'N/A')}")
                    print(f"      IRæ¯”ç‡: {factor.get('ir_ratio', 'N/A')}")
                    print(f"      æäº¤æ—¶é—´: {factor['submitted_to_arena_at'][:19]}")
                    print(f"      å½“å‰çŠ¶æ€: {factor['status']}")
                    print(f"      ä¸‹ä¸€æ­¥: {factor['next_step']}")
                    print(f"      æ–‡ä»¶è·¯å¾„: {factor['file_path']}")
        else:
            print("   ğŸ“ Arenaæµ‹è¯•é˜Ÿåˆ—ä¸ºç©ºï¼Œå°šæ— å¾…æµ‹è¯•å› å­")
        
        # æ£€æŸ¥å¾…æµ‹è¯•å› å­æ–‡ä»¶
        pending_factors_dir = Path(self.temp_dir) / "pending_arena_factors"
        if pending_factors_dir.exists():
            factor_files = list(pending_factors_dir.glob("*.py"))
            print(f"\nğŸ“ å¾…Arenaæµ‹è¯•å› å­æ–‡ä»¶:")
            print(f"   æ–‡ä»¶æ•°é‡: {len(factor_files)}")
            
            for factor_file in factor_files[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"   â€¢ {factor_file.name}")
                # æ˜¾ç¤ºæ–‡ä»¶å‰å‡ è¡Œ
                with open(factor_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[:8]
                    for line in lines:
                        if line.strip():
                            print(f"     {line.rstrip()}")
                    if len(lines) >= 8:
                        print(f"     ...")
        
        print(f"\nğŸ’¡ è¯´æ˜:")
        print(f"   â€¢ å› å­æŒ–æ˜æ™ºèƒ½å“¨å…µè´Ÿè´£å‘ç°å’Œåˆæ­¥éªŒè¯å› å­")
        print(f"   â€¢ éªŒè¯é€šè¿‡çš„å› å­æäº¤åˆ°Arenaæµ‹è¯•é˜Ÿåˆ—")
        print(f"   â€¢ å®Œæ•´æµç¨‹: Arenaä¸‰è½¨æµ‹è¯• â†’ ç­–ç•¥ç”Ÿæˆ â†’ æ–¯å·´è¾¾è€ƒæ ¸ â†’ æ¨¡æ‹Ÿç›˜éªŒè¯ â†’ Z2Hè®¤è¯ â†’ ç­–ç•¥åº“")
        print(f"   â€¢ åªæœ‰é€šè¿‡å®Œæ•´éªŒè¯æµç¨‹çš„ç­–ç•¥æ‰èƒ½è¿›å…¥æœ€ç»ˆç­–ç•¥åº“")
    
    async def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        try:
            # 1. åˆå§‹åŒ–å“¨å…µ
            await self.initialize_sentinel()
            
            # 2. å­¦æœ¯è®ºæ–‡å‘ç°
            await self.demonstrate_academic_discovery()
            
            # 3. æ›¿ä»£æ•°æ®å‘ç°
            await self.demonstrate_alternative_data_discovery()
            
            # 4. å¸‚åœºå¼‚è±¡å‘ç°
            await self.demonstrate_market_anomaly_detection()
            
            # 5. æ‰‹åŠ¨å‘ç°è¾“å…¥
            await self.demonstrate_manual_discovery_input()
            
            # 6. å› å­è‡ªåŠ¨å®ç°
            await self.demonstrate_factor_implementation()
            
            # 7. å‘ç°ç»Ÿè®¡
            self.demonstrate_discovery_statistics()
            
            # 8. å‘ç°æŸ¥è¯¢
            await self.demonstrate_discovery_query()
            
            # 9. Arenaæµ‹è¯•é˜Ÿåˆ—çŠ¶æ€
            self.demonstrate_factor_library_status()
            
            print("\nğŸ‰ å› å­æŒ–æ˜æ™ºèƒ½å“¨å…µæ¼”ç¤ºå®Œæˆ!")
            print("=" * 60)
            print("ğŸ’¡ æ ¸å¿ƒä»·å€¼:")
            print("   â€¢ è‡ªåŠ¨è·Ÿè¸ªå‰æ²¿ç ”ç©¶ï¼Œæ°¸ä¸è½å")
            print("   â€¢ æ™ºèƒ½å‘ç°æ–°æ•°æ®æºï¼Œæ‹“å±•Alphaç©ºé—´")
            print("   â€¢ è‡ªåŠ¨å®ç°å’ŒéªŒè¯ï¼Œæé«˜ç ”å‘æ•ˆç‡")
            print("   â€¢ å®Œæ•´è®°å½•å‘ç°è¿‡ç¨‹ï¼Œç§¯ç´¯çŸ¥è¯†èµ„äº§")
            print("   â€¢ äººæœºåä½œå‘ç°ï¼Œç»“åˆä¸“ä¸šåˆ¤æ–­")
            print("=" * 60)
            
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    demo = FactorMiningIntelligenceSentinelDemo()
    await demo.run_complete_demo()


if __name__ == "__main__":
    asyncio.run(main())