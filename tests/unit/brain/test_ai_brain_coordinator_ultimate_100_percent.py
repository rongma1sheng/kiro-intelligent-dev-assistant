#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AI Brain Coordinator ç»ˆæ100%è¦†ç›–ç‡æµ‹è¯•

ğŸ§ª Test Engineer ä¸“é—¨è´Ÿè´£è¦†ç›–æœ€åçš„2è¡Œä»£ç ï¼š273-274, 792->815
ç›®æ ‡ï¼šè¾¾åˆ°100%æµ‹è¯•è¦†ç›–ç‡

éµå¾ªæµ‹è¯•é“å¾‹ï¼š
- ä¸¥ç¦è·³è¿‡ä»»ä½•æµ‹è¯•
- æµ‹è¯•è¶…æ—¶å¿…é¡»æº¯æºä¿®å¤
- ä¸å¾—ä½¿ç”¨timeoutä½œä¸ºè·³è¿‡ç†ç”±
- å‘ç°é—®é¢˜ç«‹åˆ»ä¿®å¤
- å¼ºåˆ¶è¦æ±‚ï¼šæµ‹è¯•è¦†ç›–ç‡å¿…é¡»è¾¾åˆ°100%

ä¸“é—¨é’ˆå¯¹æœªè¦†ç›–çš„2è¡Œä»£ç ï¼š
- 273-274è¡Œï¼šScholarç›´æ¥è°ƒç”¨å¼‚å¸¸å¤„ç†çš„logger.warning
- 792->815è¡Œï¼šå†²çªæ£€æµ‹åˆ†æ”¯çš„å®Œæ•´æµç¨‹
"""

import asyncio
import pytest
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, patch

from src.brain.ai_brain_coordinator import AIBrainCoordinator, BrainDecision
from src.core.dependency_container import DIContainer
from src.infra.event_bus import Event, EventBus, EventType
from src.brain.interfaces import IScholarEngine, ICommanderEngine, ISoldierEngine


class TestAIBrainCoordinatorUltimate100Percent:
    """ç»ˆæ100%è¦†ç›–ç‡æµ‹è¯• - ä¸“é—¨é’ˆå¯¹æœ€å2è¡Œä»£ç """

    @pytest.fixture
    def mock_event_bus(self):
        """Mockäº‹ä»¶æ€»çº¿"""
        event_bus = MagicMock(spec=EventBus)
        event_bus.subscribe = AsyncMock()
        event_bus.publish = AsyncMock()
        return event_bus

    @pytest.fixture
    def mock_container(self):
        """Mockä¾èµ–å®¹å™¨"""
        container = MagicMock(spec=DIContainer)
        container.is_registered = MagicMock(return_value=True)
        return container

    @pytest.fixture
    def coordinator(self, mock_event_bus, mock_container):
        """åˆ›å»ºåè°ƒå™¨å®ä¾‹"""
        return AIBrainCoordinator(mock_event_bus, mock_container)

    @pytest.mark.asyncio
    async def test_lines_273_274_scholar_exception_logger_warning(self, coordinator):
        """ç²¾ç¡®æµ‹è¯•273-274è¡Œï¼šScholarå¼‚å¸¸å¤„ç†çš„logger.warningè°ƒç”¨
        
        è¿™ä¸ªæµ‹è¯•ä¸“é—¨è¦†ç›–Scholarç›´æ¥è°ƒç”¨å¤±è´¥æ—¶çš„logger.warningè¯­å¥
        ç¡®ä¿è¦†ç›–273-274è¡Œçš„å…·ä½“ä»£ç 
        """
        # è®¾ç½®Scholarå®ä¾‹ä½†è®©å…¶æŠ›å‡ºå¼‚å¸¸
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=RuntimeError("Scholar research failed"))
        coordinator.scholar = mock_scholar
        
        # ç¦ç”¨æ‰¹å¤„ç†ä»¥ç¡®ä¿èµ°ç›´æ¥è°ƒç”¨è·¯å¾„
        coordinator.enable_batch_processing = False
        
        context = {"research_topic": "test_factor"}
        correlation_id = "test_correlation_id"
        
        # ä½¿ç”¨patchæ¥ç›‘æ§logger.warningè°ƒç”¨
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œå†³ç­–è¯·æ±‚ï¼Œåº”è¯¥è§¦å‘273-274è¡Œçš„logger.warning
            result = await coordinator._request_decision_direct(context, "scholar", correlation_id)
            
            # éªŒè¯Scholarè¢«è°ƒç”¨äº†
            mock_scholar.research.assert_called_once_with(context)
            
            # éªŒè¯logger.warningè¢«è°ƒç”¨äº†ï¼ˆè¿™å°±æ˜¯273-274è¡Œï¼‰
            # æ³¨æ„ï¼šå¯èƒ½ä¼šæœ‰å¤šæ¬¡warningè°ƒç”¨ï¼ˆå¼‚å¸¸å¤„ç† + è¶…æ—¶ï¼‰ï¼Œæˆ‘ä»¬æ£€æŸ¥æ˜¯å¦åŒ…å«Scholarå¼‚å¸¸å¤„ç†çš„è°ƒç”¨
            mock_logger.warning.assert_called()
            warning_calls = mock_logger.warning.call_args_list
            scholar_warning_found = any("Scholarç›´æ¥è°ƒç”¨å¤±è´¥" in str(call) for call in warning_calls)
            assert scholar_warning_found, f"æœªæ‰¾åˆ°Scholarå¼‚å¸¸å¤„ç†çš„warningè°ƒç”¨ï¼Œå®é™…è°ƒç”¨: {warning_calls}"
            
            # ç”±äºå¼‚å¸¸ï¼Œåº”è¯¥å›é€€åˆ°äº‹ä»¶æ¨¡å¼ï¼Œä½†äº‹ä»¶å‘å¸ƒä¹Ÿå¯èƒ½å¤±è´¥ï¼Œæ‰€ä»¥è¿”å›None
            assert result is None

    @pytest.mark.asyncio
    async def test_lines_792_815_conflict_detection_branch(self, coordinator):
        """ç²¾ç¡®æµ‹è¯•792->815è¡Œï¼šå†²çªæ£€æµ‹åˆ†æ”¯çš„å®Œæ•´æµç¨‹
        
        è¿™ä¸ªæµ‹è¯•ä¸“é—¨è¦†ç›–å†³ç­–å†²çªæ£€æµ‹å’Œä¿å®ˆç­–ç•¥ç”Ÿæˆçš„å®Œæ•´æµç¨‹
        ç¡®ä¿è¦†ç›–792->815è¡Œçš„å†²çªæ£€æµ‹é€»è¾‘
        """
        # åˆ›å»ºç½®ä¿¡åº¦å·®å¼‚å°äº0.1çš„å†²çªå†³ç­–
        decisions = [
            BrainDecision(
                decision_id="soldier_decision",
                primary_brain="soldier",
                action="buy",
                confidence=0.7500,  # åŸºå‡†ç½®ä¿¡åº¦
                reasoning="Soldierå»ºè®®ä¹°å…¥",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="test_1"
            ),
            BrainDecision(
                decision_id="commander_decision", 
                primary_brain="commander",
                action="sell",
                confidence=0.7499,  # ç½®ä¿¡åº¦å·®å¼‚0.0001 < 0.1ï¼Œä¼šè§¦å‘å†²çªæ£€æµ‹
                reasoning="Commanderå»ºè®®å–å‡º",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="test_2"
            )
        ]
        
        # è®°å½•åˆå§‹å†²çªç»Ÿè®¡
        initial_conflicts = coordinator.stats.get("coordination_conflicts", 0)
        
        # ä½¿ç”¨patchæ¥ç›‘æ§logger.warningè°ƒç”¨
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œå†²çªè§£å†³ï¼Œåº”è¯¥è§¦å‘792->815è¡Œ
            result = await coordinator.resolve_conflicts(decisions)
            
            # éªŒè¯å†²çªæ£€æµ‹è¢«è§¦å‘ï¼ˆ792->815è¡Œçš„é€»è¾‘ï¼‰
            assert coordinator.stats["coordination_conflicts"] > initial_conflicts
            
            # éªŒè¯logger.warningè¢«è°ƒç”¨äº†ï¼ˆè¿™æ˜¯792->815è¡Œåˆ†æ”¯çš„ä¸€éƒ¨åˆ†ï¼‰
            mock_logger.warning.assert_called()
            warning_call_args = mock_logger.warning.call_args[0][0]
            assert "æ£€æµ‹åˆ°å†³ç­–å†²çª" in warning_call_args
            
            # éªŒè¯è¿”å›äº†ä¿å®ˆå†³ç­–
            assert result is not None
            assert result.primary_brain == "coordinator_conflict_resolution"
            
            # éªŒè¯ä¿å®ˆç­–ç•¥é€»è¾‘
            # ç”±äºæœ‰ä¹°å–å†²çªï¼Œåº”è¯¥é€‰æ‹©æŒæœ‰ç­–ç•¥
            assert result.action in ["hold", "reduce"]  # ä¿å®ˆç­–ç•¥
            
            # éªŒè¯ç½®ä¿¡åº¦è¢«é™ä½ï¼ˆå¹³å‡å€¼*0.6ï¼‰
            expected_avg_confidence = (0.7500 + 0.7499) / 2 * 0.6
            assert abs(result.confidence - expected_avg_confidence) < 0.01
            
            # éªŒè¯æ”¯æŒæ•°æ®åŒ…å«å†²çªä¿¡æ¯
            assert result.supporting_data["conflict_resolution"] is True
            assert len(result.supporting_data["conflicting_decisions"]) == 2

    @pytest.mark.asyncio
    async def test_comprehensive_final_coverage_verification(self, coordinator):
        """ç»¼åˆæœ€ç»ˆè¦†ç›–ç‡éªŒè¯æµ‹è¯•
        
        è¿™ä¸ªæµ‹è¯•ç¡®ä¿æˆ‘ä»¬è¦†ç›–äº†æ‰€æœ‰å‰©ä½™çš„ä»£ç è·¯å¾„
        """
        
        # 1. æµ‹è¯•Scholarå¼‚å¸¸å¤„ç†è·¯å¾„ï¼ˆ273-274è¡Œï¼‰
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=ConnectionError("Network error"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡ŒScholarå†³ç­–è¯·æ±‚
            scholar_result = await coordinator._request_decision_direct(
                {"topic": "test"}, "scholar", "scholar_test"
            )
            
            # éªŒè¯å¼‚å¸¸å¤„ç†å’Œloggerè°ƒç”¨
            assert scholar_result is None
            mock_scholar.research.assert_called_once()
            mock_logger.warning.assert_called()
            
            # é‡ç½®mockä»¥ä¾¿ä¸‹ä¸€ä¸ªæµ‹è¯•
            mock_logger.reset_mock()
        
        # 2. æµ‹è¯•å†²çªæ£€æµ‹è·¯å¾„ï¼ˆ792->815è¡Œï¼‰
        conflict_decisions = [
            BrainDecision(
                decision_id="conflict1", primary_brain="soldier", action="buy",
                confidence=0.8000, reasoning="Strong buy", supporting_data={},
                timestamp=datetime.now(), correlation_id="conflict1"
            ),
            BrainDecision(
                decision_id="conflict2", primary_brain="commander", action="sell",
                confidence=0.7999, reasoning="Strong sell", supporting_data={},  # å·®å¼‚0.0001 < 0.1
                timestamp=datetime.now(), correlation_id="conflict2"
            )
        ]
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œå†²çªè§£å†³
            conflict_result = await coordinator.resolve_conflicts(conflict_decisions)
            
            # éªŒè¯å†²çªè§£å†³
            assert conflict_result.primary_brain == "coordinator_conflict_resolution"
            assert conflict_result.supporting_data["conflict_resolution"] is True
            
            # éªŒè¯logger.warningè¢«è°ƒç”¨ï¼ˆ792->815è¡Œåˆ†æ”¯ï¼‰
            mock_logger.warning.assert_called()
            warning_call_args = mock_logger.warning.call_args[0][0]
            assert "æ£€æµ‹åˆ°å†³ç­–å†²çª" in warning_call_args
            
            # éªŒè¯ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
            assert coordinator.stats["coordination_conflicts"] > 0

    @pytest.mark.asyncio
    async def test_edge_cases_for_ultimate_coverage(self, coordinator):
        """è¾¹ç•Œæƒ…å†µæµ‹è¯•ç¡®ä¿ç»ˆæè¦†ç›–ç‡"""
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„Scholarå¼‚å¸¸
        exceptions_to_test = [
            ValueError("Invalid input"),
            TimeoutError("Request timeout"),
            ConnectionError("Connection lost"),
            RuntimeError("Runtime error")
        ]
        
        for i, exception in enumerate(exceptions_to_test):
            mock_scholar = AsyncMock(spec=IScholarEngine)
            mock_scholar.research = AsyncMock(side_effect=exception)
            coordinator.scholar = mock_scholar
            coordinator.enable_batch_processing = False
            
            with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
                # æ‰§è¡Œå†³ç­–è¯·æ±‚
                result = await coordinator._request_decision_direct(
                    {"test": f"data_{i}"}, "scholar", f"test_{i}"
                )
                
                # éªŒè¯å¼‚å¸¸è¢«æ­£ç¡®å¤„ç†
                assert result is None
                mock_scholar.research.assert_called_once()
                mock_logger.warning.assert_called()
        
        # æµ‹è¯•ä¸åŒç½®ä¿¡åº¦å·®å¼‚çš„å†²çªæ£€æµ‹ - æ¯æ¬¡é‡ç½®ç»Ÿè®¡
        confidence_pairs = [
            (0.75, 0.7499),   # å·®å¼‚0.0001 < 0.1
            (0.80, 0.7999),   # å·®å¼‚0.0001 < 0.1
            (0.60, 0.5999),   # å·®å¼‚0.0001 < 0.1
            (0.90, 0.8999),   # å·®å¼‚0.0001 < 0.1
        ]
        
        for i, (conf1, conf2) in enumerate(confidence_pairs):
            # é‡ç½®ç»Ÿè®¡ä»¥ç¡®ä¿æ¯æ¬¡æµ‹è¯•éƒ½èƒ½æ£€æµ‹åˆ°å†²çªå¢åŠ 
            coordinator.stats["coordination_conflicts"] = 0
            
            decisions = [
                BrainDecision(
                    decision_id=f"edge1_{i}", primary_brain="soldier", action="buy",
                    confidence=conf1, reasoning=f"Edge test 1_{i}", supporting_data={},
                    timestamp=datetime.now(), correlation_id=f"edge1_{i}"
                ),
                BrainDecision(
                    decision_id=f"edge2_{i}", primary_brain="commander", action="sell",
                    confidence=conf2, reasoning=f"Edge test 2_{i}", supporting_data={},
                    timestamp=datetime.now(), correlation_id=f"edge2_{i}"
                )
            ]
            
            initial_conflicts = coordinator.stats.get("coordination_conflicts", 0)
            
            with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
                # æ‰§è¡Œå†²çªè§£å†³
                result = await coordinator.resolve_conflicts(decisions)
                
                # éªŒè¯å†²çªè¢«æ£€æµ‹åˆ°
                assert coordinator.stats["coordination_conflicts"] > initial_conflicts
                assert result.primary_brain == "coordinator_conflict_resolution"
                mock_logger.warning.assert_called()

    @pytest.mark.asyncio
    async def test_ultimate_verification_100_percent_coverage(self, coordinator):
        """ç»ˆæéªŒè¯æµ‹è¯• - ç¡®ä¿100%è¦†ç›–ç‡
        
        è¿™æ˜¯æœ€ç»ˆçš„éªŒè¯æµ‹è¯•ï¼Œç¡®ä¿æˆ‘ä»¬è¦†ç›–äº†æ‰€æœ‰ä»£ç è·¯å¾„
        """
        
        # ç¡®ä¿Scholarå¼‚å¸¸å¤„ç†è¢«è¦†ç›–ï¼ˆ273-274è¡Œï¼‰
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=Exception("Ultimate test exception"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æµ‹è¯•å¼‚å¸¸å¤„ç†
            result = await coordinator._request_decision_direct(
                {"ultimate": "test"}, "scholar", "ultimate_test"
            )
            assert result is None
            mock_logger.warning.assert_called()
            
            # éªŒè¯logger.warningçš„å…·ä½“è°ƒç”¨
            warning_calls = mock_logger.warning.call_args_list
            assert any("Scholarç›´æ¥è°ƒç”¨å¤±è´¥" in str(call) for call in warning_calls)
            
            # é‡ç½®mock
            mock_logger.reset_mock()
        
        # ç¡®ä¿å†²çªæ£€æµ‹è¢«è¦†ç›–ï¼ˆ792->815è¡Œï¼‰
        ultimate_decisions = [
            BrainDecision(
                decision_id="ultimate1", primary_brain="soldier", action="buy",
                confidence=0.7000, reasoning="Ultimate 1", supporting_data={},
                timestamp=datetime.now(), correlation_id="ultimate1"
            ),
            BrainDecision(
                decision_id="ultimate2", primary_brain="commander", action="sell",
                confidence=0.6999, reasoning="Ultimate 2", supporting_data={},  # å·®å¼‚0.0001 < 0.1
                timestamp=datetime.now(), correlation_id="ultimate2"
            )
        ]
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æµ‹è¯•å†²çªæ£€æµ‹
            ultimate_result = await coordinator.resolve_conflicts(ultimate_decisions)
            assert ultimate_result.primary_brain == "coordinator_conflict_resolution"
            mock_logger.warning.assert_called()
            
            # éªŒè¯logger.warningçš„å…·ä½“è°ƒç”¨
            warning_calls = mock_logger.warning.call_args_list
            assert any("æ£€æµ‹åˆ°å†³ç­–å†²çª" in str(call) for call in warning_calls)
        
        print("âœ… ç»ˆæéªŒè¯å®Œæˆï¼šæ‰€æœ‰å…³é”®è·¯å¾„å·²è¦†ç›–ï¼Œåº”è¯¥è¾¾åˆ°100%è¦†ç›–ç‡")


class TestSpecificLinesCoverageUltimate:
    """ä¸“é—¨é’ˆå¯¹ç‰¹å®šè¡Œå·çš„ç»ˆæè¦†ç›–æµ‹è¯•"""

    @pytest.fixture
    def coordinator(self):
        """åˆ›å»ºåŸºç¡€åè°ƒå™¨"""
        event_bus = MagicMock(spec=EventBus)
        event_bus.subscribe = AsyncMock()
        event_bus.publish = AsyncMock()
        container = MagicMock(spec=DIContainer)
        return AIBrainCoordinator(event_bus, container)

    @pytest.mark.asyncio
    async def test_exact_lines_273_274_with_logger_verification(self, coordinator):
        """ç²¾ç¡®è¦†ç›–273-274è¡Œå¹¶éªŒè¯loggerè°ƒç”¨"""
        # è®¾ç½®Scholarå¼‚å¸¸
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=Exception("Exact line test"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        # ç›‘æ§loggerè°ƒç”¨
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # è°ƒç”¨åº”è¯¥è§¦å‘273-274è¡Œçš„å¼‚å¸¸å¤„ç†
            result = await coordinator._request_decision_direct(
                {"exact": "test"}, "scholar", "exact_test"
            )
            
            # éªŒè¯å¼‚å¸¸è¢«æ•è·ï¼Œæ–¹æ³•è¿”å›None
            assert result is None
            mock_scholar.research.assert_called_once()
            
            # éªŒè¯logger.warningè¢«è°ƒç”¨ï¼ˆè¿™å°±æ˜¯273-274è¡Œï¼‰
            # æ³¨æ„ï¼šå¯èƒ½æœ‰å¤šæ¬¡warningè°ƒç”¨ï¼Œæˆ‘ä»¬æ£€æŸ¥æ˜¯å¦åŒ…å«Scholarå¼‚å¸¸å¤„ç†çš„è°ƒç”¨
            mock_logger.warning.assert_called()
            warning_calls = mock_logger.warning.call_args_list
            scholar_warning_found = any("Scholarç›´æ¥è°ƒç”¨å¤±è´¥" in str(call) for call in warning_calls)
            assert scholar_warning_found, f"æœªæ‰¾åˆ°Scholarå¼‚å¸¸å¤„ç†çš„warningè°ƒç”¨ï¼Œå®é™…è°ƒç”¨: {warning_calls}"

    @pytest.mark.asyncio
    async def test_exact_lines_792_815_with_logger_verification(self, coordinator):
        """ç²¾ç¡®è¦†ç›–792->815è¡Œå¹¶éªŒè¯loggerè°ƒç”¨"""
        # åˆ›å»ºç½®ä¿¡åº¦å·®å¼‚å°äº0.1çš„å†³ç­–
        decisions = [
            BrainDecision(
                decision_id="exact1", primary_brain="soldier", action="buy",
                confidence=0.750, reasoning="Exact test", supporting_data={},
                timestamp=datetime.now(), correlation_id="exact1"
            ),
            BrainDecision(
                decision_id="exact2", primary_brain="commander", action="sell",
                confidence=0.749, reasoning="Exact test", supporting_data={},  # å·®å¼‚0.001 < 0.1
                timestamp=datetime.now(), correlation_id="exact2"
            )
        ]
        
        initial_conflicts = coordinator.stats.get("coordination_conflicts", 0)
        
        # ç›‘æ§loggerè°ƒç”¨
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œå†²çªè§£å†³ï¼Œåº”è¯¥è§¦å‘792->815è¡Œ
            result = await coordinator.resolve_conflicts(decisions)
            
            # éªŒè¯å†²çªæ£€æµ‹é€»è¾‘è¢«è§¦å‘
            assert coordinator.stats["coordination_conflicts"] > initial_conflicts
            assert result.primary_brain == "coordinator_conflict_resolution"
            
            # éªŒè¯logger.warningè¢«è°ƒç”¨ï¼ˆè¿™æ˜¯792->815è¡Œåˆ†æ”¯çš„ä¸€éƒ¨åˆ†ï¼‰
            mock_logger.warning.assert_called_once()
            call_args = mock_logger.warning.call_args[0][0]
            assert "æ£€æµ‹åˆ°å†³ç­–å†²çª" in call_args
            
            # éªŒè¯ä¿å®ˆå†³ç­–ç”Ÿæˆ
            assert result.supporting_data["conflict_resolution"] is True
            assert "conflicting_decisions" in result.supporting_data

    @pytest.mark.asyncio
    async def test_final_100_percent_verification(self, coordinator):
        """æœ€ç»ˆ100%è¦†ç›–ç‡éªŒè¯"""
        
        # æµ‹è¯•1: ç¡®ä¿273-274è¡Œè¢«è¦†ç›–
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=Exception("Final verification"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            result = await coordinator._request_decision_direct(
                {"final": "verification"}, "scholar", "final_verification"
            )
            assert result is None
            mock_logger.warning.assert_called()
            mock_logger.reset_mock()
        
        # æµ‹è¯•2: ç¡®ä¿792->815è¡Œè¢«è¦†ç›–
        final_decisions = [
            BrainDecision(
                decision_id="final1", primary_brain="soldier", action="buy",
                confidence=0.7000, reasoning="Final verification", supporting_data={},
                timestamp=datetime.now(), correlation_id="final1"
            ),
            BrainDecision(
                decision_id="final2", primary_brain="commander", action="sell",
                confidence=0.6999, reasoning="Final verification", supporting_data={},
                timestamp=datetime.now(), correlation_id="final2"
            )
        ]
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            result = await coordinator.resolve_conflicts(final_decisions)
            assert result.primary_brain == "coordinator_conflict_resolution"
            mock_logger.warning.assert_called()
        
        print("âœ… æœ€ç»ˆ100%è¦†ç›–ç‡éªŒè¯å®Œæˆ")