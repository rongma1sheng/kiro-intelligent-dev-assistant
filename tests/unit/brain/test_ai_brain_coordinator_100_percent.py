#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AI Brain Coordinator 100%è¦†ç›–ç‡æµ‹è¯•

ğŸ§ª Test Engineer ä¸“é—¨è´Ÿè´£è¾¾åˆ°100%æµ‹è¯•è¦†ç›–ç‡
ç›®æ ‡ï¼šè¦†ç›–å‰©ä½™çš„6è¡Œä»£ç ï¼š273-274, 457-461, 792->815

éµå¾ªæµ‹è¯•é“å¾‹ï¼š
- ä¸¥ç¦è·³è¿‡ä»»ä½•æµ‹è¯•
- æµ‹è¯•è¶…æ—¶å¿…é¡»æº¯æºä¿®å¤
- ä¸å¾—ä½¿ç”¨timeoutä½œä¸ºè·³è¿‡ç†ç”±
- å‘ç°é—®é¢˜ç«‹åˆ»ä¿®å¤
- å¼ºåˆ¶è¦æ±‚ï¼šæµ‹è¯•è¦†ç›–ç‡å¿…é¡»è¾¾åˆ°100%
"""

import asyncio
import pytest
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, patch

from src.brain.ai_brain_coordinator import AIBrainCoordinator, BrainDecision
from src.core.dependency_container import DIContainer
from src.infra.event_bus import Event, EventBus, EventType
from src.brain.interfaces import IScholarEngine, ICommanderEngine, ISoldierEngine


class TestAIBrainCoordinator100Percent:
    """ä¸“é—¨é’ˆå¯¹100%è¦†ç›–ç‡çš„æµ‹è¯•"""

    @pytest.fixture
    def mock_event_bus(self):
        """Mockäº‹ä»¶æ€»çº¿"""
        event_bus = MagicMock(spec=EventBus)
        event_bus.subscribe = AsyncMock()
        event_bus.publish = AsyncMock()
        return event_bus

    @pytest.fixture
    def mock_container(self):
        """Mockä¾èµ–å®¹å™¨"""
        container = MagicMock(spec=DIContainer)
        container.is_registered = MagicMock(return_value=True)
        return container

    @pytest.fixture
    def coordinator(self, mock_event_bus, mock_container):
        """åˆ›å»ºåè°ƒå™¨å®ä¾‹"""
        return AIBrainCoordinator(mock_event_bus, mock_container)

    @pytest.mark.asyncio
    async def test_scholar_direct_call_exception_lines_273_274(self, coordinator):
        """æµ‹è¯•Scholarç›´æ¥è°ƒç”¨å¼‚å¸¸å¤„ç† - è¦†ç›–273-274è¡Œ
        
        è¿™ä¸ªæµ‹è¯•ä¸“é—¨è¦†ç›–Scholarç›´æ¥è°ƒç”¨å¤±è´¥æ—¶çš„å¼‚å¸¸å¤„ç†é€»è¾‘
        """
        # è®¾ç½®Scholarå®ä¾‹ä½†è®©å…¶æŠ›å‡ºå¼‚å¸¸
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=Exception("Scholar research failed"))
        coordinator.scholar = mock_scholar
        
        # ç¦ç”¨æ‰¹å¤„ç†ä»¥ç¡®ä¿èµ°ç›´æ¥è°ƒç”¨è·¯å¾„
        coordinator.enable_batch_processing = False
        
        context = {"research_topic": "test_factor"}
        
        # æ‰§è¡Œå†³ç­–è¯·æ±‚ï¼Œåº”è¯¥æ•è·å¼‚å¸¸å¹¶å›é€€åˆ°äº‹ä»¶æ¨¡å¼
        result = await coordinator._request_decision_direct(context, "scholar", "test_correlation_id")
        
        # éªŒè¯Scholarè¢«è°ƒç”¨äº†
        mock_scholar.research.assert_called_once_with(context)
        
        # ç”±äºå¼‚å¸¸ï¼Œåº”è¯¥å›é€€åˆ°äº‹ä»¶æ¨¡å¼ï¼Œä½†äº‹ä»¶å‘å¸ƒä¹Ÿå¯èƒ½å¤±è´¥ï¼Œæ‰€ä»¥è¿”å›None
        # è¿™ä¼šè§¦å‘è¶…æ—¶å¤„ç†é€»è¾‘
        assert result is None

    @pytest.mark.asyncio
    async def test_batch_decision_exception_handling_lines_457_461(self, coordinator):
        """æµ‹è¯•æ‰¹é‡å†³ç­–å¼‚å¸¸å¤„ç† - è¦†ç›–457-461è¡Œ
        
        è¿™ä¸ªæµ‹è¯•ä¸“é—¨è¦†ç›–æ‰¹é‡å†³ç­–ä¸­çš„å¼‚å¸¸å¤„ç†å’Œå¤‡ç”¨å†³ç­–ç”Ÿæˆ
        """
        # åˆ›å»ºä¼šå¤±è´¥çš„è¯·æ±‚
        requests = [
            ({"data": "test1"}, "soldier"),
            ({"data": "test2"}, "commander"),  # è¿™ä¸ªä¼šå¤±è´¥
            ({"data": "test3"}, "scholar")
        ]
        
        # Mock request_decisionæ–¹æ³•è®©ç¬¬äºŒä¸ªè¯·æ±‚å¤±è´¥
        original_method = coordinator.request_decision
        
        async def mock_request_decision(context, brain):
            if context.get("data") == "test2":
                raise Exception("Commander decision failed")
            # ä¸ºå…¶ä»–è¯·æ±‚è¿”å›æ­£å¸¸å†³ç­–
            return BrainDecision(
                decision_id=f"{brain}_test",
                primary_brain=brain,
                action="buy",
                confidence=0.8,
                reasoning="æµ‹è¯•å†³ç­–",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id=f"test_{brain}"
            )
        
        coordinator.request_decision = AsyncMock(side_effect=mock_request_decision)
        
        # æ‰§è¡Œæ‰¹é‡å†³ç­–
        results = await coordinator.request_decisions_batch(requests)
        
        # éªŒè¯ç»“æœ
        assert len(results) == 3
        
        # ç¬¬ä¸€ä¸ªå’Œç¬¬ä¸‰ä¸ªåº”è¯¥æˆåŠŸ
        assert results[0].primary_brain == "soldier"
        assert results[2].primary_brain == "scholar"
        
        # ç¬¬äºŒä¸ªåº”è¯¥æ˜¯å¤‡ç”¨å†³ç­–ï¼ˆç”±äºå¼‚å¸¸ï¼‰
        assert "fallback" in results[1].decision_id
        assert results[1].primary_brain.startswith("coordinator_fallback")

    @pytest.mark.asyncio
    async def test_conflict_detection_lines_792_815(self, coordinator):
        """æµ‹è¯•å†²çªæ£€æµ‹é€»è¾‘ - è¦†ç›–792->815è¡Œ
        
        è¿™ä¸ªæµ‹è¯•ä¸“é—¨è¦†ç›–å†³ç­–å†²çªæ£€æµ‹å’Œä¿å®ˆç­–ç•¥ç”Ÿæˆçš„å®Œæ•´æµç¨‹
        """
        # åˆ›å»ºç½®ä¿¡åº¦ç›¸è¿‘çš„å†²çªå†³ç­–ï¼ˆå·®å¼‚<0.1ï¼‰
        decisions = [
            BrainDecision(
                decision_id="soldier_decision",
                primary_brain="soldier",
                action="buy",
                confidence=0.75,  # åŸºå‡†ç½®ä¿¡åº¦
                reasoning="Soldierå»ºè®®ä¹°å…¥",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="test_1"
            ),
            BrainDecision(
                decision_id="commander_decision", 
                primary_brain="commander",
                action="sell",
                confidence=0.74,  # ç½®ä¿¡åº¦å·®å¼‚0.01 < 0.1ï¼Œä¼šè§¦å‘å†²çªæ£€æµ‹
                reasoning="Commanderå»ºè®®å–å‡º",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="test_2"
            ),
            BrainDecision(
                decision_id="scholar_decision",
                primary_brain="scholar", 
                action="hold",
                confidence=0.73,  # ç½®ä¿¡åº¦å·®å¼‚0.02 < 0.1
                reasoning="Scholarå»ºè®®æŒæœ‰",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="test_3"
            )
        ]
        
        # è®°å½•åˆå§‹å†²çªç»Ÿè®¡
        initial_conflicts = coordinator.stats.get("coordination_conflicts", 0)
        
        # æ‰§è¡Œå†²çªè§£å†³
        result = await coordinator.resolve_conflicts(decisions)
        
        # éªŒè¯å†²çªæ£€æµ‹è¢«è§¦å‘
        assert coordinator.stats["coordination_conflicts"] > initial_conflicts
        
        # éªŒè¯è¿”å›äº†ä¿å®ˆå†³ç­–
        assert result is not None
        assert result.primary_brain == "coordinator_conflict_resolution"
        
        # éªŒè¯ä¿å®ˆç­–ç•¥é€»è¾‘
        # ç”±äºæœ‰ä¹°å–å†²çªï¼Œåº”è¯¥é€‰æ‹©æŒæœ‰ç­–ç•¥
        assert result.action in ["hold", "reduce"]  # ä¿å®ˆç­–ç•¥
        
        # éªŒè¯ç½®ä¿¡åº¦è¢«é™ä½ï¼ˆå¹³å‡å€¼*0.6ï¼‰
        expected_avg_confidence = (0.75 + 0.74 + 0.73) / 3 * 0.6
        assert abs(result.confidence - expected_avg_confidence) < 0.01
        
        # éªŒè¯æ”¯æŒæ•°æ®åŒ…å«å†²çªä¿¡æ¯
        assert result.supporting_data["conflict_resolution"] is True
        assert len(result.supporting_data["conflicting_decisions"]) == 3

    @pytest.mark.asyncio
    async def test_comprehensive_coverage_scenario(self, coordinator):
        """ç»¼åˆæµ‹è¯•åœºæ™¯ - ç¡®ä¿è¦†ç›–æ‰€æœ‰è¾¹ç•Œæƒ…å†µ"""
        
        # 1. æµ‹è¯•Scholarå¼‚å¸¸å¤„ç†
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=RuntimeError("Network error"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        # è¿™åº”è¯¥è§¦å‘273-274è¡Œçš„å¼‚å¸¸å¤„ç†
        result1 = await coordinator._request_decision_direct(
            {"topic": "test"}, "scholar", "correlation_1"
        )
        assert result1 is None  # å¼‚å¸¸å¯¼è‡´è¿”å›None
        
        # 2. æµ‹è¯•æ‰¹é‡å†³ç­–å¼‚å¸¸
        async def failing_request_decision(context, brain):
            if "fail" in context:
                raise ValueError("Simulated failure")
            return BrainDecision(
                decision_id="success",
                primary_brain=brain,
                action="hold",
                confidence=0.5,
                reasoning="Success",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="success"
            )
        
        coordinator.request_decision = AsyncMock(side_effect=failing_request_decision)
        
        # è¿™åº”è¯¥è§¦å‘457-461è¡Œçš„å¼‚å¸¸å¤„ç†
        batch_requests = [
            ({"normal": True}, "soldier"),
            ({"fail": True}, "commander"),  # è¿™ä¸ªä¼šå¤±è´¥
        ]
        
        results = await coordinator.request_decisions_batch(batch_requests)
        assert len(results) == 2
        assert results[0].decision_id == "success"
        assert "fallback" in results[1].decision_id
        
        # 3. æµ‹è¯•å†²çªæ£€æµ‹çš„å®Œæ•´è·¯å¾„
        conflict_decisions = [
            BrainDecision(
                decision_id="d1", primary_brain="soldier", action="buy",
                confidence=0.80, reasoning="Buy signal", supporting_data={},
                timestamp=datetime.now(), correlation_id="c1"
            ),
            BrainDecision(
                decision_id="d2", primary_brain="commander", action="sell", 
                confidence=0.79, reasoning="Sell signal", supporting_data={},
                timestamp=datetime.now(), correlation_id="c2"
            )
        ]
        
        # è¿™åº”è¯¥è§¦å‘792->815è¡Œçš„å†²çªæ£€æµ‹é€»è¾‘
        conflict_result = await coordinator.resolve_conflicts(conflict_decisions)
        
        # éªŒè¯å†²çªè¢«æ­£ç¡®å¤„ç†
        assert conflict_result.primary_brain == "coordinator_conflict_resolution"
        assert conflict_result.supporting_data["conflict_resolution"] is True

    @pytest.mark.asyncio
    async def test_edge_cases_for_complete_coverage(self, coordinator):
        """è¾¹ç•Œæƒ…å†µæµ‹è¯• - ç¡®ä¿100%è¦†ç›–ç‡"""
        
        # æµ‹è¯•ç©ºçš„å†²çªå†³ç­–åˆ—è¡¨ï¼ˆè™½ç„¶è¿™ä¸ªåœ¨å…¶ä»–åœ°æ–¹å¯èƒ½å·²ç»æµ‹è¯•è¿‡ï¼‰
        empty_result = await coordinator.resolve_conflicts([])
        assert "fallback" in empty_result.decision_id
        
        # æµ‹è¯•å•ä¸ªå†³ç­–ï¼ˆæ— å†²çªï¼‰
        single_decision = [BrainDecision(
            decision_id="single", primary_brain="soldier", action="buy",
            confidence=0.9, reasoning="Single", supporting_data={},
            timestamp=datetime.now(), correlation_id="single"
        )]
        
        single_result = await coordinator.resolve_conflicts(single_decision)
        assert single_result == single_decision[0]  # åº”è¯¥ç›´æ¥è¿”å›
        
        # æµ‹è¯•é«˜ç½®ä¿¡åº¦å†³ç­–ï¼ˆ>0.8ï¼‰
        high_conf_decisions = [
            BrainDecision(
                decision_id="high", primary_brain="soldier", action="buy",
                confidence=0.85, reasoning="High confidence", supporting_data={},
                timestamp=datetime.now(), correlation_id="high"
            ),
            BrainDecision(
                decision_id="low", primary_brain="commander", action="sell",
                confidence=0.60, reasoning="Low confidence", supporting_data={},
                timestamp=datetime.now(), correlation_id="low"
            )
        ]
        
        high_conf_result = await coordinator.resolve_conflicts(high_conf_decisions)
        # é«˜ç½®ä¿¡åº¦å†³ç­–åº”è¯¥è¢«ç›´æ¥é‡‡ç”¨
        assert high_conf_result.decision_id == "high"
        assert high_conf_result.confidence == 0.85

    @pytest.mark.asyncio
    async def test_specific_line_coverage_verification(self, coordinator):
        """ä¸“é—¨éªŒè¯ç‰¹å®šè¡Œçš„è¦†ç›–æƒ…å†µ"""
        
        # ç¡®ä¿Scholarå¼‚å¸¸å¤„ç†è·¯å¾„è¢«è¦†ç›–ï¼ˆ273-274è¡Œï¼‰
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=ConnectionError("Connection failed"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        # ç›´æ¥è°ƒç”¨_request_decision_directæ¥è§¦å‘å¼‚å¸¸å¤„ç†
        with patch.object(coordinator.event_bus, 'publish', AsyncMock(side_effect=Exception("Event publish failed"))):
            result = await coordinator._request_decision_direct(
                {"test": "data"}, "scholar", "test_id"
            )
            # å¼‚å¸¸å¤„ç†åº”è¯¥è¿”å›None
            assert result is None
        
        # ç¡®ä¿æ‰¹é‡å†³ç­–å¼‚å¸¸å¤„ç†è¢«è¦†ç›–ï¼ˆ457-461è¡Œï¼‰
        def create_failing_request(fail_index):
            async def mock_request(context, brain):
                if context.get("index") == fail_index:
                    raise RuntimeError(f"Request {fail_index} failed")
                return BrainDecision(
                    decision_id=f"success_{context.get('index')}",
                    primary_brain=brain, action="hold", confidence=0.5,
                    reasoning="Success", supporting_data={},
                    timestamp=datetime.now(), correlation_id=f"corr_{context.get('index')}"
                )
            return mock_request
        
        coordinator.request_decision = AsyncMock(side_effect=create_failing_request(1))
        
        batch_requests = [
            ({"index": 0}, "soldier"),
            ({"index": 1}, "commander"),  # è¿™ä¸ªä¼šå¤±è´¥
            ({"index": 2}, "scholar")
        ]
        
        batch_results = await coordinator.request_decisions_batch(batch_requests)
        
        # éªŒè¯å¼‚å¸¸å¤„ç†ç”Ÿæˆäº†å¤‡ç”¨å†³ç­–
        assert len(batch_results) == 3
        assert batch_results[0].decision_id == "success_0"
        assert "fallback" in batch_results[1].decision_id  # å¤±è´¥çš„è¯·æ±‚
        assert batch_results[2].decision_id == "success_2"
        
        # ç¡®ä¿å†²çªæ£€æµ‹è·¯å¾„è¢«è¦†ç›–ï¼ˆ792->815è¡Œï¼‰
        # åˆ›å»ºç½®ä¿¡åº¦éå¸¸æ¥è¿‘çš„å†³ç­–æ¥è§¦å‘å†²çªæ£€æµ‹
        very_close_decisions = [
            BrainDecision(
                decision_id="close1", primary_brain="soldier", action="buy",
                confidence=0.7500, reasoning="Very close 1", supporting_data={},
                timestamp=datetime.now(), correlation_id="close1"
            ),
            BrainDecision(
                decision_id="close2", primary_brain="commander", action="sell",
                confidence=0.7499, reasoning="Very close 2", supporting_data={},  # å·®å¼‚0.0001 < 0.1
                timestamp=datetime.now(), correlation_id="close2"
            )
        ]
        
        initial_conflicts = coordinator.stats.get("coordination_conflicts", 0)
        close_result = await coordinator.resolve_conflicts(very_close_decisions)
        
        # éªŒè¯å†²çªè¢«æ£€æµ‹åˆ°
        assert coordinator.stats["coordination_conflicts"] > initial_conflicts
        assert close_result.primary_brain == "coordinator_conflict_resolution"
        assert close_result.supporting_data["conflict_resolution"] is True


class TestSpecificLineCoverage:
    """ä¸“é—¨é’ˆå¯¹ç‰¹å®šè¡Œå·çš„è¦†ç›–æµ‹è¯•"""

    @pytest.fixture
    def coordinator(self):
        """åˆ›å»ºåŸºç¡€åè°ƒå™¨"""
        event_bus = MagicMock(spec=EventBus)
        event_bus.subscribe = AsyncMock()
        event_bus.publish = AsyncMock()
        container = MagicMock(spec=DIContainer)
        return AIBrainCoordinator(event_bus, container)

    @pytest.mark.asyncio
    async def test_lines_273_274_scholar_exception(self, coordinator):
        """ä¸“é—¨æµ‹è¯•273-274è¡Œï¼šScholarç›´æ¥è°ƒç”¨å¼‚å¸¸å¤„ç†"""
        # è®¾ç½®Scholarä½†è®©å…¶æŠ›å‡ºå¼‚å¸¸
        mock_scholar = AsyncMock(spec=IScholarEngine)
        mock_scholar.research = AsyncMock(side_effect=TimeoutError("Scholar timeout"))
        coordinator.scholar = mock_scholar
        coordinator.enable_batch_processing = False
        
        # è°ƒç”¨åº”è¯¥è§¦å‘å¼‚å¸¸å¤„ç†
        result = await coordinator._request_decision_direct(
            {"query": "test"}, "scholar", "test_correlation"
        )
        
        # éªŒè¯å¼‚å¸¸è¢«æ•è·ï¼Œæ–¹æ³•è¿”å›Noneï¼ˆå›é€€åˆ°äº‹ä»¶æ¨¡å¼ï¼‰
        assert result is None
        mock_scholar.research.assert_called_once()

    @pytest.mark.asyncio
    async def test_lines_457_461_batch_exception(self, coordinator):
        """ä¸“é—¨æµ‹è¯•457-461è¡Œï¼šæ‰¹é‡å†³ç­–å¼‚å¸¸å¤„ç†"""
        # Mock request_decisionè®©æŸäº›è¯·æ±‚å¤±è´¥
        async def selective_failure(context, brain):
            if context.get("should_fail"):
                raise Exception("Intentional failure")
            return BrainDecision(
                decision_id="success", primary_brain=brain, action="hold",
                confidence=0.5, reasoning="OK", supporting_data={},
                timestamp=datetime.now(), correlation_id="ok"
            )
        
        coordinator.request_decision = AsyncMock(side_effect=selective_failure)
        
        # åˆ›å»ºåŒ…å«å¤±è´¥è¯·æ±‚çš„æ‰¹æ¬¡
        requests = [
            ({"should_fail": False}, "soldier"),
            ({"should_fail": True}, "commander"),  # è¿™ä¸ªä¼šå¤±è´¥
        ]
        
        results = await coordinator.request_decisions_batch(requests)
        
        # éªŒè¯å¼‚å¸¸å¤„ç†ç”Ÿæˆäº†å¤‡ç”¨å†³ç­–
        assert len(results) == 2
        assert results[0].decision_id == "success"
        assert "fallback" in results[1].decision_id

    @pytest.mark.asyncio
    async def test_lines_792_815_conflict_detection(self, coordinator):
        """ä¸“é—¨æµ‹è¯•792->815è¡Œï¼šå†²çªæ£€æµ‹é€»è¾‘"""
        # åˆ›å»ºç½®ä¿¡åº¦å·®å¼‚å°äº0.1çš„å†³ç­–æ¥è§¦å‘å†²çªæ£€æµ‹
        decisions = [
            BrainDecision(
                decision_id="d1", primary_brain="soldier", action="buy",
                confidence=0.750, reasoning="Buy", supporting_data={},
                timestamp=datetime.now(), correlation_id="d1"
            ),
            BrainDecision(
                decision_id="d2", primary_brain="commander", action="sell",
                confidence=0.751, reasoning="Sell", supporting_data={},  # å·®å¼‚0.001 < 0.1
                timestamp=datetime.now(), correlation_id="d2"
            )
        ]
        
        initial_conflicts = coordinator.stats.get("coordination_conflicts", 0)
        
        # æ‰§è¡Œå†²çªè§£å†³
        result = await coordinator.resolve_conflicts(decisions)
        
        # éªŒè¯å†²çªæ£€æµ‹é€»è¾‘è¢«è§¦å‘
        assert coordinator.stats["coordination_conflicts"] > initial_conflicts
        assert result.primary_brain == "coordinator_conflict_resolution"
        
        # éªŒè¯ä¿å®ˆå†³ç­–ç”Ÿæˆ
        assert result.supporting_data["conflict_resolution"] is True
        assert "conflicting_decisions" in result.supporting_data
        assert len(result.supporting_data["conflicting_decisions"]) == 2