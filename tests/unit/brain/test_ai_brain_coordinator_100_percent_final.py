#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AI Brain Coordinator 100%è¦†ç›–ç‡æµ‹è¯• - æœ€ç»ˆç‰ˆæœ¬

ğŸ§ª Test Engineer ä¸“é—¨è´Ÿè´£è¾¾åˆ°100%æµ‹è¯•è¦†ç›–ç‡
ç›®æ ‡ï¼šè¦†ç›–æ‰€æœ‰å‰©ä½™çš„æœªè¦†ç›–ä»£ç è¡Œï¼Œç¡®ä¿100%è¦†ç›–ç‡

éµå¾ªæµ‹è¯•é“å¾‹ï¼šä¸¥ç¦è·³è¿‡ä»»ä½•æµ‹è¯•ï¼Œå¼ºåˆ¶è¦æ±‚100%è¦†ç›–ç‡
"""

import asyncio
import pytest
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, patch, call

from src.brain.ai_brain_coordinator import AIBrainCoordinator, BrainDecision
from src.core.dependency_container import DIContainer
from src.infra.event_bus import EventBus, Event, EventType, EventPriority
from src.brain.interfaces import IScholarEngine, ICommanderEngine, ISoldierEngine


class TestAIBrainCoordinator100PercentFinal:
    """100%è¦†ç›–ç‡æµ‹è¯• - æœ€ç»ˆç‰ˆæœ¬"""

    @pytest.fixture
    def mock_event_bus(self):
        """Mockäº‹ä»¶æ€»çº¿"""
        event_bus = MagicMock(spec=EventBus)
        event_bus.subscribe = AsyncMock()
        event_bus.publish = AsyncMock()
        return event_bus

    @pytest.fixture
    def mock_container(self):
        """Mockä¾èµ–å®¹å™¨"""
        container = MagicMock(spec=DIContainer)
        container.is_registered = MagicMock(return_value=True)
        return container

    @pytest.fixture
    def coordinator(self, mock_event_bus, mock_container):
        """åˆ›å»ºåè°ƒå™¨å®ä¾‹"""
        return AIBrainCoordinator(mock_event_bus, mock_container)

    @pytest.mark.asyncio
    async def test_initialization_failure_lines_97_116(self, coordinator):
        """æµ‹è¯•åˆå§‹åŒ–å¤±è´¥ï¼ˆ97-116è¡Œï¼‰"""
        # è®©å®¹å™¨è§£ææŠ›å‡ºå¼‚å¸¸
        coordinator.container.resolve.side_effect = Exception("Container resolve failed")
        
        with pytest.raises(Exception, match="Container resolve failed"):
            await coordinator.initialize()

    @pytest.mark.asyncio
    async def test_partial_brain_registration_lines_121_135(self, coordinator):
        """æµ‹è¯•éƒ¨åˆ†è„‘æ³¨å†Œï¼ˆ121-135è¡Œï¼‰"""
        # åªæ³¨å†ŒSoldierï¼Œä¸æ³¨å†ŒCommanderå’ŒScholar
        def mock_is_registered(interface):
            return interface == ISoldierEngine
        
        coordinator.container.is_registered.side_effect = mock_is_registered
        coordinator.container.resolve.return_value = MagicMock()
        
        await coordinator.initialize()
        
        # éªŒè¯åªæœ‰Soldierè¢«è®¾ç½®
        assert coordinator.soldier is not None
        assert coordinator.commander is None
        assert coordinator.scholar is None
    @pytest.mark.asyncio
    async def test_execute_decision_request_timeout_lines_181_226(self, coordinator):
        """æµ‹è¯•å†³ç­–è¯·æ±‚è¶…æ—¶å¤„ç†ï¼ˆ181-226è¡Œï¼‰"""
        # æ¨¡æ‹Ÿè¶…æ—¶æƒ…å†µ - è®©_request_decision_directè¿”å›None
        with patch.object(coordinator, '_request_decision_direct', return_value=None), \
             patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            
            result = await coordinator._execute_decision_request({"test": "data"}, "soldier")
            
            # éªŒè¯è¶…æ—¶å¤„ç†é€»è¾‘
            assert result is not None
            assert result.action == "hold"  # å¤‡ç”¨å†³ç­–
            assert "å¤‡ç”¨å†³ç­–" in result.reasoning
            
            # éªŒè¯logger.warningè¢«è°ƒç”¨
            warning_calls = mock_logger.warning.call_args_list
            timeout_warning_found = False
            for call_obj in warning_calls:
                call_args = call_obj[0][0]
                if "å†³ç­–è¶…æ—¶ï¼Œç”Ÿæˆå¤‡ç”¨å†³ç­–" in call_args:
                    timeout_warning_found = True
                    break
            
            assert timeout_warning_found, f"æœªæ‰¾åˆ°è¶…æ—¶è­¦å‘Šï¼Œå®é™…è°ƒç”¨: {warning_calls}"

    @pytest.mark.asyncio
    async def test_request_decision_direct_event_fallback_lines_276_294(self, coordinator):
        """æµ‹è¯•ç›´æ¥å†³ç­–è¯·æ±‚äº‹ä»¶å›é€€ï¼ˆ276-294è¡Œï¼‰"""
        # è®¾ç½®æ‰€æœ‰AIè„‘ä¸ºNoneï¼Œå¼ºåˆ¶ä½¿ç”¨äº‹ä»¶æ¨¡å¼
        coordinator.soldier = None
        coordinator.commander = None
        coordinator.scholar = None
        
        # Mockäº‹ä»¶å‘å¸ƒæˆåŠŸ
        coordinator.event_bus.publish = AsyncMock()
        
        # Mockç­‰å¾…å†³ç­–è¿”å›ç»“æœ
        test_decision = BrainDecision(
            decision_id="test_001",
            primary_brain="soldier",
            action="buy",
            confidence=0.8,
            reasoning="event mode test",
            supporting_data={},
            timestamp=datetime.now(),
            correlation_id="test_corr"
        )
        
        with patch.object(coordinator, '_wait_for_decision', return_value=test_decision):
            result = await coordinator._request_decision_direct({"test": "data"}, "soldier", "test_corr")
            
            # éªŒè¯äº‹ä»¶å‘å¸ƒè¢«è°ƒç”¨
            coordinator.event_bus.publish.assert_called_once()
            
            # éªŒè¯è¿”å›äº†æ­£ç¡®çš„å†³ç­–
            assert result == test_decision

    @pytest.mark.asyncio
    async def test_request_decision_with_batch_future_handling_lines_445_467(self, coordinator):
        """æµ‹è¯•æ‰¹å¤„ç†Futureå¤„ç†ï¼ˆ445-467è¡Œï¼‰"""
        coordinator.enable_batch_processing = True
        
        # Mockæ‰¹å¤„ç†é”å’Œé˜Ÿåˆ—
        with patch.object(coordinator, 'batch_lock', new_callable=AsyncMock) as mock_lock, \
             patch.object(coordinator, '_process_batch', new_callable=AsyncMock) as mock_process:
            
            # è®¾ç½®æ‰¹å¤„ç†é˜Ÿåˆ—è¾¾åˆ°æ‰¹å¤„ç†å¤§å°
            coordinator.pending_batch = [None] * (coordinator.batch_size - 1)  # 4ä¸ªå…ƒç´ 
            
            # åˆ›å»ºä¸€ä¸ªFutureæ¥æ¨¡æ‹Ÿæ‰¹å¤„ç†ç»“æœ
            future = asyncio.Future()
            future.set_result(BrainDecision(
                decision_id="batch_001",
                primary_brain="commander",
                action="buy",
                confidence=0.8,
                reasoning="batch test",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="batch_corr"
            ))
            
            # Mockæ‰¹å¤„ç†æ·»åŠ é€»è¾‘
            async def mock_batch_add(*args):
                coordinator.pending_batch.append(("context", "commander", "batch_corr", future))
                return len(coordinator.pending_batch) >= coordinator.batch_size
            
            mock_lock.__aenter__ = AsyncMock(return_value=mock_lock)
            mock_lock.__aexit__ = AsyncMock(return_value=None)
            
            # æ‰§è¡Œæ‰¹å¤„ç†å†³ç­–
            with patch('asyncio.wait_for', return_value=future.result()):
                result = await coordinator._request_decision_with_batch({"test": "data"}, "commander", "batch_corr")
                
                # éªŒè¯ç»“æœ
                assert result is not None
                assert result.action == "buy"

    @pytest.mark.asyncio
    async def test_process_batch_concurrent_execution_lines_475_476(self, coordinator):
        """æµ‹è¯•æ‰¹å¤„ç†å¹¶å‘æ‰§è¡Œï¼ˆ475-476è¡Œï¼‰"""
        # è®¾ç½®æ‰¹å¤„ç†é˜Ÿåˆ—
        futures = [asyncio.Future() for _ in range(3)]
        for future in futures:
            future.set_result(None)
        
        coordinator.pending_batch = [
            ({"test": f"data_{i}"}, "commander", f"corr_{i}", futures[i])
            for i in range(3)
        ]
        
        with patch.object(coordinator, '_process_batch_item', new_callable=AsyncMock) as mock_process_item, \
             patch('asyncio.gather', new_callable=AsyncMock) as mock_gather:
            
            mock_gather.return_value = [None, None, None]
            
            await coordinator._process_batch()
            
            # éªŒè¯å¹¶å‘æ‰§è¡Œ
            mock_gather.assert_called_once()
            assert mock_process_item.call_count == 3

    @pytest.mark.asyncio
    async def test_request_decisions_batch_exception_handling_lines_606(self, coordinator):
        """æµ‹è¯•æ‰¹é‡å†³ç­–å¼‚å¸¸å¤„ç†ï¼ˆ606è¡Œï¼‰"""
        # æ¨¡æ‹Ÿrequest_decisionæ–¹æ³•æŠ›å‡ºå¼‚å¸¸
        async def mock_request_decision(context, primary_brain):
            if context.get("symbol") == "000002.SZ":
                raise Exception("Second request failed")
            elif context.get("symbol") == "000001.SZ":
                return BrainDecision(
                    decision_id="test_001",
                    primary_brain="soldier",
                    action="buy",
                    confidence=0.8,
                    reasoning="test",
                    supporting_data={},
                    timestamp=datetime.now(),
                    correlation_id="corr_001"
                )
            else:
                return BrainDecision(
                    decision_id="test_003",
                    primary_brain="soldier",
                    action="sell",
                    confidence=0.7,
                    reasoning="test",
                    supporting_data={},
                    timestamp=datetime.now(),
                    correlation_id="corr_003"
                )
        
        requests = [
            ({"symbol": "000001.SZ"}, "soldier"),
            ({"symbol": "000002.SZ"}, "soldier"),
            ({"symbol": "000003.SZ"}, "soldier")
        ]
        
        with patch.object(coordinator, 'request_decision', side_effect=mock_request_decision), \
             patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            
            results = await coordinator.request_decisions_batch(requests)
            
            # éªŒè¯ç»“æœ
            assert len(results) == 3
            assert results[0].action == "buy"
            assert results[1].primary_brain.startswith("coordinator_fallback")  # å¼‚å¸¸æ—¶çš„å¤‡ç”¨å†³ç­–
            assert results[2].action == "sell"
            
            # éªŒè¯logger.errorè¢«è°ƒç”¨
            error_calls = mock_logger.error.call_args_list
            batch_error_found = False
            for call_obj in error_calls:
                call_args = call_obj[0][0]
                if "æ‰¹é‡å†³ç­–å¤±è´¥" in call_args:
                    batch_error_found = True
                    break
            
            assert batch_error_found, f"æœªæ‰¾åˆ°æ‰¹é‡å†³ç­–å¤±è´¥é”™è¯¯ï¼Œå®é™…è°ƒç”¨: {error_calls}"
    @pytest.mark.asyncio
    async def test_wait_for_decision_success_with_cleanup_lines_526_545(self, coordinator):
        """æµ‹è¯•ç­‰å¾…å†³ç­–æˆåŠŸå¹¶æ¸…ç†ï¼ˆ526-545è¡Œï¼‰"""
        correlation_id = "test_success_corr"
        
        # é¢„è®¾å†³ç­–ç»“æœ
        test_decision = BrainDecision(
            decision_id="test_001",
            primary_brain="soldier",
            action="buy",
            confidence=0.8,
            reasoning="test",
            supporting_data={},
            timestamp=datetime.now(),
            correlation_id=correlation_id
        )
        
        # åœ¨ç¬¬äºŒæ¬¡æ£€æŸ¥æ—¶æ·»åŠ å†³ç­–
        async def delayed_add():
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå»¶è¿Ÿ
            coordinator.pending_decisions[correlation_id] = test_decision
        
        # å¯åŠ¨å»¶è¿Ÿæ·»åŠ ä»»åŠ¡
        asyncio.create_task(delayed_add())
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            result = await coordinator._wait_for_decision(correlation_id, timeout=1.0)
            
            # éªŒè¯ç»“æœ
            assert result == test_decision
            assert correlation_id not in coordinator.pending_decisions  # åº”è¯¥è¢«æ¸…ç†
            
            # éªŒè¯logger.debugè¢«è°ƒç”¨
            debug_calls = mock_logger.debug.call_args_list
            success_debug_found = False
            for call_obj in debug_calls:
                call_args = call_obj[0][0]
                if "æ”¶åˆ°å†³ç­–ç»“æœ" in call_args and correlation_id in call_args:
                    success_debug_found = True
                    break
            
            assert success_debug_found, f"æœªæ‰¾åˆ°æˆåŠŸè°ƒè¯•ä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {debug_calls}"

    @pytest.mark.asyncio
    async def test_handle_analysis_completed_unknown_type_lines_637_676(self, coordinator):
        """æµ‹è¯•å¤„ç†æœªçŸ¥åˆ†æç±»å‹ï¼ˆ637-676è¡Œï¼‰"""
        # æµ‹è¯•æœªçŸ¥åˆ†æç±»å‹
        event = Event(
            event_type=EventType.ANALYSIS_COMPLETED,
            source_module="test",
            target_module="coordinator",
            data={"analysis_type": "unknown_analysis", "result": "test"}
        )
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œäº‹ä»¶å¤„ç†
            await coordinator._handle_analysis_completed(event)
            
            # éªŒè¯logger.debugè¢«è°ƒç”¨
            debug_calls = mock_logger.debug.call_args_list
            analysis_debug_found = False
            for call_obj in debug_calls:
                call_args = call_obj[0][0]
                if "Analysis completed" in call_args and "unknown_analysis" in call_args:
                    analysis_debug_found = True
                    break
            
            assert analysis_debug_found, f"æœªæ‰¾åˆ°åˆ†æå®Œæˆè°ƒè¯•ä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {debug_calls}"

    @pytest.mark.asyncio
    async def test_handle_analysis_completed_exception_lines_687_696(self, coordinator):
        """æµ‹è¯•åˆ†æå®Œæˆäº‹ä»¶å¤„ç†å¼‚å¸¸ï¼ˆ687-696è¡Œï¼‰"""
        # åˆ›å»ºä¼šå¯¼è‡´å¼‚å¸¸çš„äº‹ä»¶
        event = Event(
            event_type=EventType.ANALYSIS_COMPLETED,
            source_module="test",
            target_module="coordinator",
            data=None  # è¿™ä¼šå¯¼è‡´å¼‚å¸¸
        )
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œäº‹ä»¶å¤„ç†ï¼Œåº”è¯¥æ•è·å¼‚å¸¸
            await coordinator._handle_analysis_completed(event)
            
            # éªŒè¯logger.errorè¢«è°ƒç”¨
            error_calls = mock_logger.error.call_args_list
            analysis_error_found = False
            for call_obj in error_calls:
                call_args = call_obj[0][0]
                if "Failed to handle analysis completed" in call_args:
                    analysis_error_found = True
                    break
            
            assert analysis_error_found, f"æœªæ‰¾åˆ°åˆ†æå®Œæˆå¤±è´¥é”™è¯¯ï¼Œå®é™…è°ƒç”¨: {error_calls}"

    @pytest.mark.asyncio
    async def test_handle_factor_discovered_exception_lines_715_726(self, coordinator):
        """æµ‹è¯•å› å­å‘ç°äº‹ä»¶å¤„ç†å¼‚å¸¸ï¼ˆ715-726è¡Œï¼‰"""
        # åˆ›å»ºä¼šå¯¼è‡´å¼‚å¸¸çš„äº‹ä»¶
        event = Event(
            event_type=EventType.FACTOR_DISCOVERED,
            source_module="test",
            target_module="coordinator",
            data={"factor_info": None}  # è¿™ä¼šå¯¼è‡´å¼‚å¸¸
        )
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            # æ‰§è¡Œäº‹ä»¶å¤„ç†ï¼Œåº”è¯¥æ•è·å¼‚å¸¸
            await coordinator._handle_factor_discovered(event)
            
            # éªŒè¯logger.errorè¢«è°ƒç”¨
            error_calls = mock_logger.error.call_args_list
            factor_error_found = False
            for call_obj in error_calls:
                call_args = call_obj[0][0]
                if "Failed to handle factor discovered" in call_args:
                    factor_error_found = True
                    break
            
            assert factor_error_found, f"æœªæ‰¾åˆ°å› å­å‘ç°å¤±è´¥é”™è¯¯ï¼Œå®é™…è°ƒç”¨: {error_calls}"

    def test_create_fallback_decision_with_primary_brain_lines_763_764(self, coordinator):
        """æµ‹è¯•åˆ›å»ºå¤‡ç”¨å†³ç­–æŒ‡å®šä¸»è„‘ï¼ˆ763-764è¡Œï¼‰"""
        context = {"test": "data"}
        correlation_id = "test_corr"
        primary_brain = "scholar"
        
        decision = coordinator._create_fallback_decision(context, correlation_id, primary_brain)
        
        # éªŒè¯ä¸»è„‘è¢«æ­£ç¡®è®¾ç½®
        assert decision.primary_brain == f"coordinator_fallback_{primary_brain}"
        assert decision.supporting_data["original_brain"] == primary_brain

    def test_add_to_history_debug_logging_lines_786_789(self, coordinator):
        """æµ‹è¯•æ·»åŠ å†å²è®°å½•è°ƒè¯•æ—¥å¿—ï¼ˆ786-789è¡Œï¼‰"""
        decision = BrainDecision(
            decision_id="test_001",
            primary_brain="soldier",
            action="buy",
            confidence=0.8,
            reasoning="test",
            supporting_data={},
            timestamp=datetime.now(),
            correlation_id="corr_001"
        )
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            coordinator._add_to_history(decision)
            
            # éªŒè¯logger.debugè¢«è°ƒç”¨
            debug_calls = mock_logger.debug.call_args_list
            history_debug_found = False
            for call_obj in debug_calls:
                call_args = call_obj[0][0]
                if "æ·»åŠ å†³ç­–å†å²" in call_args and "test_001" in call_args:
                    history_debug_found = True
                    break
            
            assert history_debug_found, f"æœªæ‰¾åˆ°å†å²è®°å½•è°ƒè¯•ä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {debug_calls}"
    def test_add_to_history_overflow_cleanup_lines_815_816(self, coordinator):
        """æµ‹è¯•å†å²è®°å½•æº¢å‡ºæ¸…ç†ï¼ˆ815-816è¡Œï¼‰"""
        coordinator.max_history = 3
        
        # æ·»åŠ 4ä¸ªå†³ç­–ï¼Œè§¦å‘æº¢å‡ºæ¸…ç†
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            for i in range(4):
                decision = BrainDecision(
                    decision_id=f"test_{i:03d}",
                    primary_brain="soldier",
                    action="buy",
                    confidence=0.8,
                    reasoning="test",
                    supporting_data={},
                    timestamp=datetime.now(),
                    correlation_id=f"corr_{i:03d}"
                )
                coordinator._add_to_history(decision)
            
            # éªŒè¯åªä¿ç•™æœ€å3ä¸ª
            assert len(coordinator.decision_history) == 3
            assert coordinator.decision_history[0].decision_id == "test_001"
            assert coordinator.decision_history[-1].decision_id == "test_003"
            
            # éªŒè¯logger.debugè¢«è°ƒç”¨ï¼ˆæº¢å‡ºæ¸…ç†ï¼‰
            debug_calls = mock_logger.debug.call_args_list
            overflow_debug_found = False
            for call_obj in debug_calls:
                call_args = call_obj[0][0]
                if "å†å²è®°å½•è¶…é™ï¼Œç§»é™¤" in call_args:
                    overflow_debug_found = True
                    break
            
            assert overflow_debug_found, f"æœªæ‰¾åˆ°æº¢å‡ºæ¸…ç†è°ƒè¯•ä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {debug_calls}"

    @pytest.mark.asyncio
    async def test_resolve_conflicts_high_confidence_decision_lines_836_847(self, coordinator):
        """æµ‹è¯•é«˜ç½®ä¿¡åº¦å†³ç­–ä¼˜å…ˆï¼ˆ836-847è¡Œï¼‰"""
        decisions = [
            BrainDecision(
                decision_id="low_conf",
                primary_brain="commander",
                action="sell",
                confidence=0.6,
                reasoning="low confidence",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="low_corr"
            ),
            BrainDecision(
                decision_id="high_conf",
                primary_brain="soldier",  # æ”¹ä¸ºsoldierï¼Œä¼˜å…ˆçº§æœ€é«˜
                action="buy",
                confidence=0.85,  # é«˜ç½®ä¿¡åº¦ > 0.8
                reasoning="high confidence",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="high_corr"
            )
        ]
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            result = await coordinator.resolve_conflicts(decisions)
            
            # éªŒè¯é«˜ç½®ä¿¡åº¦å†³ç­–è¢«é€‰ä¸­
            # ç”±äºsoldierä¼˜å…ˆçº§æœ€é«˜ä¸”ç½®ä¿¡åº¦>0.8ï¼Œåº”è¯¥è¢«é€‰ä¸­
            assert result.decision_id == "high_conf"
            assert result.confidence == 0.85
            
            # éªŒè¯logger.infoè¢«è°ƒç”¨
            info_calls = mock_logger.info.call_args_list
            high_conf_info_found = False
            for call_obj in info_calls:
                call_args = call_obj[0][0]
                if "é«˜ç½®ä¿¡åº¦å†³ç­–é‡‡ç”¨" in call_args and "0.85" in call_args:
                    high_conf_info_found = True
                    break
            
            assert high_conf_info_found, f"æœªæ‰¾åˆ°é«˜ç½®ä¿¡åº¦å†³ç­–ä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {info_calls}"

    def test_create_conservative_decision_default_case_lines_884_955(self, coordinator):
        """æµ‹è¯•ä¿å®ˆå†³ç­–é»˜è®¤æƒ…å†µï¼ˆ884-955è¡Œï¼‰"""
        # åˆ›å»ºä¸åŒ¹é…ä»»ä½•ç‰¹æ®Šæƒ…å†µçš„å†³ç­–
        decisions = [
            BrainDecision(
                decision_id="test_001",
                primary_brain="soldier",
                action="unknown_action",  # ä¸åŒ¹é…ä»»ä½•ç‰¹æ®Šæƒ…å†µ
                confidence=0.6,
                reasoning="test",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="corr_001"
            ),
            BrainDecision(
                decision_id="test_002",
                primary_brain="commander",
                action="custom_action",  # ä¸åŒ¹é…ä»»ä½•ç‰¹æ®Šæƒ…å†µ
                confidence=0.7,
                reasoning="test",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id="corr_002"
            )
        ]
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            result = coordinator._create_conservative_decision(decisions)
            
            # éªŒè¯é»˜è®¤ä¿å®ˆç­–ç•¥
            assert result.action == "hold"
            assert "å†³ç­–å†²çªï¼Œé‡‡ç”¨é»˜è®¤ä¿å®ˆç­–ç•¥" in result.reasoning
            assert result.primary_brain == "coordinator_conflict_resolution"
            
            # éªŒè¯å¹³å‡ç½®ä¿¡åº¦è®¡ç®—ï¼ˆé™ä½60%ï¼‰
            expected_confidence = (0.6 + 0.7) / 2 * 0.6  # å¹³å‡åé™ä½60%
            assert abs(result.confidence - expected_confidence) < 0.01
            
            # éªŒè¯logger.infoè¢«è°ƒç”¨
            info_calls = mock_logger.info.call_args_list
            conservative_info_found = False
            for call_obj in info_calls:
                call_args = call_obj[0][0]
                if "ç”Ÿæˆä¿å®ˆå†³ç­–" in call_args:
                    conservative_info_found = True
                    break
            
            assert conservative_info_found, f"æœªæ‰¾åˆ°ä¿å®ˆå†³ç­–ä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {info_calls}"

    def test_get_statistics_with_zero_decisions_lines_963_965(self, coordinator):
        """æµ‹è¯•é›¶å†³ç­–æ—¶çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆ963-965è¡Œï¼‰"""
        # ç¡®ä¿æ²¡æœ‰å†³ç­–
        coordinator.stats["total_decisions"] = 0
        coordinator.decision_history = []
        
        stats = coordinator.get_statistics()
        
        # éªŒè¯é›¶å†³ç­–æ—¶çš„è®¡ç®— - æ£€æŸ¥å®é™…è¿”å›çš„é”®
        # å½“total_decisionsä¸º0æ—¶ï¼Œbrain_percentageså­—å…¸ä¸ºç©º
        assert stats["total_decisions"] == 0
        assert stats["average_confidence"] == 0.0
        assert stats["conflict_rate"] == 0.0
        assert stats["decisions_per_minute"] == 0.0
        
        # éªŒè¯ç™¾åˆ†æ¯”ç»Ÿè®¡ä¸å­˜åœ¨ï¼ˆå› ä¸ºtotal_decisionsä¸º0ï¼‰
        # æ ¹æ®æºä»£ç ï¼Œå½“total_decisionsä¸º0æ—¶ï¼Œbrain_percentagesä¸ºç©ºå­—å…¸
        assert "soldier_percentage" not in stats
        assert "commander_percentage" not in stats
        assert "scholar_percentage" not in stats

    @pytest.mark.asyncio
    async def test_get_coordination_status_duplicate_method_lines_1021_1023(self, coordinator):
        """æµ‹è¯•åè°ƒçŠ¶æ€é‡å¤æ–¹æ³•ï¼ˆ1021-1023è¡Œï¼‰"""
        # è®¾ç½®ä¸€äº›çŠ¶æ€
        coordinator.coordination_active = True
        coordinator.soldier = MagicMock()
        coordinator.commander = None
        coordinator.scholar = MagicMock()
        
        # æ·»åŠ ä¸€äº›å†³ç­–å†å²
        for i in range(3):
            decision = BrainDecision(
                decision_id=f"test_{i:03d}",
                primary_brain="soldier",
                action="buy",
                confidence=0.8,
                reasoning="test",
                supporting_data={},
                timestamp=datetime.now(),
                correlation_id=f"corr_{i:03d}"
            )
            coordinator.decision_history.append(decision)
        
        status = await coordinator.get_coordination_status()
        
        # éªŒè¯çŠ¶æ€ä¿¡æ¯
        assert status["coordination_active"] is True
        assert status["brains_available"]["soldier"] is True
        assert status["brains_available"]["commander"] is False
        assert status["brains_available"]["scholar"] is True
        assert len(status["recent_decisions"]) == 3

    @pytest.mark.asyncio
    async def test_shutdown_cleanup_lines_1047_1048(self, coordinator):
        """æµ‹è¯•å…³é—­æ¸…ç†ï¼ˆ1047-1048è¡Œï¼‰"""
        # è®¾ç½®ä¸€äº›çŠ¶æ€
        coordinator.coordination_active = True
        coordinator.pending_decisions["test"] = BrainDecision(
            decision_id="test_001",
            primary_brain="soldier",
            action="buy",
            confidence=0.8,
            reasoning="test",
            supporting_data={},
            timestamp=datetime.now(),
            correlation_id="corr_001"
        )
        
        with patch('src.brain.ai_brain_coordinator.logger') as mock_logger:
            await coordinator.shutdown()
            
            # éªŒè¯çŠ¶æ€è¢«æ¸…ç†
            assert coordinator.coordination_active is False
            assert len(coordinator.pending_decisions) == 0
            
            # éªŒè¯logger.infoè¢«è°ƒç”¨
            info_calls = mock_logger.info.call_args_list
            shutdown_info_found = False
            for call_obj in info_calls:
                call_args = call_obj[0][0]
                if "Shutdown completed" in call_args:
                    shutdown_info_found = True
                    break
            
            assert shutdown_info_found, f"æœªæ‰¾åˆ°å…³é—­å®Œæˆä¿¡æ¯ï¼Œå®é™…è°ƒç”¨: {info_calls}"

    @pytest.mark.asyncio
    async def test_global_coordinator_singleton_lines_1053_1054(self):
        """æµ‹è¯•å…¨å±€åè°ƒå™¨å•ä¾‹ï¼ˆ1053-1054è¡Œï¼‰"""
        # é‡ç½®å…¨å±€å˜é‡
        import src.brain.ai_brain_coordinator as module
        module._global_coordinator = None
        
        # Mockä¾èµ–
        with patch('src.brain.ai_brain_coordinator.get_event_bus') as mock_get_event_bus, \
             patch('src.brain.ai_brain_coordinator.get_container') as mock_get_container:
            
            mock_event_bus = AsyncMock()
            mock_container = MagicMock()
            mock_get_event_bus.return_value = mock_event_bus
            mock_get_container.return_value = mock_container
            
            # é…ç½®å®¹å™¨
            mock_container.is_registered.return_value = False
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨
            coordinator1 = await module.get_ai_brain_coordinator()
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨åº”è¯¥è¿”å›åŒä¸€ä¸ªå®ä¾‹
            coordinator2 = await module.get_ai_brain_coordinator()
            
            assert coordinator1 is coordinator2
            
            # éªŒè¯åˆå§‹åŒ–åªè¢«è°ƒç”¨ä¸€æ¬¡
            assert mock_get_event_bus.call_count == 1
            assert mock_get_container.call_count == 1


if __name__ == "__main__":
    pytest.main([__file__, "-v"])